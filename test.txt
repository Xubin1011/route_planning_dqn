Batchsize, Gamma, EPS_start, EPS_end, EPS_decay, TAU, LR, Replaybuffer, actions, oberservations =  128 0.99 0.9 0.05 1000 0.005 0.0001 10000 22 8 

Number of episodes =  60 

state_reset =  tensor([[ 4.0000, 49.9254,  9.9478,  0.3233,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.663713165886136 m 80.0 km/h 104.85552548010654 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.012666284042114858 40.0 -0.8978092877402087 -150.00132907535124 0.0
reward =  -110.91180464713355 

state, action, next_state, reward =  tensor([[ 4.0000, 49.9254,  9.9478,  0.3233,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9781e+01, 1.0245e+01, 8.0000e-01, 2.2196e+04, 1.1999e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([-110.9118], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 26.044571077351403 m 92.00000000000001 km/h 151.19830935689535 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5852345755365072 40.0 -0.8978092877402087 -139.80997517551808 -243.0
reward =  -344.2930190387948 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9781e+01, 1.0245e+01, 8.0000e-01, 2.2196e+04, 1.1999e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9787e+01, 9.8822e+00, 7.3303e-01, 0.0000e+00, 2.2190e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([-344.2930], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.302742827262676 m 83.00000000000001 km/h 112.54645788244656 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8922603724998294 40.0 -0.8978092877402087 -128.83529153959694 -81.0
reward =  -169.84084045483732 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9787e+01, 9.8822e+00, 7.3303e-01, 0.0000e+00, 2.2190e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.0011e+01, 9.9489e+00, 6.8460e-01, 0.0000e+00, 3.3165e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([-169.8408], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 26.904187720680923 m 79.99999999999999 km/h 102.96126728323166 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8122280540586461 40.0 -0.03374877813318506 -116.7284070652905 0.0
reward =  -77.57438389748233 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0011e+01, 9.9489e+00, 6.8460e-01, 0.0000e+00, 3.3165e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9982e+01, 9.5752e+00, 3.0000e-01, 0.0000e+00, 4.5272e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([-77.5744], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 27.682595967802335 m 97.0 km/h 148.35533699549768 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7417430676052393 40.0 -7.2070636537394055 -106.45445392260099 0.0
reward =  -74.40326064394563 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9982e+01, 9.5752e+00, 3.0000e-01, 0.0000e+00, 4.5272e+03,
         0.0000e+00, 4.4956e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9998e+01, 9.1888e+00, 5.0000e-01, 2.5964e+04, 5.5546e+03,
         0.0000e+00, 1.7114e+04]], device='cuda:0') tensor([-74.4033], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.033751132257326 m 100.0 km/h 159.95543895852165 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7098285546499724 40.0 -0.5343409576093563 -152.98784959238736 -270.0
reward =  -384.2320191046467 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9998e+01, 9.1888e+00, 5.0000e-01, 2.5964e+04, 5.5546e+03,
         0.0000e+00, 1.7114e+04]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 5.0013e+01, 8.8393e+00, 4.3190e-01, 0.0000e+00, 9.0122e+02,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([-384.2320], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.26837929030962 m 94.0 km/h 137.43666185713124 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4014932481838693 40.0 -0.5343409576093563 -143.31059794929007 -243.0
reward =  -346.4434456587156 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0013e+01, 8.8393e+00, 4.3190e-01, 0.0000e+00, 9.0122e+02,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0234e+01, 8.7539e+00, 3.7284e-01, 0.0000e+00, 1.8689e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([-346.4434], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.26837929030962 m 93.0 km/h 148.82812069174796 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4014932481838693 40.0 -0.5343409576093563 -133.52928983691214 -81.0
reward =  -175.46512404270538 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0234e+01, 8.7539e+00, 3.7284e-01, 0.0000e+00, 1.8689e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.0013e+01, 8.8393e+00, 3.0888e-01, 0.0000e+00, 2.8471e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([-175.4651], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.522420674332682 m 97.0 km/h 141.30789062964595 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9529829906309978 40.0 -0.5343409576093563 -124.05705123612888 -270.0
reward =  -355.54437518436924 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0013e+01, 8.8393e+00, 3.0888e-01, 0.0000e+00, 2.8471e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9943e+01, 8.4993e+00, 2.4755e-01, 0.0000e+00, 3.7943e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([-355.5444], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.067223056155765 m 94.0 km/h 151.16319071038285 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8146053241991438 40.0 -0.5343409576093563 -114.45683815079263 -162.0
reward =  -236.17657378420284 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9943e+01, 8.4993e+00, 2.4755e-01, 0.0000e+00, 3.7943e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9957e+01, 8.8490e+00, 1.8310e-01, 0.0000e+00, 4.7543e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([-236.1766], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.05810785957899 m 87.0 km/h 123.31743367171596 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.07185160759255756 40.0 -0.013055111978530905 -104.08796593303582 0.0
reward =  -64.17287265260691 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9957e+01, 8.8490e+00, 1.8310e-01, 0.0000e+00, 4.7543e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.0124e+01, 8.6128e+00, 0.0000e+00, 0.0000e+00, 5.7912e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([-64.1729], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.14098558943078 m 80.00000000000001 km/h 126.79446501094287 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.852394542664173 -500 -0.5343409576093563 -92.77452241779196 -162.0
reward =  -754.4564688327371 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0124e+01, 8.6128e+00, 0.0000e+00, 0.0000e+00, 5.7912e+03,
         0.0000e+00, 3.7687e+03]], device='cuda:0') tensor([[19]], device='cuda:0') None tensor([-754.4565], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 12
Sum reward: -3093.514187942177
**************************************Episode 0 done**************************************

state_reset =  tensor([[ 5.0000, 50.0504,  8.5669,  0.1162,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.139731694334017 m 91.0 km/h 156.86050934673844 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2621672967730579 -31.609496898656708 -27.0 -152.0546116374063 0.0
reward =  -210.92627583283607 

state, action, next_state, reward =  tensor([[ 5.0000, 50.0504,  8.5669,  0.1162,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9844e+01, 8.7090e+00, 4.9119e-02, 2.7000e+03, 9.9454e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-210.9263], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.085507629625177 m 90.0 km/h 116.41670399725672 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3217551707620733 -500 -26.9227765801259 -142.02040858555625 0.0
reward =  -668.6214299949202 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9844e+01, 8.7090e+00, 4.9119e-02, 2.7000e+03, 9.9454e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[0]], device='cuda:0') None tensor([-668.6214], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -879.5477058277562
**************************************Episode 1 done**************************************

state_reset =  tensor([[ 4.0000, 50.5959, 10.3962,  0.1878,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 27.41979370293449 m 91.0 km/h 127.14630729696822 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2107717764201807 40.0 -7.614813281502859 -151.15260908455338 0.0
reward =  -118.55665058963606 

state, action, next_state, reward =  tensor([[ 4.0000, 50.5959, 10.3962,  0.1878,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0812e+01, 1.0209e+01, 5.0000e-01, 3.5745e+04, 1.0847e+03,
         0.0000e+00, 1.7930e+04]], device='cuda:0') tensor([-118.5567], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.04698620059797 m 80.0 km/h 156.91995530527632 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.08824703853325919 40.0 -25.856343454496237 -150.7288562097309 0.0
reward =  -136.6734467027604 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0812e+01, 1.0209e+01, 5.0000e-01, 3.5745e+04, 1.0847e+03,
         0.0000e+00, 1.7930e+04]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0626e+01, 1.0410e+01, 4.3316e-01, 2.3271e+03, 1.1271e+03,
         0.0000e+00, 1.1437e+02]], device='cuda:0') tensor([-136.6734], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.04698620059797 m 91.0 km/h 97.8231179992504 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.08824703853325919 40.0 -0.5193491064692936 -140.82015837213171 0.0
reward =  -101.25126044006774 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0626e+01, 1.0410e+01, 4.3316e-01, 2.3271e+03, 1.1271e+03,
         0.0000e+00, 1.1437e+02]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0812e+01, 1.0209e+01, 8.0000e-01, 3.9306e+04, 2.1180e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([-101.2513], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.04698620059797 m 85.0 km/h 166.19332683854316 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.08824703853325919 40.0 -0.5193491064692936 -130.21202304011373 -0.0
reward =  -90.8196191851163 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0812e+01, 1.0209e+01, 8.0000e-01, 3.9306e+04, 2.1180e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0626e+01, 1.0410e+01, 7.2921e-01, 0.0000e+00, 3.1788e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([-90.8196], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.437335810363688 m 98.0 km/h 176.44818002749454 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5875525909515319 40.0 -0.5193491064692936 -120.867695599572 -0.0
reward =  -80.79949211508976 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0626e+01, 1.0410e+01, 7.2921e-01, 0.0000e+00, 3.1788e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.0854e+01, 1.0380e+01, 6.5287e-01, 0.0000e+00, 4.1132e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([-80.7995], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.234001632341965 m 84.0 km/h 106.92986777426293 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0085855589674204 40.0 -0.5193491064692936 -110.05312347142542 -0.0
reward =  -71.58105813686214 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0854e+01, 1.0380e+01, 6.5287e-01, 0.0000e+00, 4.1132e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.0726e+01, 1.0084e+01, 6.0698e-01, 0.0000e+00, 5.1947e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([-71.5811], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.234001632341965 m 94.0 km/h 161.428315931077 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0085855589674204 40.0 -0.5193491064692936 -100.38903773989021 -0.0
reward =  -59.89980128739209 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0726e+01, 1.0084e+01, 6.0698e-01, 0.0000e+00, 5.1947e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0854e+01, 1.0380e+01, 5.3771e-01, 0.0000e+00, 6.1611e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([-59.8998], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 28.21012534517487 m 86.0 km/h 76.3125988918459 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.077891491117693 40.0 -0.050109604764844835 -88.58014806051469 0.0
reward =  -47.55236617416184 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0854e+01, 1.0380e+01, 5.3771e-01, 0.0000e+00, 6.1611e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.0945e+01, 1.0756e+01, 0.0000e+00, 0.0000e+00, 7.3420e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([-47.5524], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.000301048237194 m 98.0 km/h 189.60040212464472 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.49361711528653746 -500 -2.2257732739831555 -79.39636400197858 0.0
reward =  -582.1157543912483 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0945e+01, 1.0756e+01, 0.0000e+00, 0.0000e+00, 7.3420e+03,
         0.0000e+00, 3.7387e+03]], device='cuda:0') tensor([[4]], device='cuda:0') None tensor([-582.1158], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 9
Sum reward: -1289.2494490223344
**************************************Episode 2 done**************************************

state_reset =  tensor([[ 4.0000, 52.2800,  9.4918,  0.7617,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 26.089356208334866 m 99.0 km/h 139.89796204879136 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9059392917377036 40.0 -0.039964956400012276 -152.5129613787873 0.0
reward =  -111.64698704344963 

state, action, next_state, reward =  tensor([[ 4.0000, 52.2800,  9.4918,  0.7617,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.2333e+01, 9.8655e+00, 3.0000e-01, 0.0000e+00, 9.4870e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-111.6470], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.444828299179235 m 86.0 km/h 130.64187797034262 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.09636111353641492 40.0 -0.758662243038314 -141.8616379047123 0.0
reward =  -102.71666126128703 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2333e+01, 9.8655e+00, 3.0000e-01, 0.0000e+00, 9.4870e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.2118e+01, 9.7364e+00, 8.0000e-01, 5.8903e+04, 2.0138e+03,
         0.0000e+00, 4.2173e+03]], device='cuda:0') tensor([-102.7167], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.444828299179235 m 95.0 km/h 143.6631512831173 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.09636111353641492 40.0 -0.043783190106602164 -132.2193871808128 0.0
reward =  -92.16680925738297 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.2118e+01, 9.7364e+00, 8.0000e-01, 5.8903e+04, 2.0138e+03,
         0.0000e+00, 4.2173e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 5.2333e+01, 9.8655e+00, 3.0000e-01, 0.0000e+00, 2.9781e+03,
         0.0000e+00, 4.2173e+03]], device='cuda:0') tensor([-92.1668], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.01183807599641 m 92.00000000000001 km/h 138.74641087830463 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9555928407577856 40.0 -2.0079712375432903 -122.43214619455334 0.0
reward =  -83.48452459133884 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.2333e+01, 9.8655e+00, 3.0000e-01, 0.0000e+00, 2.9781e+03,
         0.0000e+00, 4.2173e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.2322e+01, 1.0233e+01, 3.0000e-01, 2.4986e+03, 3.9568e+03,
         0.0000e+00, 6.7159e+03]], device='cuda:0') tensor([-83.4845], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.01183807599641 m 98.0 km/h 154.0716521675933 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9555928407577856 40.0 -6.967066513136074 -113.2441240441873 0.0
reward =  -81.16678339808117 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2322e+01, 1.0233e+01, 3.0000e-01, 2.4986e+03, 3.9568e+03,
         0.0000e+00, 6.7159e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.2333e+01, 9.8655e+00, 8.0000e-01, 2.3943e+04, 4.8756e+03,
         0.0000e+00, 1.6634e+04]], device='cuda:0') tensor([-81.1668], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.01183807599641 m 80.0 km/h 115.54612136962248 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9555928407577856 40.0 -0.0450849985067918 -150.74467286580162 0.0
reward =  -109.83416502355063 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2333e+01, 9.8655e+00, 8.0000e-01, 2.3943e+04, 4.8756e+03,
         0.0000e+00, 1.6634e+04]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.2322e+01, 1.0233e+01, 3.0000e-01, 0.0000e+00, 1.1255e+03,
         0.0000e+00, 2.6097e+03]], device='cuda:0') tensor([-109.8342], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.01183807599641 m 87.0 km/h 131.19733571886843 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9555928407577856 40.0 -0.024419240617342727 -140.3949467653893 0.0
reward =  -101.37495884676443 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2322e+01, 1.0233e+01, 3.0000e-01, 0.0000e+00, 1.1255e+03,
         0.0000e+00, 2.6097e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.2333e+01, 9.8655e+00, 0.0000e+00, 0.0000e+00, 2.1605e+03,
         0.0000e+00, 2.6097e+03]], device='cuda:0') tensor([-101.3750], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.081664865801034 m 89.0 km/h 133.00407650536863 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9618290828513564 -500 -0.9027937814658435 -130.24955423540237 0.0
reward =  -630.1905189340168 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2333e+01, 9.8655e+00, 0.0000e+00, 0.0000e+00, 2.1605e+03,
         0.0000e+00, 2.6097e+03]], device='cuda:0') tensor([[18]], device='cuda:0') None tensor([-630.1905], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 8
Sum reward: -1312.5814083558716
**************************************Episode 3 done**************************************

state_reset =  tensor([[ 5.0000, 50.2948,  8.6743,  0.5646,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.36860464348969 m 89.0 km/h 111.96950667741417 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.12399324025879614 40.0 -0.05162624626220267 -151.73854194195923 0.0
reward =  -111.66617494796263 

state, action, next_state, reward =  tensor([[ 5.0000, 50.2948,  8.6743,  0.5646,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   50.1278,    8.9171,    0.0000,    0.0000, 1026.1458,
            0.0000,    0.0000]], device='cuda:0') tensor([-111.6662], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.297210446217385 m 90.0 km/h 139.98931897214777 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0022382612867606 -500 -6.275282134413986 -141.61965776347228 0.0
reward =  -648.8971781591731 

state, action, next_state, reward =  tensor([[   3.0000,   50.1278,    8.9171,    0.0000,    0.0000, 1026.1458,
            0.0000,    0.0000]], device='cuda:0') tensor([[5]], device='cuda:0') None tensor([-648.8972], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -760.5633531071358
**************************************Episode 4 done**************************************

state_reset =  tensor([[ 4.0000, 49.1511, 10.3928,  0.6075,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.52010794542111 m 88.0 km/h 114.32924824002524 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.39784311813608975 40.0 -0.05578352139440738 -151.55995584050953 0.0
reward =  -111.21789624376785 

state, action, next_state, reward =  tensor([[ 4.0000, 49.1511, 10.3928,  0.6075,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   49.3274,   10.1677,    0.0000,    0.0000, 1044.0044,
            0.0000,    0.0000]], device='cuda:0') tensor([-111.2179], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.2154781807228 m 96.0 km/h 120.87722145510914 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2925169687383156 -500 -27.0 -142.1041515227385 0.0
reward =  -668.8116345540002 

state, action, next_state, reward =  tensor([[   3.0000,   49.3274,   10.1677,    0.0000,    0.0000, 1044.0044,
            0.0000,    0.0000]], device='cuda:0') tensor([[12]], device='cuda:0') None tensor([-668.8116], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -780.0295307977681
**************************************Episode 5 done**************************************

state_reset =  tensor([[ 4.0000, 49.7921,  9.9272,  0.2187,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 27.066034983002176 m 86.00000000000001 km/h 138.27372609468196 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0723774231707317 40.0 -0.015506806223410538 -150.6700318675805 0.0
reward =  -109.61316125063317 

state, action, next_state, reward =  tensor([[ 4.0000, 49.7921,  9.9272,  0.2187,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   50.0031,   10.1158,    0.0000,    0.0000, 1132.9968,
            0.0000,    0.0000]], device='cuda:0') tensor([-109.6132], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.147067968258952 m 83.00000000000001 km/h 114.98374636310443 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9867850143468717 -500 -27.0 -139.7628698572513 0.0
reward =  -667.7496548715982 

state, action, next_state, reward =  tensor([[   3.0000,   50.0031,   10.1158,    0.0000,    0.0000, 1132.9968,
            0.0000,    0.0000]], device='cuda:0') tensor([[20]], device='cuda:0') None tensor([-667.7497], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -777.3628161222314
**************************************Episode 6 done**************************************

state_reset =  tensor([[ 4.0000, 49.3626, 11.2533,  0.4601,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.50449149349504 m 86.0 km/h 135.73676709449535 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5420884285682789 40.0 -27.0 -151.32370123528116 0.0
reward =  -138.86578966384945 

state, action, next_state, reward =  tensor([[ 4.0000, 49.3626, 11.2533,  0.4601,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 4.9309e+01, 1.0911e+01, 4.0124e-01, 2.7000e+03, 1.0676e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-138.8658], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 27.168053879456373 m 96.0 km/h 132.9323312866671 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9479497220703424 40.0 -0.003981990168293831 -141.13568103048502 0.0
reward =  -100.19171329858297 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9309e+01, 1.0911e+01, 4.0124e-01, 2.7000e+03, 1.0676e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9470e+01, 1.1192e+01, 3.0000e-01, 0.0000e+00, 2.0864e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-100.1917], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.26342419243729 m 86.0 km/h 145.57712252239045 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7745855131351109 40.0 -0.5200084872175194 -130.56029415923217 0.0
reward =  -91.85488815958479 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9470e+01, 1.1192e+01, 3.0000e-01, 0.0000e+00, 2.0864e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 4.9262e+01, 1.1332e+01, 3.0000e-01, 2.6480e+03, 3.1440e+03,
         0.0000e+00, 2.6480e+03]], device='cuda:0') tensor([-91.8549], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.26342419243729 m 88.0 km/h 114.32821651432155 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7745855131351109 40.0 -0.1304549151314677 -120.22525698959875 0.0
reward =  -79.5811263915951 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9262e+01, 1.1332e+01, 3.0000e-01, 2.6480e+03, 3.1440e+03,
         0.0000e+00, 2.6480e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9470e+01, 1.1192e+01, 8.0000e-01, 5.2835e+04, 4.1775e+03,
         0.0000e+00, 2.9609e+03]], device='cuda:0') tensor([-79.5811], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.53429725872397 m 86.0 km/h 131.68678062278286 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.019676874708822 40.0 -0.04428141258253995 -109.53648139292359 0.0
reward =  -70.60043968021495 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9470e+01, 1.1192e+01, 8.0000e-01, 5.2835e+04, 4.1775e+03,
         0.0000e+00, 2.9609e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9248e+01, 1.1104e+01, 3.0000e-01, 0.0000e+00, 5.2464e+03,
         0.0000e+00, 2.9609e+03]], device='cuda:0') tensor([-70.6004], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.262820201555737 m 82.0 km/h 116.18155123120475 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9588120071860752 40.0 -0.4826637518704793 -98.44548715809425 0.0
reward =  -57.96933890277866 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9248e+01, 1.1104e+01, 3.0000e-01, 0.0000e+00, 5.2464e+03,
         0.0000e+00, 2.9609e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9475e+01, 1.1104e+01, 3.0000e-01, 7.0442e+02, 6.3555e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([-57.9693], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.243433860255948 m 83.99999999999999 km/h 142.30241868599273 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6894056261958077 40.0 -0.4826637518704793 -87.62687264655598 -0.0
reward =  -47.42013077223065 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9475e+01, 1.1104e+01, 3.0000e-01, 7.0442e+02, 6.3555e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9574e+01, 1.1419e+01, 2.3891e-01, 0.0000e+00, 7.4373e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([-47.4201], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.09374756331435 m 80.99999999999999 km/h 105.02391466519394 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.885119930955813 40.0 -0.4826637518704793 -76.4740959517496 -81.0
reward =  -118.84187963457589 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9574e+01, 1.1419e+01, 2.3891e-01, 0.0000e+00, 7.4373e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9414e+01, 1.1175e+01, 1.9409e-01, 0.0000e+00, 8.5526e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([-118.8419], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.039578210934657 m 82.0 km/h 132.98509886922386 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2765459732051613 40.0 -0.4826637518704793 -65.48111039572952 -270.0
reward =  -296.24032012080517 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9414e+01, 1.1175e+01, 1.9409e-01, 0.0000e+00, 8.5526e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 4.9296e+01, 1.1469e+01, 1.3746e-01, 0.0000e+00, 9.6519e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([-296.2403], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.199375852432496 m 98.0 km/h 144.09248242033658 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.48055954437416515 11.649693915924875 -0.4826637518704793 -56.224196817284934 -243.0
reward =  -288.5377261976047 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9296e+01, 1.1469e+01, 1.3746e-01, 0.0000e+00, 9.6519e+03,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9244e+01, 1.1131e+01, 7.5704e-02, 0.0000e+00, 1.0578e+04,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([-288.5377], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.006626633366718 m 86.0 km/h 115.79760557818287 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7297533058899921 -93.47911806937476 -0.4826637518704793 -45.756306598666306 -81.0
reward =  -219.98833511402157 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9244e+01, 1.1131e+01, 7.5704e-02, 0.0000e+00, 1.0578e+04,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9449e+01, 1.0989e+01, 2.6458e-02, 0.0000e+00, 1.1624e+04,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([-219.9883], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 27.26371729195968 m 99.0 km/h 157.9923719108532 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9542891772553976 -500 -0.8128729782081332 -35.84222758340824 0.0
reward =  -535.7008113843609 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9449e+01, 1.0989e+01, 2.6458e-02, 0.0000e+00, 1.1624e+04,
         0.0000e+00, 3.6653e+03]], device='cuda:0') tensor([[0]], device='cuda:0') None tensor([-535.7008], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 12
Sum reward: -2045.7924993202046
**************************************Episode 7 done**************************************

state_reset =  tensor([[ 4.0000, 49.4880,  8.4719,  0.3857,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 27.072184279874026 m 100.0 km/h 198.5268244585187 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9882262772043864 40.0 -4.5644825959979975 -152.25401365924535 0.0
reward =  -115.83026997803896 

state, action, next_state, reward =  tensor([[ 4.0000, 49.4880,  8.4719,  0.3857,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9574e+01, 8.8230e+00, 8.0000e-01, 4.8654e+04, 9.7460e+02,
         0.0000e+00, 1.1829e+04]], device='cuda:0') tensor([-115.8303], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.687739549283492 m 94.0 km/h 106.80875759663255 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7993060306581972 40.0 -0.07533388512461761 -142.41615595951976 0.0
reward =  -103.29079587530256 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9574e+01, 8.8230e+00, 8.0000e-01, 4.8654e+04, 9.7460e+02,
         0.0000e+00, 1.1829e+04]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 4.9343e+01, 8.7965e+00, 0.0000e+00, 0.0000e+00, 1.9584e+03,
         0.0000e+00, 1.1829e+04]], device='cuda:0') tensor([-103.2908], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.240755478399123 m 89.0 km/h 139.76377379985374 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.409137965677802 -500 -4.5644825959979975 -132.20641217050436 -81.0
reward =  -717.3617568008245 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9343e+01, 8.7965e+00, 0.0000e+00, 0.0000e+00, 1.9584e+03,
         0.0000e+00, 1.1829e+04]], device='cuda:0') tensor([[18]], device='cuda:0') None tensor([-717.3618], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 3
Sum reward: -936.4828226541661
**************************************Episode 8 done**************************************

state_reset =  tensor([[ 4.0000, 50.1133,  8.6828,  0.2274,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.617356357969847 m 85.0 km/h 132.37956563947074 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.1998788881009957 40.0 -0.016971655780305753 -151.1502961307422 0.0
reward =  -111.36714667462348 

state, action, next_state, reward =  tensor([[ 4.0000, 50.1133,  8.6828,  0.2274,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   49.9092,    8.8492,    0.0000,    0.0000, 1084.9703,
            0.0000,    0.0000]], device='cuda:0') tensor([-111.3671], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.054715694886987 m 94.0 km/h 138.0953713494402 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8356963367600971 -500 -6.2459784964584255 -141.55487309865782 0.0
reward =  -646.9651552583562 

state, action, next_state, reward =  tensor([[   3.0000,   49.9092,    8.8492,    0.0000,    0.0000, 1084.9703,
            0.0000,    0.0000]], device='cuda:0') tensor([[5]], device='cuda:0') None tensor([-646.9652], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -758.3323019329796
**************************************Episode 9 done**************************************

state_reset =  tensor([[ 4.0000, 49.7803,  9.1776,  0.7569,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.033060461650997 m 94.0 km/h 142.032848524695 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.43345951948260886 40.0 -0.03964735895401444 -152.41287046149537 0.0
reward =  -112.01905830096678 

state, action, next_state, reward =  tensor([[ 4.0000, 49.7803,  9.1776,  0.7569,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 4.9994e+01, 9.0702e+00, 3.0000e-01, 0.0000e+00, 9.5871e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-112.0191], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.542627980101546 m 100.0 km/h 218.37982949933155 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.37659820984395687 40.0 -13.612812616177369 -143.2175243886588 0.0
reward =  -116.45373879499222 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9994e+01, 9.0702e+00, 3.0000e-01, 0.0000e+00, 9.5871e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9898e+01, 9.3943e+00, 3.0000e-01, 1.3387e+03, 1.8782e+03,
         0.0000e+00, 1.3387e+03]], device='cuda:0') tensor([-116.4537], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.646942826328498 m 96.0 km/h 142.15747267041758 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9259253011429939 40.0 -13.612812616177369 -133.59992082878563 0.0
reward =  -108.13865874610599 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9898e+01, 9.3943e+00, 3.0000e-01, 1.3387e+03, 1.8782e+03,
         0.0000e+00, 1.3387e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 4.9679e+01, 9.2861e+00, 2.3799e-01, 0.0000e+00, 2.8400e+03,
         0.0000e+00, 1.3387e+03]], device='cuda:0') tensor([-108.1387], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.646942826328498 m 98.0 km/h 159.11332415425116 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9259253011429939 40.0 -0.2465603573596964 -124.17859489258332 0.0
reward =  -83.49922994880002 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9679e+01, 9.2861e+00, 2.3799e-01, 0.0000e+00, 2.8400e+03,
         0.0000e+00, 1.3387e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9898e+01, 9.3943e+00, 3.0000e-01, 1.8544e+03, 3.7821e+03,
         0.0000e+00, 3.1931e+03]], device='cuda:0') tensor([-83.4992], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.55589440923714 m 100.0 km/h 96.1781857793163 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.37631939090577654 40.0 -0.5415107045894804 -114.97847290525795 0.0
reward =  -75.89630300075319 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9898e+01, 9.3943e+00, 3.0000e-01, 1.8544e+03, 3.7821e+03,
         0.0000e+00, 3.1931e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9995e+01, 9.0701e+00, 3.0000e-01, 5.8990e+02, 4.7022e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([-75.8963], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.03366027006237 m 98.0 km/h 167.69018577343937 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0012176700529898 40.0 -0.5415107045894804 -105.7824344387044 -243.0
reward =  -310.3251628133469 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9995e+01, 9.0701e+00, 3.0000e-01, 5.8990e+02, 4.7022e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9848e+01, 8.8048e+00, 2.2861e-01, 0.0000e+00, 5.6218e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([-310.3252], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.025181142828938 m 93.0 km/h 129.1738408458721 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.22036372516936156 40.0 -0.5415107045894804 -96.09526754470612 -270.0
reward =  -326.41641452412625 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9848e+01, 8.8048e+00, 2.2861e-01, 0.0000e+00, 5.6218e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 5.0049e+01, 8.6468e+00, 1.7363e-01, 0.0000e+00, 6.5905e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([-326.4164], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.025181142828938 m 84.0 km/h 137.08267019333417 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.22036372516936156 40.0 -0.5415107045894804 -85.37018991206514 -243.0
reward =  -289.132064341824 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0049e+01, 8.6468e+00, 1.7363e-01, 0.0000e+00, 6.5905e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9848e+01, 8.8048e+00, 1.1529e-01, 0.0000e+00, 7.6630e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([-289.1321], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.02155586972071 m 88.0 km/h 117.02706762137097 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0007247054489166 -2.845015053094624 -0.617511665416565 -75.13409887445212 0.0
reward =  -77.59590088751439 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9848e+01, 8.8048e+00, 1.1529e-01, 0.0000e+00, 7.6630e+03,
         0.0000e+00, 3.7830e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9994e+01, 9.0701e+00, 8.0000e-01, 1.0365e+04, 8.6866e+03,
         0.0000e+00, 3.9350e+03]], device='cuda:0') tensor([-77.5959], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.537024405623384 m 88.0 km/h 193.21038446939514 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.37640311909271174 40.0 -0.07160881240881833 -64.68713434487893 0.0
reward =  -24.382340038195032 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9994e+01, 9.0701e+00, 8.0000e-01, 1.0365e+04, 8.6866e+03,
         0.0000e+00, 3.9350e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 4.9898e+01, 9.3942e+00, 0.0000e+00, 0.0000e+00, 9.7313e+03,
         0.0000e+00, 3.9350e+03]], device='cuda:0') tensor([-24.3823], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.64192048967702 m 87.0 km/h 123.46825673627109 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9255160647258558 -500 -0.617511665416565 -54.07668448708153 -270.0
reward =  -825.6197122172239 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9898e+01, 9.3942e+00, 0.0000e+00, 0.0000e+00, 9.7313e+03,
         0.0000e+00, 3.9350e+03]], device='cuda:0') tensor([[16]], device='cuda:0') None tensor([-825.6197], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 11
Sum reward: -2349.478583613848
**************************************Episode 10 done**************************************

state_reset =  tensor([[ 5.0000, 52.3723, 10.6287,  0.3846,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.01376710576339 m 88.0 km/h 135.13718403848037 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9743852558755275 40.0 -27.0 -151.76709527491496 0.0
reward =  -137.79271001903945 

state, action, next_state, reward =  tensor([[ 5.0000, 52.3723, 10.6287,  0.3846,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.2227e+01, 1.0910e+01, 3.2711e-01, 0.0000e+00, 1.0233e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-137.7927], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.01376710576339 m 90.0 km/h 132.68209772643817 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9743852558755275 40.0 -27.0 -141.7615884326096 0.0
reward =  -129.73597368848513 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.2227e+01, 1.0910e+01, 3.2711e-01, 0.0000e+00, 1.0233e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 5.2372e+01, 1.0629e+01, 2.7067e-01, 8.1000e+02, 2.0238e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-129.7360], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.140123110912825 m 94.0 km/h 137.58069511819423 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0041489309340914 40.0 -27.0 -132.1334561773664 0.0
reward =  -120.1376051083005 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.2372e+01, 1.0629e+01, 2.7067e-01, 8.1000e+02, 2.0238e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 5.2490e+01, 1.0312e+01, 2.1185e-01, 2.4300e+03, 2.9867e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-120.1376], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.327098800782572 m 96.0 km/h 153.0602430841526 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5549166785990598 40.0 -0.014591927896154799 -122.63579412707296 0.0
reward =  -82.09546937637006 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.2490e+01, 1.0312e+01, 2.1185e-01, 2.4300e+03, 2.9867e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.2265e+01, 1.0368e+01, 0.0000e+00, 0.0000e+00, 3.9364e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-82.0955], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.297109978244183 m 98.0 km/h 149.62389467330684 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2581643281920592 -500 -27.0 -113.34297821669752 0.0
reward =  -640.0848138885054 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2265e+01, 1.0368e+01, 0.0000e+00, 0.0000e+00, 3.9364e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[12]], device='cuda:0') None tensor([-640.0848], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 5
Sum reward: -1109.8465720807005
**************************************Episode 11 done**************************************

state_reset =  tensor([[ 5.0000, 49.3660,  8.7434,  0.1089,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.020822712437052 m 88.0 km/h 89.05561194947805 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2607754135439149 5.2765396025773015 -0.2656105934093591 -151.76420889036666 0.0
reward =  -147.01405529474263 

state, action, next_state, reward =  tensor([[ 5.0000, 49.3660,  8.7434,  0.1089,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 4.9476e+01, 8.4415e+00, 3.0000e-01, 3.2312e+03, 1.0236e+03,
         0.0000e+00, 3.2312e+03]], device='cuda:0') tensor([-147.0141], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.38969697169037 m 80.0 km/h 130.23038955228398 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9956718168303953 40.0 -5.03538477417791 -140.338845253106 0.0
reward =  -104.37855821045352 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9476e+01, 8.4415e+00, 3.0000e-01, 3.2312e+03, 1.0236e+03,
         0.0000e+00, 3.2312e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9600e+01, 8.7371e+00, 8.0000e-01, 1.5699e+04, 2.1661e+03,
         0.0000e+00, 2.1965e+03]], device='cuda:0') tensor([-104.3786], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.004610014053032 m 90.0 km/h 127.11889479851715 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.80776562222288 40.0 -0.04459428845262866 -130.33700124748478 0.0
reward =  -91.1893611581603 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9600e+01, 8.7371e+00, 8.0000e-01, 1.5699e+04, 2.1661e+03,
         0.0000e+00, 2.1965e+03]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 4.9377e+01, 8.6879e+00, 3.0000e-01, 0.0000e+00, 3.1663e+03,
         0.0000e+00, 2.1965e+03]], device='cuda:0') tensor([-91.1894], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.259962546116725 m 89.0 km/h 129.99109971819047 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.06386421300273389 40.0 -0.14225919851630625 -120.1194883074825 0.0
reward =  -80.19788329299607 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9377e+01, 8.6879e+00, 3.0000e-01, 0.0000e+00, 3.1663e+03,
         0.0000e+00, 2.1965e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9548e+01, 8.4568e+00, 3.0000e-01, 7.8806e+02, 4.1881e+03,
         0.0000e+00, 2.9845e+03]], device='cuda:0') tensor([-80.1979], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.023652870909057 m 81.0 km/h 117.35642668487218 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7003788269542065 40.0 -0.14225919851630625 -108.9978648093007 -81.0
reward =  -149.4397451808628 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9548e+01, 8.4568e+00, 3.0000e-01, 7.8806e+02, 4.1881e+03,
         0.0000e+00, 2.9845e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9772e+01, 8.4728e+00, 2.5006e-01, 0.0000e+00, 5.3002e+03,
         0.0000e+00, 2.9845e+03]], device='cuda:0') tensor([-149.4397], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.015792379423225 m 87.0 km/h 131.19713724957882 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.700172573482974 40.0 -0.3322613349536041 -98.64650244540144 0.0
reward =  -59.67893635383802 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9772e+01, 8.4728e+00, 2.5006e-01, 0.0000e+00, 5.3002e+03,
         0.0000e+00, 2.9845e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 4.9548e+01, 8.4568e+00, 5.0000e-01, 1.2945e+04, 6.3353e+03,
         0.0000e+00, 3.3645e+03]], device='cuda:0') tensor([-59.6789], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.294450045706306 m 85.0 km/h 128.02603889521063 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.25986013848910805 40.0 -0.7208631243997506 -87.93355889663171 0.0
reward =  -48.91428215952057 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9548e+01, 8.4568e+00, 5.0000e-01, 1.2945e+04, 6.3353e+03,
         0.0000e+00, 3.3645e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9351e+01, 8.6322e+00, 5.0000e-01, 7.7720e+02, 7.4066e+03,
         0.0000e+00, 4.1417e+03]], device='cuda:0') tensor([-48.9143], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.294450045706306 m 97.0 km/h 148.67321338783083 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.25986013848910805 40.0 -3.147785307710401 -78.54592795183349 0.0
reward =  -41.43385312105478 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9351e+01, 8.6322e+00, 5.0000e-01, 7.7720e+02, 7.4066e+03,
         0.0000e+00, 4.1417e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9548e+01, 8.4568e+00, 8.0000e-01, 1.5408e+04, 8.3454e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-41.4339], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.549590806623108 m 90.0 km/h 137.8419503075748 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7590019778718939 40.0 -3.147785307710401 -68.32609162918425 -0.0
reward =  -32.232878914766545 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9548e+01, 8.4568e+00, 8.0000e-01, 1.5408e+04, 8.3454e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9318e+01, 8.4353e+00, 7.4011e-01, 0.0000e+00, 9.3674e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-32.2329], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.07433692294893 m 81.0 km/h 115.74868371203951 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6914166350212809 40.0 -3.147785307710401 -62.955706154208016 -243.0
reward =  -268.41207482689714 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9318e+01, 8.4353e+00, 7.4011e-01, 0.0000e+00, 9.3674e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9544e+01, 8.4303e+00, 6.9075e-01, 0.0000e+00, 5.7738e+02,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-268.4121], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.937438519772208 m 91.0 km/h 140.5394478479543 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.191846588304732 40.0 -0.012875237741006828 -145.96527104230267 0.0
reward =  -106.16999286834842 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9544e+01, 8.4303e+00, 6.9075e-01, 0.0000e+00, 5.7738e+02,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9351e+01, 8.6322e+00, 5.0000e-01, 0.0000e+00, 1.6035e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-106.1700], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.222636832195196 m 98.0 km/h 155.3062238685213 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8112912903848477 40.0 -3.147785307710401 -136.69981261414935 -243.0
reward =  -343.6588892122446 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9351e+01, 8.6322e+00, 5.0000e-01, 0.0000e+00, 1.6035e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9125e+01, 8.5981e+00, 4.3338e-01, 0.0000e+00, 2.5300e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-343.6589], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.713823568957775 m 85.00000000000001 km/h 122.41118328979555 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.348431061446704 40.0 -3.147785307710401 -125.80925204376723 -243.0
reward =  -331.60860629003093 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9125e+01, 8.5981e+00, 4.3338e-01, 0.0000e+00, 2.5300e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9330e+01, 8.4346e+00, 3.7985e-01, 0.0000e+00, 3.6191e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-331.6086], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.140771146241693 m 100.0 km/h 162.62066501738678 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7685602636245801 40.0 -3.147785307710401 -116.75857443112024 -81.0
reward =  -160.13779947520607 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9330e+01, 8.4346e+00, 3.7985e-01, 0.0000e+00, 3.6191e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9356e+01, 8.7793e+00, 3.1032e-01, 0.0000e+00, 4.5241e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-160.1378], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.377907506971273 m 87.0 km/h 125.34549903312684 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.04637864141071215 40.0 -0.025621926095023683 -106.25737132478729 0.0
reward =  -66.32937189229301 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9356e+01, 8.7793e+00, 3.1032e-01, 0.0000e+00, 4.5241e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 4.9507e+01, 8.5163e+00, 0.0000e+00, 0.0000e+00, 5.5743e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([-66.3294], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.18497563118593 m 82.0 km/h 143.42188681196407 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7739045682085631 -500 -3.147785307710401 -95.20055275499836 -0.0
reward =  -597.5744334945002 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9507e+01, 8.5163e+00, 0.0000e+00, 0.0000e+00, 5.5743e+03,
         0.0000e+00, 8.9956e+03]], device='cuda:0') tensor([[12]], device='cuda:0') None tensor([-597.5744], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 16
Sum reward: -2628.370721745915
**************************************Episode 12 done**************************************

state_reset =  tensor([[ 5.0000, 49.0622, 13.0695,  0.7257,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 29.91130984623253 m 82.0 km/h 89.69611250078908 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.025815435782224 40.0 -27.0 -148.86820543336134 0.0
reward =  -134.84238999757912 

state, action, next_state, reward =  tensor([[ 5.0000, 49.0622, 13.0695,  0.7257,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9273e+01, 1.2815e+01, 6.8007e-01, 2.7000e+03, 1.3132e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-134.8424], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 30.838148096757422 m 87.0 km/h 144.3438170324692 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.1611492250876687 40.0 -0.030437000273859097 -136.10759242780654 0.0
reward =  -97.29917865316807 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9273e+01, 1.2815e+01, 6.8007e-01, 2.7000e+03, 1.3132e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9025e+01, 1.3004e+01, 3.0000e-01, 0.0000e+00, 2.5892e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-97.2992], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 28.28756933305686 m 99.0 km/h 167.71786652627574 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8556813135501556 40.0 -27.0 -125.82120357942222 0.0
reward =  -111.96552226587207 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9025e+01, 1.3004e+01, 3.0000e-01, 0.0000e+00, 2.5892e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9199e+01, 1.2720e+01, 2.1931e-01, 8.1000e+02, 3.6179e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-111.9655], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 26.817971633112666 m 84.0 km/h 101.59148348235549 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.27699930986408844 40.0 -27.0 -114.32778716523107 0.0
reward =  -101.05078785536699 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9199e+01, 1.2720e+01, 2.1931e-01, 8.1000e+02, 3.6179e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 4.9254e+01, 1.2360e+01, 1.7298e-01, 8.1000e+02, 4.7672e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-101.0508], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 28.89239234462803 m 83.00000000000001 km/h 144.967627168278 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.1536407350720408 40.0 -0.3231450404173011 -101.79614711213941 0.0
reward =  -60.96565141748467 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9254e+01, 1.2360e+01, 1.7298e-01, 8.1000e+02, 4.7672e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 4.9513e+01, 1.2342e+01, 5.0000e-01, 3.5126e+04, 6.0204e+03,
         0.0000e+00, 3.3463e+03]], device='cuda:0') tensor([-60.9657], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 26.511665785374976 m 82.0 km/h 86.0918055398749 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8747450749615405 40.0 -0.01611830412358392 -90.15687920636503 0.0
reward =  -51.04774258545016 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9513e+01, 1.2342e+01, 5.0000e-01, 3.5126e+04, 6.0204e+03,
         0.0000e+00, 3.3463e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9323e+01, 1.2122e+01, 3.0000e-01, 0.0000e+00, 7.1843e+03,
         0.0000e+00, 3.3463e+03]], device='cuda:0') tensor([-51.0477], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 26.511665785374976 m 98.0 km/h 187.1652472431168 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8747450749615405 40.0 -26.524061906723254 -80.4178999382681 0.0
reward =  -66.06721677002983 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9323e+01, 1.2122e+01, 3.0000e-01, 0.0000e+00, 7.1843e+03,
         0.0000e+00, 3.3463e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9513e+01, 1.2342e+01, 3.0000e-01, 7.4431e+03, 8.1582e+03,
         0.0000e+00, 4.7594e+01]], device='cuda:0') tensor([-66.0672], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 26.54495786757106 m 82.0 km/h 87.8249416742281 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0574532931003942 40.0 -26.524061906723254 -68.76401599640764 0.0
reward =  -56.345531196231285 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9513e+01, 1.2342e+01, 3.0000e-01, 7.4431e+03, 8.1582e+03,
         0.0000e+00, 4.7594e+01]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9276e+01, 1.2301e+01, 2.6035e-01, 2.3872e+03, 9.3236e+03,
         0.0000e+00, 4.7594e+01]], device='cuda:0') tensor([-56.3455], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.432364120203804 m 88.99999999999999 km/h 139.3667886227909 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6791905359207012 40.0 -0.7900852595817451 -58.476767588235305 0.0
reward =  -18.587662311896345 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9276e+01, 1.2301e+01, 2.6035e-01, 2.3872e+03, 9.3236e+03,
         0.0000e+00, 4.7594e+01]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 4.9438e+01, 1.2054e+01, 5.0000e-01, 4.2326e+03, 1.0352e+04,
         0.0000e+00, 4.2802e+03]], device='cuda:0') tensor([-18.5877], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.643755650704225 m 80.0 km/h 103.68057788785477 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0252569508376217 40.0 -0.7900852595817451 -46.9370775454184 -162.0
reward =  -170.75241975583776 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9438e+01, 1.2054e+01, 5.0000e-01, 4.2326e+03, 1.0352e+04,
         0.0000e+00, 4.2802e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9208e+01, 1.2033e+01, 4.5478e-01, 0.0000e+00, 1.1506e+04,
         0.0000e+00, 4.2802e+03]], device='cuda:0') tensor([-170.7524], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.17241369212242 m 100.0 km/h 183.6429481767104 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.22733477121038595 40.0 -0.7900852595817451 -37.87500861625433 -162.0
reward =  -160.89242864704647 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9208e+01, 1.2033e+01, 4.5478e-01, 0.0000e+00, 1.1506e+04,
         0.0000e+00, 4.2802e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9186e+01, 1.1688e+01, 3.7617e-01, 0.0000e+00, 1.2412e+04,
         0.0000e+00, 4.2802e+03]], device='cuda:0') tensor([-160.8924], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 26.364128112419966 m 80.0 km/h 131.09533802345038 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0380033856743807 40.0 -2.0051032950323644 -26.011150965665347 0.0
reward =  13.021749124976669 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9186e+01, 1.1688e+01, 3.7617e-01, 0.0000e+00, 1.2412e+04,
         0.0000e+00, 4.2802e+03]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 4.9423e+01, 1.1688e+01, 5.0000e-01, 7.7312e+03, 1.3599e+04,
         0.0000e+00, 6.7102e+03]], device='cuda:0') tensor([13.0217], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.641252731473195 m 91.0 km/h 110.82532462892102 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.47904333669522425 40.0 -12.90908506501808 -151.856207710626 0.0
reward =  -124.28624943894886 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9423e+01, 1.1688e+01, 5.0000e-01, 7.7312e+03, 1.3599e+04,
         0.0000e+00, 6.7102e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9574e+01, 1.1419e+01, 4.5167e-01, 7.7455e+02, 1.0144e+03,
         0.0000e+00, 1.4091e+03]], device='cuda:0') tensor([-124.2862], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.383425173682507 m 92.00000000000001 km/h 126.03932360105152 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8959224576908921 40.0 -0.009726173643832364 -141.92356307744586 0.0
reward =  -102.82921170878059 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9574e+01, 1.1419e+01, 4.5167e-01, 7.7455e+02, 1.0144e+03,
         0.0000e+00, 1.4091e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9412e+01, 1.1172e+01, 3.0000e-01, 0.0000e+00, 2.0076e+03,
         0.0000e+00, 1.4091e+03]], device='cuda:0') tensor([-102.8292], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.37335894571492 m 94.0 km/h 150.72536409129128 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9567162542968244 40.0 -2.483607463822474 -132.20610645993804 0.0
reward =  -95.64643017805733 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9412e+01, 1.1172e+01, 3.0000e-01, 0.0000e+00, 2.0076e+03,
         0.0000e+00, 1.4091e+03]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 4.9184e+01, 1.1187e+01, 3.0000e-01, 6.2581e+03, 2.9794e+03,
         0.0000e+00, 7.6672e+03]], device='cuda:0') tensor([-95.6464], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.02801045734479 m 99.0 km/h 165.60607731597992 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9726220146048651 40.0 -2.483607463822474 -123.1050117481763 -243.0
reward =  -327.6159971973939 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9184e+01, 1.1187e+01, 3.0000e-01, 6.2581e+03, 2.9794e+03,
         0.0000e+00, 7.6672e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9380e+01, 1.1357e+01, 2.2951e-01, 0.0000e+00, 3.8895e+03,
         0.0000e+00, 7.6672e+03]], device='cuda:0') tensor([-327.6160], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.027902341904053 m 99.0 km/h 136.38811184295548 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5008494539422867 40.0 -2.483607463822474 -114.00395635112028 -81.0
reward =  -157.98841326888504 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9380e+01, 1.1357e+01, 2.2951e-01, 0.0000e+00, 3.8895e+03,
         0.0000e+00, 7.6672e+03]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 4.9330e+01, 1.1020e+01, 1.7146e-01, 0.0000e+00, 4.7996e+03,
         0.0000e+00, 7.6672e+03]], device='cuda:0') tensor([-157.9884], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.63567452876551 m 85.99999999999999 km/h 144.0969174284866 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5109217819464719 40.0 -3.833885942357848 -103.27274375768354 0.0
reward =  -67.61755148198786 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9330e+01, 1.1020e+01, 1.7146e-01, 0.0000e+00, 4.7996e+03,
         0.0000e+00, 7.6672e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9161e+01, 1.1260e+01, 3.0000e-01, 2.7006e+03, 5.8727e+03,
         0.0000e+00, 1.0368e+04]], device='cuda:0') tensor([-67.6176], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.085994400262877 m 84.0 km/h 114.51819350577858 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4161614896963071 40.0 -7.725157826837021 -92.52160330042803 0.0
reward =  -59.83059963756874 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9161e+01, 1.1260e+01, 3.0000e-01, 2.7006e+03, 5.8727e+03,
         0.0000e+00, 1.0368e+04]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 4.9311e+01, 1.1002e+01, 5.0000e-01, 3.5119e+03, 6.9478e+03,
         0.0000e+00, 1.9275e+03]], device='cuda:0') tensor([-59.8306], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.087214381187106 m 92.00000000000001 km/h 149.6585280908277 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4162691725192824 40.0 -0.04361476942485118 -82.70486723822438 0.0
reward =  -43.164751180168516 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9311e+01, 1.1002e+01, 5.0000e-01, 3.5119e+03, 6.9478e+03,
         0.0000e+00, 1.9275e+03]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 4.9161e+01, 1.1260e+01, 0.0000e+00, 0.0000e+00, 7.9295e+03,
         0.0000e+00, 1.9275e+03]], device='cuda:0') tensor([-43.1648], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.55730813162705 m 95.0 km/h 139.98846054777505 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3272867368294834 -500 -4.258697878749677 -73.01999257781834 0.0
reward =  -576.9514037197386 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9161e+01, 1.1260e+01, 0.0000e+00, 0.0000e+00, 7.9295e+03,
         0.0000e+00, 1.9275e+03]], device='cuda:0') tensor([[5]], device='cuda:0') None tensor([-576.9514], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 21
Sum reward: -2572.7253901425156
**************************************Episode 13 done**************************************

state_reset =  tensor([[ 4.0000, 50.1265,  8.9347,  0.2641,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.079643860814738 m 87.0 km/h 131.19394116291556 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.97433691771972 40.0 -14.03516029805537 -151.62221633345598 0.0
reward =  -126.63171354923107 

state, action, next_state, reward =  tensor([[ 4.0000, 50.1265,  8.9347,  0.2641,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.0034e+01, 8.6139e+00, 3.0000e-01, 1.2965e+03, 1.0378e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([-126.6317], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.060777432499528 m 83.00000000000001 km/h 134.11312767506018 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.13743788599376566 40.0 -14.03516029805537 -140.75248154345618 0.0
reward =  -114.92507972750532 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0034e+01, 8.6139e+00, 3.0000e-01, 1.2965e+03, 1.0378e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9843e+01, 8.7979e+00, 2.4284e-01, 0.0000e+00, 2.1248e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([-114.9251], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.01772516511574 m 84.0 km/h 114.31251365545823 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8592859361215541 40.0 -14.03516029805537 -130.03059932983516 0.0
reward =  -103.20647369176898 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9843e+01, 8.7979e+00, 2.4284e-01, 0.0000e+00, 2.1248e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 5.0056e+01, 8.9099e+00, 1.9420e-01, 4.2105e+02, 3.1969e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([-103.2065], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 26.466052528656757 m 92.00000000000001 km/h 138.9849109406541 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7856741207451373 40.0 -0.01316462543086241 -119.67431790557815 0.0
reward =  -78.90180841026387 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0056e+01, 8.9099e+00, 1.9420e-01, 4.2105e+02, 3.1969e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.0290e+01, 8.9764e+00, 0.0000e+00, 0.0000e+00, 4.2326e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([-78.9018], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.1307966966879 m 99.0 km/h 152.70972886964094 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9490923857870698 -500 -4.387027840060279 -110.53584637950982 0.0
reward =  -615.8719666053572 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0290e+01, 8.9764e+00, 0.0000e+00, 0.0000e+00, 4.2326e+03,
         0.0000e+00, 1.2965e+03]], device='cuda:0') tensor([[10]], device='cuda:0') None tensor([-615.8720], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 5
Sum reward: -1039.5370419841265
**************************************Episode 14 done**************************************

state_reset =  tensor([[ 5.0000, 49.0358,  8.7096,  0.6629,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.95653543191898 m 97.0 km/h 148.72297825954325 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0184347385552666 40.0 -0.059727531664220235 -152.36664664382388 0.0
reward =  -111.40793943693285 

state, action, next_state, reward =  tensor([[ 5.0000, 49.0358,  8.7096,  0.6629,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[  3.0000,  49.2410,   8.8799,   0.0000,   0.0000, 963.3353,   0.0000,
           0.0000]], device='cuda:0') tensor([-111.4079], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.486540714544475 m 86.0 km/h 127.11704738582038 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.44993657342535676 -500 -27.0 -141.69786215866574 0.0
reward =  -668.2479255852404 

state, action, next_state, reward =  tensor([[  3.0000,  49.2410,   8.8799,   0.0000,   0.0000, 963.3353,   0.0000,
           0.0000]], device='cuda:0') tensor([[17]], device='cuda:0') None tensor([-668.2479], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -779.6558650221732
**************************************Episode 15 done**************************************

state_reset =  tensor([[ 4.0000, 49.8947, 10.8888,  0.4820,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.12619394577428 m 90.0 km/h 160.72782845327782 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.05095319190830807 40.0 -27.0 -151.9495224216903 0.0
reward =  -138.89856922978197 

state, action, next_state, reward =  tensor([[ 4.0000, 49.8947, 10.8888,  0.4820,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9815e+01, 1.1217e+01, 4.1334e-01, 2.7000e+03, 1.0050e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-138.8986], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.009141168239015 m 98.0 km/h 125.19037650926771 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.06794772651904496 40.0 -27.0 -142.7624909721331 0.0
reward =  -129.83043869865213 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9815e+01, 1.1217e+01, 4.1334e-01, 2.7000e+03, 1.0050e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 4.9891e+01, 1.0888e+01, 3.6010e-01, 0.0000e+00, 1.9238e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-129.8304], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 27.345925642227815 m 95.00000000000001 km/h 155.82303163189118 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0087228148564127 40.0 -5.879771134468723 -132.3998244129731 0.0
reward =  -99.28831836229823 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9891e+01, 1.0888e+01, 3.6010e-01, 0.0000e+00, 1.9238e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9733e+01, 1.0595e+01, 8.0000e-01, 4.9300e+04, 2.9600e+03,
         0.0000e+00, 1.4460e+04]], device='cuda:0') tensor([-99.2883], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.47379388933047 m 85.00000000000001 km/h 140.6921682316274 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5653237501429068 40.0 -5.879771134468723 -121.61092347160961 -243.0
reward =  -331.0560183562212 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9733e+01, 1.0595e+01, 8.0000e-01, 4.9300e+04, 2.9600e+03,
         0.0000e+00, 1.4460e+04]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9535e+01, 1.0772e+01, 7.3905e-01, 0.0000e+00, 4.0389e+03,
         0.0000e+00, 1.4460e+04]], device='cuda:0') tensor([-331.0560], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.533923559984835 m 91.0 km/h 121.95619729823278 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.66949698084826 40.0 -10.924839564348026 -117.59542268937446 0.0
reward =  -87.85076527287423 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9535e+01, 1.0772e+01, 7.3905e-01, 0.0000e+00, 4.0389e+03,
         0.0000e+00, 1.4460e+04]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9746e+01, 1.0634e+01, 8.0000e-01, 1.6075e+03, 6.0858e+02,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([-87.8508], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.078772621749238 m 97.0 km/h 150.62420215866413 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.1029312469591829 40.0 -10.924839564348026 -146.60658266959013 0.0
reward =  -117.63435348089733 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9746e+01, 1.0634e+01, 8.0000e-01, 1.6075e+03, 6.0858e+02,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9629e+01, 1.0931e+01, 7.3576e-01, 6.5549e+02, 1.5393e+03,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([-117.6344], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.168906190650294 m 85.0 km/h 131.60067549902783 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6472335874238762 40.0 -0.03794266126950549 -135.94681063590295 0.0
reward =  -96.63198688459633 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9629e+01, 1.0931e+01, 7.3576e-01, 6.5549e+02, 1.5393e+03,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9431e+01, 1.1101e+01, 3.0000e-01, 0.0000e+00, 2.6053e+03,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([-96.6320], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.16079410763618 m 94.0 km/h 161.83507654656447 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5243189840564993 40.0 -0.023075001632003996 -126.31076182872312 0.0
reward =  -86.85815581441162 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9431e+01, 1.1101e+01, 3.0000e-01, 0.0000e+00, 2.6053e+03,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 4.9262e+01, 1.1332e+01, 0.0000e+00, 0.0000e+00, 3.5689e+03,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([-86.8582], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.123550721043525 m 86.0 km/h 117.2829545720509 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6284049436652963 -500 -1.9241457327311702 -115.79392664317001 0.0
reward =  -618.3464773195665 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9262e+01, 1.1332e+01, 0.0000e+00, 0.0000e+00, 3.5689e+03,
         0.0000e+00, 1.6075e+03]], device='cuda:0') tensor([[1]], device='cuda:0') None tensor([-618.3465], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 9
Sum reward: -1706.3950834192995
**************************************Episode 16 done**************************************

state_reset =  tensor([[ 5.0000, 49.9242,  8.9997,  0.6203,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.02584871833364 m 88.0 km/h 131.01252212048996 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8802373760424834 40.0 -27.0 -151.76215279704533 0.0
reward =  -139.64239017308782 

state, action, next_state, reward =  tensor([[ 5.0000, 49.9242,  8.9997,  0.6203,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9875e+01, 8.6588e+00, 5.6449e-01, 1.6200e+03, 1.0238e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-139.6424], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.748496971952765 m 88.0 km/h 140.62048407938494 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.37172514061683093 40.0 -4.938667800946157 -141.22867676306464 0.0
reward =  -106.53906970462762 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9875e+01, 8.6588e+00, 5.6449e-01, 1.6200e+03, 1.0238e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9659e+01, 8.7873e+00, 8.0000e-01, 1.2577e+04, 2.0771e+03,
         0.0000e+00, 1.2577e+04]], device='cuda:0') tensor([-106.5391], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.6
Length, speed, consumption 25.004812736855353 m 82.0 km/h 104.11648612762569 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9087079637731635 40.0 -4.938667800946157 -130.25095409810376 -162.0
reward =  -258.0983298628231 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9659e+01, 8.7873e+00, 8.0000e-01, 1.2577e+04, 2.0771e+03,
         0.0000e+00, 1.2577e+04]], device='cuda:0') tensor([[14]], device='cuda:0') tensor([[4.0000e+00, 4.9448e+01, 8.6670e+00, 7.5572e-01, 0.0000e+00, 3.1749e+03,
         0.0000e+00, 1.2577e+04]], device='cuda:0') tensor([-258.0983], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.476100091811897 m 100.0 km/h 154.8019352876574 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5529672162736161 40.0 -0.038865369326130564 -121.07955806505147 0.0
reward =  -80.56545621810399 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9448e+01, 8.6670e+00, 7.5572e-01, 0.0000e+00, 3.1749e+03,
         0.0000e+00, 1.2577e+04]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9673e+01, 8.5974e+00, 3.0000e-01, 0.0000e+00, 4.0920e+03,
         0.0000e+00, 1.2577e+04]], device='cuda:0') tensor([-80.5655], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.812918065118144 m 83.00000000000001 km/h 125.77424916412009 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5360625588723296 40.0 -5.3282598475511795 -109.88359360307253 0.0
reward =  -75.74791600949604 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9673e+01, 8.5974e+00, 3.0000e-01, 0.0000e+00, 4.0920e+03,
         0.0000e+00, 1.2577e+04]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9446e+01, 8.6779e+00, 3.0000e-01, 7.7918e+02, 5.2116e+03,
         0.0000e+00, 1.3357e+04]], device='cuda:0') tensor([-75.7479], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.00921734451283 m 100.0 km/h 175.38468793996216 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.09884214030836942 40.0 -5.3282598475511795 -106.56519695102357 -81.0
reward =  -152.99229893888312 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9446e+01, 8.6779e+00, 3.0000e-01, 7.7918e+02, 5.2116e+03,
         0.0000e+00, 1.3357e+04]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9280e+01, 8.9096e+00, 2.2540e-01, 0.0000e+00, 5.6849e+02,
         0.0000e+00, 1.3357e+04]], device='cuda:0') tensor([-152.9923], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.20420408032587 m 85.0 km/h 106.67311389444933 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5250289875634178 40.0 -15.136277801961478 -145.64035667988634 0.0
reward =  -121.30166346941124 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9280e+01, 8.9096e+00, 2.2540e-01, 0.0000e+00, 5.6849e+02,
         0.0000e+00, 1.3357e+04]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9321e+01, 8.5678e+00, 3.0000e-01, 5.0939e+03, 1.6360e+03,
         0.0000e+00, 1.1864e+03]], device='cuda:0') tensor([-121.3017], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.45895841502091 m 84.0 km/h 121.80162973019127 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4847976223279606 40.0 -3.1579154206114755 -134.3008030734488 0.0
reward =  -96.97392087173232 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9321e+01, 8.5678e+00, 3.0000e-01, 5.0939e+03, 1.6360e+03,
         0.0000e+00, 1.1864e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9548e+01, 8.4568e+00, 8.0000e-01, 7.8295e+03, 2.7699e+03,
         0.0000e+00, 9.0158e+03]], device='cuda:0') tensor([-96.9739], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.023652870909057 m 92.00000000000001 km/h 138.74700368827442 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7003788269542065 40.0 -3.1579154206114755 -124.50893890657134 -81.0
reward =  -167.96647550022863 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9548e+01, 8.4568e+00, 8.0000e-01, 7.8295e+03, 2.7699e+03,
         0.0000e+00, 9.0158e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9772e+01, 8.4728e+00, 7.4095e-01, 0.0000e+00, 3.7491e+03,
         0.0000e+00, 9.0158e+03]], device='cuda:0') tensor([-167.9665], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.015792379423225 m 90.0 km/h 137.16581638189965 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.700172573482974 40.0 -0.01825974754874523 -114.50262195480205 0.0
reward =  -75.22105427583378 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9772e+01, 8.4728e+00, 7.4095e-01, 0.0000e+00, 3.7491e+03,
         0.0000e+00, 9.0158e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 4.9548e+01, 8.4568e+00, 5.0000e-01, 0.0000e+00, 4.7497e+03,
         0.0000e+00, 9.0158e+03]], device='cuda:0') tensor([-75.2211], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.281441039604147 m 86.00000000000001 km/h 129.77170708393376 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.25943193115534496 40.0 -4.14342443728563 -103.9196931475259 0.0
reward =  -68.32254951596688 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9548e+01, 8.4568e+00, 5.0000e-01, 0.0000e+00, 4.7497e+03,
         0.0000e+00, 9.0158e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9351e+01, 8.6322e+00, 8.0000e-01, 1.5063e+04, 5.8080e+03,
         0.0000e+00, 1.0987e+04]], device='cuda:0') tensor([-68.3225], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.222636832195196 m 83.00000000000001 km/h 124.78840118631585 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8112912903848477 40.0 -4.14342443728563 -92.97975428054968 -81.0
reward =  -138.93447000822016 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9351e+01, 8.6322e+00, 8.0000e-01, 1.5063e+04, 5.8080e+03,
         0.0000e+00, 1.0987e+04]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9125e+01, 8.5981e+00, 7.4647e-01, 0.0000e+00, 6.9020e+03,
         0.0000e+00, 1.0987e+04]], device='cuda:0') tensor([-138.9345], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.123819189923708 m 92.00000000000001 km/h 137.68060223493868 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8838772770482698 40.0 -11.424473658615934 -83.14869459753605 0.0
reward =  -53.68929097910372 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9125e+01, 8.5981e+00, 7.4647e-01, 0.0000e+00, 6.9020e+03,
         0.0000e+00, 1.0987e+04]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9345e+01, 8.6789e+00, 8.0000e-01, 1.5856e+03, 7.8851e+03,
         0.0000e+00, 1.5576e+03]], device='cuda:0') tensor([-53.6893], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.446740264626236 m 98.0 km/h 156.88729866704568 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0219034724361893 40.0 -1.4664953258170499 -73.43356552073458 0.0
reward =  -33.87815737411544 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9345e+01, 8.6789e+00, 8.0000e-01, 1.5856e+03, 7.8851e+03,
         0.0000e+00, 1.5576e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9473e+01, 8.9868e+00, 8.0000e-01, 9.9580e+02, 8.8566e+03,
         0.0000e+00, 2.5534e+03]], device='cuda:0') tensor([-33.8782], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.08453147741773 m 92.00000000000001 km/h 134.63655354202587 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.49764057390813715 40.0 -1.4664953258170499 -63.61787929044069 0.0
reward =  -25.582015190165876 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9473e+01, 8.9868e+00, 8.0000e-01, 9.9580e+02, 8.8566e+03,
         0.0000e+00, 2.5534e+03]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 4.9527e+01, 8.6496e+00, 7.4256e-01, 1.4665e+02, 9.8382e+03,
         0.0000e+00, 2.5534e+03]], device='cuda:0') tensor([-25.5820], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.615059651452974 m 91.0 km/h 138.64554281985215 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7758588108512899 40.0 -0.7581202795180967 -53.484449098657095 0.0
reward =  -15.01842818902648 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9527e+01, 8.6496e+00, 7.4256e-01, 1.4665e+02, 9.8382e+03,
         0.0000e+00, 2.5534e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9297e+01, 8.6302e+00, 8.0000e-01, 1.6629e+03, 1.0852e+04,
         0.0000e+00, 4.2162e+03]], device='cuda:0') tensor([-15.0184], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.47350142447758 m 83.00000000000001 km/h 121.94603599545519 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3023708461525198 40.0 -0.024717019521021056 -42.435701492859586 0.0
reward =  -2.158047666228086 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9297e+01, 8.6302e+00, 8.0000e-01, 1.6629e+03, 1.0852e+04,
         0.0000e+00, 4.2162e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 4.9499e+01, 8.4632e+00, 5.0000e-01, 0.0000e+00, 1.1956e+04,
         0.0000e+00, 4.2162e+03]], device='cuda:0') tensor([-2.1580], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.47350142447758 m 86.0 km/h 128.3494066389035 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.3023708461525198 40.0 -0.3286425689011667 -31.772375315171303 0.0
reward =  7.5966112697750106 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9499e+01, 8.4632e+00, 5.0000e-01, 0.0000e+00, 1.1956e+04,
         0.0000e+00, 4.2162e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9297e+01, 8.6302e+00, 8.0000e-01, 5.0183e+03, 1.3023e+04,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([7.5966], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.076887245313596 m 83.00000000000001 km/h 122.11936624660991 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7712862069924432 40.0 -0.3286425689011667 -20.89565313648107 -162.0
reward =  -142.4530094983898 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9297e+01, 8.6302e+00, 8.0000e-01, 5.0183e+03, 1.3023e+04,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9522e+01, 8.6552e+00, 7.4792e-01, 0.0000e+00, 1.4110e+04,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([-142.4530], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.11085374499519 m 89.0 km/h 153.55028510293332 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9894089975220152 40.0 -0.3286425689011667 -10.738453868842571 -81.0
reward =  -51.07768744022172 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9522e+01, 8.6552e+00, 7.4792e-01, 0.0000e+00, 1.4110e+04,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9706e+01, 8.8582e+00, 6.8234e-01, 0.0000e+00, 1.5126e+04,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([-51.0777], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.11085374499519 m 99.0 km/h 135.37772475814435 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9894089975220152 40.0 -0.3286425689011667 -6.5728513780233335 -243.0
reward =  -210.8909029444465 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9706e+01, 8.8582e+00, 6.8234e-01, 0.0000e+00, 1.5126e+04,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9522e+01, 8.6552e+00, 6.2453e-01, 0.0000e+00, 4.9656e+02,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([-210.8909], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.41016686523421 m 93.0 km/h 140.84557641668832 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5511608462740667 40.0 -5.331386951997498 -147.19818932193266 0.0
reward =  -111.97841542765609 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9522e+01, 8.6552e+00, 6.2453e-01, 0.0000e+00, 4.9656e+02,
         0.0000e+00, 3.3573e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9747e+01, 8.5917e+00, 8.0000e-01, 1.0005e+04, 1.4802e+03,
         0.0000e+00, 1.3363e+04]], device='cuda:0') tensor([-111.9784], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.36643801750979 m 98.0 km/h 153.52352503477033 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7410171120770624 40.0 -5.331386951997498 -137.8799059685617 -0.0
reward =  -103.95231003263626 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9747e+01, 8.5917e+00, 8.0000e-01, 1.0005e+04, 1.4802e+03,
         0.0000e+00, 1.3363e+04]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9519e+01, 8.5671e+00, 7.3377e-01, 0.0000e+00, 2.4120e+03,
         0.0000e+00, 1.3363e+04]], device='cuda:0') tensor([-103.9523], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.10327079139984 m 100.0 km/h 157.98215967798734 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.581153360566087 40.0 -0.06663228925743062 -128.84272848365777 0.0
reward =  -89.49051413348127 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9519e+01, 8.5671e+00, 7.3377e-01, 0.0000e+00, 2.4120e+03,
         0.0000e+00, 1.3363e+04]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 4.9297e+01, 8.6301e+00, 0.0000e+00, 0.0000e+00, 3.3157e+03,
         0.0000e+00, 1.3363e+04]], device='cuda:0') tensor([-89.4905], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.060339609669644 m 91.0 km/h 137.76595499407918 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7710096263690829 -500 -5.331386951997498 -118.92874797873351 -162.0
reward =  -785.4891253043619 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9297e+01, 8.6301e+00, 0.0000e+00, 0.0000e+00, 3.3157e+03,
         0.0000e+00, 1.3363e+04]], device='cuda:0') tensor([[19]], device='cuda:0') None tensor([-785.4891], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 25
Sum reward: -3100.3668874584732
**************************************Episode 17 done**************************************

state_reset =  tensor([[ 4.0000, 49.5662,  8.7022,  0.5736,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.01436447802112 m 91.0 km/h 158.38998731918312 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9316812002714491 40.0 -27.0 -152.10420745924438 0.0
reward =  -138.17252625897294 

state, action, next_state, reward =  tensor([[ 4.0000, 49.5662,  8.7022,  0.5736,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 4.9657e+01, 9.0196e+00, 5.0617e-01, 0.0000e+00, 9.8958e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-138.1725], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.807418062181895 m 81.0 km/h 133.50541638249584 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.08359644340472995 40.0 -1.1527093366688606 -140.18979943160798 0.0
reward =  -101.25891232487211 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9657e+01, 9.0196e+00, 5.0617e-01, 0.0000e+00, 9.8958e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9511e+01, 9.3149e+00, 8.0000e-01, 5.0054e+03, 2.1810e+03,
         0.0000e+00, 5.0054e+03]], device='cuda:0') tensor([-101.2589], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 27.08899304557079 m 86.0 km/h 89.57479979675679 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.497054770403842 40.0 -3.138020260193831 -128.85022094741558 0.0
reward =  -91.49118643720557 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9511e+01, 9.3149e+00, 8.0000e-01, 5.0054e+03, 2.1810e+03,
         0.0000e+00, 5.0054e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9738e+01, 9.1804e+00, 8.0000e-01, 3.9706e+03, 3.3150e+03,
         0.0000e+00, 8.9760e+03]], device='cuda:0') tensor([-91.4912], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.55759958229273 m 83.00000000000001 km/h 126.86217943382108 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6836844548122701 40.0 -0.0244858966256691 -117.76499703220426 0.0
reward =  -77.10579847401766 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9738e+01, 9.1804e+00, 8.0000e-01, 3.9706e+03, 3.3150e+03,
         0.0000e+00, 8.9760e+03]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 4.9968e+01, 9.1650e+00, 5.0000e-01, 0.0000e+00, 4.4235e+03,
         0.0000e+00, 8.9760e+03]], device='cuda:0') tensor([-77.1058], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.075044294343588 m 80.0 km/h 107.49807429177496 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.07825764641091926 40.0 -0.04541578405710392 -106.48122709974965 0.0
reward =  -66.60490053021766 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9968e+01, 9.1650e+00, 5.0000e-01, 0.0000e+00, 4.4235e+03,
         0.0000e+00, 8.9760e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.0128e+01, 8.9171e+00, 0.0000e+00, 0.0000e+00, 5.5519e+03,
         0.0000e+00, 8.9760e+03]], device='cuda:0') tensor([-66.6049], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.075044294343588 m 97.0 km/h 159.92762200861378 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.07825764641091926 -500 -4.723338199585566 -97.1750250936015 0.0
reward =  -601.8201056467761 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0128e+01, 8.9171e+00, 0.0000e+00, 0.0000e+00, 5.5519e+03,
         0.0000e+00, 8.9760e+03]], device='cuda:0') tensor([[1]], device='cuda:0') None tensor([-601.8201], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 6
Sum reward: -1076.4534296720622
**************************************Episode 18 done**************************************

state_reset =  tensor([[ 4.0000, 49.9801,  9.1425,  0.1840,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.132423897682553 m 90.0 km/h 137.1599906500779 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6539855023659696 40.0 -15.547104201449548 -151.94703044092697 0.0
reward =  -128.14812014474248 

state, action, next_state, reward =  tensor([[ 4.0000, 49.9801,  9.1425,  0.1840,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0014e+01, 8.7950e+00, 8.0000e-01, 1.9040e+04, 1.0053e+03,
         0.0000e+00, 1.1453e+03]], device='cuda:0') tensor([-128.1481], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.369217572702592 m 95.0 km/h 144.36263037294256 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5900405535712675 40.0 -3.1004451209498076 -142.3334322028502 0.0
reward =  -106.02391787737128 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0014e+01, 8.7950e+00, 8.0000e-01, 1.9040e+04, 1.0053e+03,
         0.0000e+00, 1.1453e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0081e+01, 8.4553e+00, 8.0000e-01, 7.7556e+03, 1.9667e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([-106.0239], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.6
Length, speed, consumption 25.284748873510804 m 88.00000000000001 km/h 125.52132266775071 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4056774590126891 40.0 -3.1004451209498076 -131.98967130005033 -162.0
reward =  -257.4957938800128 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0081e+01, 8.4553e+00, 8.0000e-01, 7.7556e+03, 1.9667e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([[14]], device='cuda:0') tensor([[4.0000e+00, 4.9861e+01, 8.5409e+00, 7.4602e-01, 0.0000e+00, 3.0010e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([-257.4958], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.13630714199997 m 98.0 km/h 162.09683562556842 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3974813492113398 40.0 -3.1004451209498076 -122.75592581931565 -0.0
reward =  -85.45888959105412 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9861e+01, 8.5409e+00, 7.4602e-01, 0.0000e+00, 3.0010e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.0080e+01, 8.4537e+00, 6.7673e-01, 0.0000e+00, 3.9244e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([-85.4589], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.4055474816271 m 83.99999999999999 km/h 123.46907535870808 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5933201665819925 40.0 -0.06233828158929623 -111.86783404147548 0.0
reward =  -71.33685215648279 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0080e+01, 8.4537e+00, 6.7673e-01, 0.0000e+00, 3.9244e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 5.0013e+01, 8.7941e+00, 0.0000e+00, 0.0000e+00, 5.0132e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([-71.3369], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.072949911044557 m 92.00000000000001 km/h 130.33972327447856 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9675734610896837 -500 -0.00870315068360651 -102.05667972845804 0.0
reward =  -603.0329563402313 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0013e+01, 8.7941e+00, 0.0000e+00, 0.0000e+00, 5.0132e+03,
         0.0000e+00, 8.9009e+03]], device='cuda:0') tensor([[3]], device='cuda:0') None tensor([-603.0330], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 6
Sum reward: -1251.4965299898947
**************************************Episode 19 done**************************************

state_reset =  tensor([[ 5.0000, 49.8617,  8.6219,  0.1353,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.787520417972395 m 83.00000000000001 km/h 125.95164202166134 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7877318872661353 17.271678710718064 -1.6129379897449558 -150.81505138497585 0.0
reward =  -134.3685787767366 

state, action, next_state, reward =  tensor([[ 5.0000, 49.8617,  8.6219,  0.1353,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0089e+01, 8.6915e+00, 5.0000e-01, 5.9259e+03, 1.1185e+03,
         0.0000e+00, 5.9259e+03]], device='cuda:0') tensor([-134.3686], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.207443074877734 m 99.0 km/h 149.51322139524817 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6321798873254098 40.0 -4.257258394822856 -141.64870844865666 0.0
reward =  -105.27378695615411 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0089e+01, 8.6915e+00, 5.0000e-01, 5.9259e+03, 1.1185e+03,
         0.0000e+00, 5.9259e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0041e+01, 9.0364e+00, 8.0000e-01, 3.2113e+04, 2.0351e+03,
         0.0000e+00, 2.2743e+03]], device='cuda:0') tensor([-105.2738], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.207443074877734 m 99.0 km/h 160.5476281409765 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6321798873254098 40.0 -0.07311735510685323 -132.48236551233748 0.0
reward =  -93.18766275476975 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0041e+01, 9.0364e+00, 8.0000e-01, 3.2113e+04, 2.0351e+03,
         0.0000e+00, 2.2743e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.0089e+01, 8.6915e+00, 0.0000e+00, 0.0000e+00, 2.9518e+03,
         0.0000e+00, 2.2743e+03]], device='cuda:0') tensor([-93.1877], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.797952583405618 m 87.0 km/h 127.85496120859254 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7602094829014433 -500 -5.82774462747635 -121.8073506502386 0.0
reward =  -628.3953047606163 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0089e+01, 8.6915e+00, 0.0000e+00, 0.0000e+00, 2.9518e+03,
         0.0000e+00, 2.2743e+03]], device='cuda:0') tensor([[11]], device='cuda:0') None tensor([-628.3953], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 4
Sum reward: -961.2253332482768
**************************************Episode 20 done**************************************

state_reset =  tensor([[ 4.0000, 52.0626, 11.7825,  0.1260,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 26.07649045867815 m 94.0 km/h 148.82856151396277 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6352803931704356 -11.639530753198102 -0.005997603492064276 -152.0132589732722 0.0
reward =  -164.2940677231328 

state, action, next_state, reward =  tensor([[ 4.0000, 52.0626, 11.7825,  0.1260,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[  3.0000,  51.9595,  11.4403,   0.0000,   0.0000, 998.6741,   0.0000,
           0.0000]], device='cuda:0') tensor([-164.2941], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.07797496523653 m 95.0 km/h 142.90888554394832 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.056714997749514294 -500 -18.398722910445628 -142.51002635486677 0.0
reward =  -660.8520342675629 

state, action, next_state, reward =  tensor([[  3.0000,  51.9595,  11.4403,   0.0000,   0.0000, 998.6741,   0.0000,
           0.0000]], device='cuda:0') tensor([[0]], device='cuda:0') None tensor([-660.8520], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -825.1461019906957
**************************************Episode 21 done**************************************

state_reset =  tensor([[ 4.0000, 49.5359,  8.4972,  0.3004,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 26.94138566991373 m 84.0 km/h 126.00713899494241 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2869949379381188 40.0 -0.02426878100650018 -150.45369185575126 0.0
reward =  -110.76495557469588 

state, action, next_state, reward =  tensor([[ 4.0000, 49.5359,  8.4972,  0.3004,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   49.3262,    8.6839,    0.0000,    0.0000, 1154.6309,
            0.0000,    0.0000]], device='cuda:0') tensor([-110.7650], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.16517791185936 m 85.0 km/h 128.57087813455405 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6964719632926257 -500 -27.0 -139.7954988577873 0.0
reward =  -666.0990268944946 

state, action, next_state, reward =  tensor([[   3.0000,   49.3262,    8.6839,    0.0000,    0.0000, 1154.6309,
            0.0000,    0.0000]], device='cuda:0') tensor([[19]], device='cuda:0') None tensor([-666.0990], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -776.8639824691904
**************************************Episode 22 done**************************************

state_reset =  tensor([[ 5.0000, 50.6344, 13.2322,  0.1805,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 26.7427622609162 m 82.0 km/h 73.13630846664401 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9954931195442012 40.0 -0.01471950040969575 -150.25927510496362 0.0
reward =  -109.27850148582911 

state, action, next_state, reward =  tensor([[ 5.0000, 50.6344, 13.2322,  0.1805,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   50.8084,   12.9698,    0.0000,    0.0000, 1174.0725,
            0.0000,    0.0000]], device='cuda:0') tensor([-109.2785], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.260946349617342 m 92.00000000000001 km/h 154.0318897393138 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.23032217748615075 -500 -17.661620873196046 -140.37455696815684 0.0
reward =  -658.266500018839 

state, action, next_state, reward =  tensor([[   3.0000,   50.8084,   12.9698,    0.0000,    0.0000, 1174.0725,
            0.0000,    0.0000]], device='cuda:0') tensor([[8]], device='cuda:0') None tensor([-658.2665], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -767.5450015046681
**************************************Episode 23 done**************************************

state_reset =  tensor([[ 5.0000, 50.9144, 11.5359,  0.1615,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.147725648399415 m 87.0 km/h 116.38345350690749 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6667001845165464 40.0 -3.506470113448996 -151.594044559283 0.0
reward =  -114.43381448821545 

state, action, next_state, reward =  tensor([[ 5.0000, 50.9144, 11.5359,  0.1615,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0971e+01, 1.1883e+01, 8.0000e-01, 9.7129e+03, 1.0406e+03,
         0.0000e+00, 9.7129e+03]], device='cuda:0') tensor([-114.4338], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.046728644175978 m 86.0 km/h 106.50293644011508 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9945448756963655 40.0 -4.466788167025451 -141.10936745241864 0.0
reward =  -104.58161074374772 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0971e+01, 1.1883e+01, 8.0000e-01, 9.7129e+03, 1.0406e+03,
         0.0000e+00, 9.7129e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.1187e+01, 1.1982e+01, 8.0000e-01, 1.9206e+03, 2.0891e+03,
         0.0000e+00, 1.1634e+04]], device='cuda:0') tensor([-104.5816], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.111380723001737 m 99.0 km/h 176.46833400091077 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9972568498652056 40.0 -0.07246366748188655 -131.977956280418 0.0
reward =  -93.04767679776509 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.1187e+01, 1.1982e+01, 8.0000e-01, 1.9206e+03, 2.0891e+03,
         0.0000e+00, 1.1634e+04]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.0970e+01, 1.1883e+01, 0.0000e+00, 0.0000e+00, 3.0022e+03,
         0.0000e+00, 1.1634e+04]], device='cuda:0') tensor([-93.0477], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.002863611821226 m 87.00000000000001 km/h 120.43186876392585 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6515814781691401 -500 -4.466788167025451 -121.63194375138853 -0.0
reward =  -625.4471504402449 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0970e+01, 1.1883e+01, 0.0000e+00, 0.0000e+00, 3.0022e+03,
         0.0000e+00, 1.1634e+04]], device='cuda:0') tensor([[12]], device='cuda:0') None tensor([-625.4472], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 4
Sum reward: -937.5102524699731
**************************************Episode 24 done**************************************

state_reset =  tensor([[ 5.0000, 50.8544, 12.7457,  0.1245,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.109561899070837 m 94.0 km/h 155.79666855976006 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5456449243016582 -14.95654493579659 -27.0 -152.38357203865374 0.0
reward =  -194.88576189875198 

state, action, next_state, reward =  tensor([[ 5.0000, 50.8544, 12.7457,  0.1245,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0798e+01, 1.3092e+01, 5.8019e-02, 2.4300e+03, 9.6164e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-194.8858], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.181237671373346 m 95.0 km/h 141.49753565571024 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.04106968660872721 -500 -6.09762597256264 -142.8412082895017 0.0
reward =  -648.9799039486732 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0798e+01, 1.3092e+01, 5.8019e-02, 2.4300e+03, 9.6164e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[9]], device='cuda:0') None tensor([-648.9799], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -843.8656658474251
**************************************Episode 25 done**************************************

state_reset =  tensor([[ 4.0000, 49.5975, 11.2124,  0.4379,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.28011153038538 m 96.0 km/h 147.21255366243483 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9182078219172265 40.0 -1.6518656478130558 -152.5199581761055 0.0
reward =  -115.09003164583578 

state, action, next_state, reward =  tensor([[ 4.0000, 49.5975, 11.2124,  0.4379,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9435e+01, 1.0967e+01, 8.0000e-01, 6.0037e+03, 9.4800e+02,
         0.0000e+00, 6.0037e+03]], device='cuda:0') tensor([-115.0900], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 27.92548738423161 m 82.0 km/h 131.8496906329142 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5397016346003907 40.0 -0.07373815157757775 -140.2599881049794 0.0
reward =  -100.87342789115738 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9435e+01, 1.0967e+01, 8.0000e-01, 6.0037e+03, 9.4800e+02,
         0.0000e+00, 6.0037e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 4.9251e+01, 1.1229e+01, 0.0000e+00, 0.0000e+00, 2.1740e+03,
         0.0000e+00, 6.0037e+03]], device='cuda:0') tensor([-100.8734], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.045516423357686 m 93.0 km/h 126.85565621417614 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7279639278539503 -500 -1.6518656478130558 -130.5649494894861 -270.0
reward =  -901.4888512094452 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9251e+01, 1.1229e+01, 0.0000e+00, 0.0000e+00, 2.1740e+03,
         0.0000e+00, 6.0037e+03]], device='cuda:0') tensor([[21]], device='cuda:0') None tensor([-901.4889], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 3
Sum reward: -1117.4523107464383
**************************************Episode 26 done**************************************

state_reset =  tensor([[ 4.0000, 52.4244,  9.7920,  0.6451,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 26.20690550867898 m 85.0 km/h 135.8325861408836 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6921444450912054 40.0 -0.0584534090393972 -150.90060472573595 0.0
reward =  -111.65120257986655 

state, action, next_state, reward =  tensor([[ 4.0000, 52.4244,  9.7920,  0.6451,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   52.3044,    9.4597,    0.0000,    0.0000, 1109.9396,
            0.0000,    0.0000]], device='cuda:0') tensor([-111.6512], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.58605742600934 m 89.0 km/h 128.46281744872724 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9170107415027451 -500 -27.0 -140.55118823881082 0.0
reward =  -666.6341774973081 

state, action, next_state, reward =  tensor([[   3.0000,   52.3044,    9.4597,    0.0000,    0.0000, 1109.9396,
            0.0000,    0.0000]], device='cuda:0') tensor([[21]], device='cuda:0') None tensor([-666.6342], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -778.2853800771746
**************************************Episode 27 done**************************************

state_reset =  tensor([[ 4.0000, 51.3039,  8.5922,  0.1001,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 27.74458032585364 m 97.0 km/h 99.52761321048165 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.09548588879661635 -23.665305851340523 -27.0 -151.70304235329144 0.0
reward =  -202.27286231583534 

state, action, next_state, reward =  tensor([[ 4.0000, 51.3039,  8.5922,  0.1001,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 5.1553e+01, 8.5588e+00, 5.3180e-02, 1.6200e+03, 1.0297e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-202.2729], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 27.432360974602506 m 97.0 km/h 130.01794223901285 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4889995095134841 -500 -0.7209290438457537 -141.52195992972761 0.0
reward =  -641.7538894640599 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.1553e+01, 8.5588e+00, 5.3180e-02, 1.6200e+03, 1.0297e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[7]], device='cuda:0') None tensor([-641.7539], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -844.0267517798952
**************************************Episode 28 done**************************************

state_reset =  tensor([[ 5.0000, 50.2840,  8.6423,  0.5870,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.307517559817335 m 98.0 km/h 133.67062389218594 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7335501189287962 40.0 -0.022951723020212686 -152.70336089639363 0.0
reward =  -111.99276250048504 

state, action, next_state, reward =  tensor([[ 5.0000, 50.2840,  8.6423,  0.5870,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 5.0251e+01, 8.9945e+00, 3.0000e-01, 0.0000e+00, 9.2966e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-111.9928], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.258523002857324 m 96.0 km/h 144.3696443323601 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9456538295099371 40.0 -0.49878767787399014 -143.23141477032215 0.0
reward =  -104.67585627770607 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0251e+01, 8.9945e+00, 3.0000e-01, 0.0000e+00, 9.2966e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0191e+01, 8.6521e+00, 5.0000e-01, 3.6976e+03, 1.8769e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([-104.6759], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.212508958112803 m 89.0 km/h 138.16891803513352 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8687820464592264 40.0 -0.49878767787399014 -133.03309654007427 -243.0
reward =  -335.6631021714891 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0191e+01, 8.6521e+00, 5.0000e-01, 3.6976e+03, 1.8769e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0395e+01, 8.8047e+00, 4.4076e-01, 0.0000e+00, 2.8967e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([-335.6631], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.051212059003387 m 95.0 km/h 147.56145800483603 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.04115360576061765 40.0 -0.49878767787399014 -123.54000565455719 -81.0
reward =  -165.0799469381918 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0395e+01, 8.8047e+00, 4.4076e-01, 0.0000e+00, 2.8967e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 5.0585e+01, 8.6132e+00, 3.7789e-01, 0.0000e+00, 3.8460e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([-165.0799], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.051212059003387 m 95.0 km/h 145.05427694591876 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.04115360576061765 40.0 -0.49878767787399014 -114.04691476904013 -81.0
reward =  -155.5045488411535 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0585e+01, 8.6132e+00, 3.7789e-01, 0.0000e+00, 3.8460e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 5.0395e+01, 8.8047e+00, 3.1609e-01, 0.0000e+00, 4.7953e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([-155.5045], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.145323175346533 m 90.0 km/h 178.72584581648368 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8382020548533788 40.0 -0.49878767787399014 -103.98878549890149 -81.0
reward =  -146.32577523162885 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0395e+01, 8.8047e+00, 3.1609e-01, 0.0000e+00, 4.7953e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.0403e+01, 8.4501e+00, 2.3966e-01, 0.0000e+00, 5.8011e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([-146.3258], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.085796028052098 m 90.0 km/h 94.06235172304756 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9501105094462238 40.0 -2.6189131219338235 -93.95446708768065 0.0
reward =  -55.62326970016825 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0403e+01, 8.4501e+00, 2.3966e-01, 0.0000e+00, 5.8011e+03,
         0.0000e+00, 3.6976e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0572e+01, 8.6859e+00, 5.0000e-01, 4.2403e+03, 6.8046e+03,
         0.0000e+00, 7.9378e+03]], device='cuda:0') tensor([-55.6233], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.243349439546048 m 88.0 km/h 133.3306202887831 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6323314407226862 40.0 -3.022798494606765 -83.62764231695728 0.0
reward =  -46.01810937084136 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0572e+01, 8.6859e+00, 5.0000e-01, 4.2403e+03, 6.8046e+03,
         0.0000e+00, 7.9378e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0794e+01, 8.7608e+00, 5.0000e-01, 8.0777e+02, 7.8372e+03,
         0.0000e+00, 8.7456e+03]], device='cuda:0') tensor([-46.0181], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.20615268243535 m 84.99999999999999 km/h 123.76126682485773 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.622513128698538 40.0 -5.498630069274299 -72.95209529851407 0.0
reward =  -39.0732384964869 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0794e+01, 8.7608e+00, 5.0000e-01, 8.0777e+02, 7.8372e+03,
         0.0000e+00, 8.7456e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0572e+01, 8.6900e+00, 8.0000e-01, 1.4947e+04, 8.9048e+03,
         0.0000e+00, 1.3697e+04]], device='cuda:0') tensor([-39.0732], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 27.91637751156682 m 93.99999999999999 km/h 169.41288277867855 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9060308702277392 40.0 -0.07195681294052311 -151.30862137854888 0.0
reward =  -112.28660906171714 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0572e+01, 8.6900e+00, 8.0000e-01, 1.4947e+04, 8.9048e+03,
         0.0000e+00, 1.3697e+04]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.0342e+01, 8.5305e+00, 0.0000e+00, 0.0000e+00, 1.0691e+03,
         0.0000e+00, 3.7021e+03]], device='cuda:0') tensor([-112.2866], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.266051230442713 m 89.0 km/h 104.24529257673353 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4214721661866293 -500 -19.93853526299863 -141.08864559994282 0.0
reward =  -660.6057086967548 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0342e+01, 8.5305e+00, 0.0000e+00, 0.0000e+00, 1.0691e+03,
         0.0000e+00, 3.7021e+03]], device='cuda:0') tensor([[7]], device='cuda:0') None tensor([-660.6057], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 11
Sum reward: -1932.848927286623
**************************************Episode 29 done**************************************

state_reset =  tensor([[ 4.0000, 52.3681,  9.7441,  0.7507,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.184431532148214 m 97.0 km/h 155.6120089140042 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9080642214724701 40.0 -0.0384004119030648 -152.65320066848108 0.0
reward =  -113.59966530185662 

state, action, next_state, reward =  tensor([[ 4.0000, 52.3681,  9.7441,  0.7507,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 5.2335e+01, 9.3773e+00, 3.0000e-01, 0.0000e+00, 9.3468e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-113.5997], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.010710028260245 m 81.0 km/h 113.94764410126426 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8834311653527757 40.0 -27.0 -141.53732954480986 0.0
reward =  -127.65389837945709 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.2335e+01, 9.3773e+00, 3.0000e-01, 0.0000e+00, 9.3468e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 5.2376e+01, 9.7392e+00, 2.5153e-01, 8.1000e+02, 2.0463e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-127.6539], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.56680522740836 m 96.0 km/h 153.01706409972618 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.600710557699554 40.0 -0.01849988272223184 -131.94977758453172 0.0
reward =  -91.3675669095544 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.2376e+01, 9.7392e+00, 2.5153e-01, 8.1000e+02, 2.0463e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.2160e+01, 9.8667e+00, 0.0000e+00, 0.0000e+00, 3.0050e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-91.3676], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.23715212284325 m 98.0 km/h 148.1941805359378 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6449056710182725 -500 -1.7099992455590927 -122.67898700879337 0.0
reward =  -625.0338919253708 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2160e+01, 9.8667e+00, 0.0000e+00, 0.0000e+00, 3.0050e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[4]], device='cuda:0') None tensor([-625.0339], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 4
Sum reward: -957.6550225162389
**************************************Episode 30 done**************************************

state_reset =  tensor([[ 5.0000, 52.0104, 11.7320,  0.2565,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.34541098227363 m 80.99999999999999 km/h 121.62048455548228 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9198935568124225 40.0 -27.0 -150.73537289676727 0.0
reward =  -136.81547933995483 

state, action, next_state, reward =  tensor([[ 5.0000, 52.0104, 11.7320,  0.2565,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.1965e+01, 1.2095e+01, 2.0412e-01, 2.4300e+03, 1.1265e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-136.8155], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.34541098227363 m 84.0 km/h 121.16631734307609 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9198935568124225 40.0 -27.0 -139.87305390436427 0.0
reward =  -127.7929474611767 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.1965e+01, 1.2095e+01, 2.0412e-01, 2.4300e+03, 1.1265e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.2010e+01, 1.1732e+01, 1.5190e-01, 0.0000e+00, 2.2127e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-127.7929], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.064669550347432 m 95.0 km/h 155.77441065725762 kWh/100km

Terminated: Violated soc 10 times,should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0334004437020723 20.663302606635092 -3.7102445073704233 -129.99591596949577 0.0
reward =  -114.07625831393317 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.2010e+01, 1.1732e+01, 1.5190e-01, 0.0000e+00, 2.2127e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[11]], device='cuda:0') None tensor([-114.0763], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 3
Sum reward: -378.6846851150647
**************************************Episode 31 done**************************************

state_reset =  tensor([[ 5.0000, 50.5681,  9.7136,  0.1041,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 26.337177353917284 m 83.00000000000001 km/h 115.14393026003853 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.578285476427041 -24.992527504769146 -27.0 -150.57664596697563 0.0
reward =  -203.14745894817182 

state, action, next_state, reward =  tensor([[ 5.0000, 50.5681,  9.7136,  0.1041,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.0659e+01, 9.3692e+00, 5.2479e-02, 0.0000e+00, 1.1423e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-203.1475], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.12027279091277 m 81.0 km/h 112.36064108603048 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5441055236449373 -271.1410596125688 -7.169029067788557 -139.41208028212552 0.0
reward =  -417.17806343883797 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0659e+01, 9.3692e+00, 5.2479e-02, 0.0000e+00, 1.1423e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0570e+01, 9.6962e+00, 8.0000e-01, 3.3679e+04, 2.2588e+03,
         0.0000e+00, 1.7038e+04]], device='cuda:0') tensor([-417.1781], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 26.615301298608443 m 86.0 km/h 110.97239506042196 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3742793896431301 40.0 -1.765840067752788 -150.85871108430345 0.0
reward =  -112.25027176241312 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0570e+01, 9.6962e+00, 8.0000e-01, 3.3679e+04, 2.2588e+03,
         0.0000e+00, 1.7038e+04]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0804e+01, 9.6132e+00, 8.0000e-01, 2.1266e+03, 1.1141e+03,
         0.0000e+00, 2.5234e+03]], device='cuda:0') tensor([-112.2503], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.562623292053406 m 95.0 km/h 166.31440298943906 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.320334300716843 40.0 -0.022769672735269066 -141.17182225784111 0.0
reward =  -101.51492623129323 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0804e+01, 9.6132e+00, 8.0000e-01, 2.1266e+03, 1.1141e+03,
         0.0000e+00, 2.5234e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0581e+01, 9.7067e+00, 5.0000e-01, 0.0000e+00, 2.0828e+03,
         0.0000e+00, 2.5234e+03]], device='cuda:0') tensor([-101.5149], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 28.71896420881815 m 85.0 km/h 153.09863304824557 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.04479668480286724 40.0 -1.7522432276069622 -129.00849623998872 0.0
reward =  -90.80553615239855 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0581e+01, 9.7067e+00, 5.0000e-01, 0.0000e+00, 2.0828e+03,
         0.0000e+00, 2.5234e+03]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0793e+01, 9.4731e+00, 5.0000e-01, 3.6811e+03, 3.2992e+03,
         0.0000e+00, 6.2045e+03]], device='cuda:0') tensor([-90.8055], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 28.02644120129409 m 87.0 km/h 84.80116168998971 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.29230339906908104 40.0 -1.7376787376583673 -117.4113481566946 0.0
reward =  -78.85672349528389 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0793e+01, 9.4731e+00, 5.0000e-01, 3.6811e+03, 3.2992e+03,
         0.0000e+00, 6.2045e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.1041e+01, 9.3983e+00, 8.0000e-01, 1.4412e+04, 4.4589e+03,
         0.0000e+00, 6.1754e+03]], device='cuda:0') tensor([-78.8567], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.385152169805778 m 96.0 km/h 134.31636070929534 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5972842110682884 40.0 -1.7376787376583673 -107.89191609301743 -243.0
reward =  -312.03231061960753 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1041e+01, 9.3983e+00, 8.0000e-01, 1.4412e+04, 4.4589e+03,
         0.0000e+00, 6.1754e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 5.1260e+01, 9.5001e+00, 7.4201e-01, 0.0000e+00, 5.4108e+03,
         0.0000e+00, 6.1754e+03]], device='cuda:0') tensor([-312.0323], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 26.164994990905875 m 85.0 km/h 130.3615652648089 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.06833325129006756 40.0 -0.06840042354139396 -96.81027115569259 0.0
reward =  -56.94700483052405 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.1260e+01, 9.5001e+00, 7.4201e-01, 0.0000e+00, 5.4108e+03,
         0.0000e+00, 6.1754e+03]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 5.1485e+01, 9.3888e+00, 0.0000e+00, 0.0000e+00, 6.5190e+03,
         0.0000e+00, 6.1754e+03]], device='cuda:0') tensor([-56.9470], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.523728859563896 m 80.00000000000001 km/h 124.5354452501279 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.07429960921604419 -500 -2.147682151770245 -85.32459316888884 0.0
reward =  -587.5465749298751 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.1485e+01, 9.3888e+00, 0.0000e+00, 0.0000e+00, 6.5190e+03,
         0.0000e+00, 6.1754e+03]], device='cuda:0') tensor([[7]], device='cuda:0') None tensor([-587.5466], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 9
Sum reward: -1960.2788704084053
**************************************Episode 32 done**************************************

state_reset =  tensor([[ 4.0000, 51.3908, 10.3171,  0.2610,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 27.75032176787635 m 88.0 km/h 102.48532816986312 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0882727860556531 40.0 -0.02125834880641215 -150.6475956404142 0.0
reward =  -111.75712677527628 

state, action, next_state, reward =  tensor([[ 4.0000, 51.3908, 10.3171,  0.2610,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   51.2671,    9.9702,    0.0000,    0.0000, 1135.2405,
            0.0000,    0.0000]], device='cuda:0') tensor([-111.7571], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.17442172123031 m 99.0 km/h 192.45125202161992 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.08214290247448254 -500 -27.0 -141.49326046905776 0.0
reward =  -668.4111175665832 

state, action, next_state, reward =  tensor([[   3.0000,   51.2671,    9.9702,    0.0000,    0.0000, 1135.2405,
            0.0000,    0.0000]], device='cuda:0') tensor([[13]], device='cuda:0') None tensor([-668.4111], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -780.1682443418595
**************************************Episode 33 done**************************************

state_reset =  tensor([[ 5.0000, 51.7212,  8.8710,  0.1796,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.215847740743666 m 82.0 km/h 92.86642336977714 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.56381444853588 40.0 -2.615663300560751 -150.92962782113693 0.0
reward =  -114.10910557023357 

state, action, next_state, reward =  tensor([[ 5.0000, 51.7212,  8.8710,  0.1796,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.1908e+01, 8.6639e+00, 8.0000e-01, 6.3524e+04, 1.1070e+03,
         0.0000e+00, 7.9313e+03]], device='cuda:0') tensor([-114.1091], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.305402647117496 m 84.0 km/h 128.07568466130303 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.14424493027401156 40.0 -3.004584112919894 -140.08445525808656 0.0
reward =  -102.94479444073244 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1908e+01, 8.6639e+00, 8.0000e-01, 6.3524e+04, 1.1070e+03,
         0.0000e+00, 7.9313e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.1684e+01, 8.7219e+00, 8.0000e-01, 7.7784e+02, 2.1916e+03,
         0.0000e+00, 8.7092e+03]], device='cuda:0') tensor([-102.9448], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.815718473415927 m 98.0 km/h 162.72147152395127 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6332001043977926 40.0 -3.004584112919894 -130.60113010458684 -243.0
reward =  -335.97251411310896 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1684e+01, 8.7219e+00, 8.0000e-01, 7.7784e+02, 2.1916e+03,
         0.0000e+00, 8.7092e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 5.1870e+01, 8.9455e+00, 7.2856e-01, 0.0000e+00, 3.1399e+03,
         0.0000e+00, 8.7092e+03]], device='cuda:0') tensor([-335.9725], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.234415640912175 m 93.0 km/h 136.39233388518912 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.40753569277356844 40.0 -3.9216904179521204 -120.83296921133052 0.0
reward =  -84.34712393650906 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.1870e+01, 8.9455e+00, 7.2856e-01, 0.0000e+00, 3.1399e+03,
         0.0000e+00, 8.7092e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.2071e+01, 9.1182e+00, 8.0000e-01, 1.8342e+03, 4.1167e+03,
         0.0000e+00, 1.0543e+04]], device='cuda:0') tensor([-84.3471], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.105278576023107 m 89.99999999999999 km/h 111.33511423866638 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9132598660763935 40.0 -4.270462518651368 -110.3908577809213 0.0
reward =  -75.57458016564905 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2071e+01, 9.1182e+00, 8.0000e-01, 1.8342e+03, 4.1167e+03,
         0.0000e+00, 1.0543e+04]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.2214e+01, 8.8148e+00, 8.0000e-01, 6.9754e+02, 5.1609e+03,
         0.0000e+00, 1.1241e+04]], device='cuda:0') tensor([-75.5746], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.105278576023107 m 100.0 km/h 181.84130058645965 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9132598660763935 40.0 -4.840104655663675 -100.99295749355296 0.0
reward =  -64.91980228314024 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2214e+01, 8.8148e+00, 8.0000e-01, 6.9754e+02, 5.1609e+03,
         0.0000e+00, 1.1241e+04]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.2071e+01, 9.1182e+00, 8.0000e-01, 1.1393e+03, 6.1007e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([-64.9198], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.21240559611027 m 86.0 km/h 108.06771607951684 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0065862204883143 40.0 -4.840104655663675 -96.80209311327347 -81.0
reward =  -143.64878398942545 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.2071e+01, 9.1182e+00, 8.0000e-01, 1.1393e+03, 6.1007e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.2083e+01, 8.7499e+00, 7.5366e-01, 0.0000e+00, 6.3632e+02,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([-143.6488], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.25014339844173 m 83.00000000000001 km/h 168.13328702685763 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.387507591156757 40.0 -4.840104655663675 -144.68496470491482 -81.0
reward =  -190.13756176942172 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.2083e+01, 8.7499e+00, 7.5366e-01, 0.0000e+00, 6.3632e+02,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 5.1868e+01, 8.8684e+00, 6.8146e-01, 0.0000e+00, 1.7315e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([-190.1376], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.25014339844173 m 88.0 km/h 86.06914917246881 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.387507591156757 40.0 -4.840104655663675 -134.35536058737048 -270.0
reward =  -369.5829728341909 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.1868e+01, 8.8684e+00, 6.8146e-01, 0.0000e+00, 1.7315e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.2083e+01, 8.7499e+00, 6.4450e-01, 0.0000e+00, 2.7645e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([-369.5830], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.434485826880486 m 94.0 km/h 140.1102911291175 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2746526774046477 40.0 -0.008151294964351963 -124.23151495154393 0.0
reward =  -83.96501356910363 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.2083e+01, 8.7499e+00, 6.4450e-01, 0.0000e+00, 2.7645e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.2300e+01, 8.9104e+00, 5.0000e-01, 0.0000e+00, 3.7768e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([-83.9650], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.90233447930976 m 84.0 km/h 119.84540733187097 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.1708255608280876 40.0 -4.840104655663675 -113.13051446041116 -270.0
reward =  -347.79979355524677 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.2300e+01, 8.9104e+00, 5.0000e-01, 0.0000e+00, 3.7768e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.2511e+01, 9.0715e+00, 4.4721e-01, 0.0000e+00, 4.8869e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([-347.7998], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.113758858190792 m 98.0 km/h 154.4238321569842 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0032482024266733 40.0 -0.038125104235939664 -103.90505202270842 0.0
reward =  -62.93992892451768 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.2511e+01, 9.0715e+00, 4.4721e-01, 0.0000e+00, 4.8869e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.2428e+01, 9.4165e+00, 0.0000e+00, 0.0000e+00, 5.8095e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([-62.9399], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.408719719730094 m 94.0 km/h 146.65532135644327 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9899598888253711 -500 -9.113645012386494 -96.80209311327347 0.0
reward =  -604.9257782368346 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.2428e+01, 9.4165e+00, 0.0000e+00, 0.0000e+00, 5.8095e+03,
         0.0000e+00, 1.2380e+04]], device='cuda:0') tensor([[8]], device='cuda:0') None tensor([-604.9258], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 13
Sum reward: -2580.867753388114
**************************************Episode 34 done**************************************

state_reset =  tensor([[ 5.0000, 49.4489, 10.9895,  0.2684,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.68595574281885 m 89.0 km/h 136.34362946396212 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.783966080104895 40.0 -27.0 -151.6101752051519 0.0
reward =  -137.826209125047 

state, action, next_state, reward =  tensor([[ 5.0000, 49.4489, 10.9895,  0.2684,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9669e+01, 1.0879e+01, 2.0884e-01, 2.4300e+03, 1.0390e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-137.8262], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.600071189563096 m 100.0 km/h 154.81387415071626 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7576426343283685 40.0 -3.29680096219815 -142.3941495769092 0.0
reward =  -106.44859317343571 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9669e+01, 1.0879e+01, 2.0884e-01, 2.4300e+03, 1.0390e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9452e+01, 1.1001e+01, 8.0000e-01, 9.2936e+03, 1.9606e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([-106.4486], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.6
Length, speed, consumption 25.023115164853333 m 91.0 km/h 150.13617417545245 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7560767516665184 40.0 -3.29680096219815 -132.4948952259782 -162.0
reward =  -258.54777293984284 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9452e+01, 1.1001e+01, 8.0000e-01, 9.2936e+03, 1.9606e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([[14]], device='cuda:0') tensor([[4.0000e+00, 4.9244e+01, 1.1131e+01, 7.3611e-01, 0.0000e+00, 2.9505e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([-258.5478], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.009737664105238 m 82.00000000000001 km/h 124.74872273099929 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7375164564468991 40.0 -3.29680096219815 -121.51501039783444 -270.0
reward =  -354.0742949035857 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9244e+01, 1.1131e+01, 7.3611e-01, 0.0000e+00, 2.9505e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9362e+01, 1.1425e+01, 6.8305e-01, 0.0000e+00, 4.0485e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([-354.0743], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.38048910259626 m 95.0 km/h 152.67121348831978 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9874986252548755 40.0 -0.061714833883575224 -111.8971408431664 0.0
reward =  -72.94635430230485 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9362e+01, 1.1425e+01, 6.8305e-01, 0.0000e+00, 4.0485e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 4.9161e+01, 1.1260e+01, 0.0000e+00, 0.0000e+00, 5.0103e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([-72.9464], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.77881118795344 m 83.00000000000001 km/h 122.29826729341275 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8097949086695327 -500 -4.396375894744626 -100.71596972549986 0.0
reward =  -605.922140528914 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9161e+01, 1.1260e+01, 0.0000e+00, 0.0000e+00, 5.0103e+03,
         0.0000e+00, 9.2936e+03]], device='cuda:0') tensor([[9]], device='cuda:0') None tensor([-605.9221], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 6
Sum reward: -1535.76536497313
**************************************Episode 35 done**************************************

state_reset =  tensor([[ 4.0000, 49.3167,  8.5767,  0.4157,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.075044751998128 m 81.0 km/h 130.4195376214439 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6049831798296771 40.0 -27.0 -150.8555356657786 0.0
reward =  -137.25055248594893 

state, action, next_state, reward =  tensor([[ 4.0000, 49.3167,  8.5767,  0.4157,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9298e+01, 8.9214e+00, 3.6005e-01, 2.4300e+03, 1.1144e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-137.2506], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.502007175836873 m 80.0 km/h 115.74617353645716 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9810606707061199 40.0 -27.0 -139.37963243665203 0.0
reward =  -127.36069310735814 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9298e+01, 8.9214e+00, 3.6005e-01, 2.4300e+03, 1.1144e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9088e+01, 8.7787e+00, 3.0985e-01, 2.4300e+03, 2.2620e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-127.3607], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.620183930449183 m 87.00000000000001 km/h 118.90991317850956 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4185764507338195 40.0 -0.025804051910367908 -128.7781770171558 0.0
reward =  -88.38540461833236 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9088e+01, 8.7787e+00, 3.0985e-01, 2.4300e+03, 2.2620e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 4.9297e+01, 8.6301e+00, 0.0000e+00, 0.0000e+00, 3.3222e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-88.3854], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.060339609669644 m 82.00000000000001 km/h 120.26457380947741 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7710096263690829 -500 -27.0 -117.77607670071548 0.0
reward =  -644.0050670743465 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9297e+01, 8.6301e+00, 0.0000e+00, 0.0000e+00, 3.3222e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[18]], device='cuda:0') None tensor([-644.0051], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 4
Sum reward: -997.0017172859859
**************************************Episode 36 done**************************************

state_reset =  tensor([[ 4.0000, 49.8102,  9.9858,  0.4084,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 27.344680513509747 m 100.0 km/h 150.7047032031001 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5348005416164641 40.0 -0.03382881677781067 -152.1559150151365 0.0
reward =  -112.72454437353076 

state, action, next_state, reward =  tensor([[ 4.0000, 49.8102,  9.9858,  0.4084,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[  3.0000,  49.8529,   9.6103,   0.0000,   0.0000, 984.4085,   0.0000,
           0.0000]], device='cuda:0') tensor([-112.7245], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.770623615266246 m 94.0 km/h 147.66511069836196 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.44290233561912085 -500 -1.2234506386696935 -142.28631448163026 0.0
reward =  -643.0668627846808 

state, action, next_state, reward =  tensor([[  3.0000,  49.8529,   9.6103,   0.0000,   0.0000, 984.4085,   0.0000,
           0.0000]], device='cuda:0') tensor([[9]], device='cuda:0') None tensor([-643.0669], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -755.7914071582115
**************************************Episode 37 done**************************************

state_reset =  tensor([[ 5.0000, 49.0606, 11.3758,  0.4536,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.36234205000171 m 99.0 km/h 162.10589284994973 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.45072503965169425 40.0 -27.0 -152.77733016363575 0.0
reward =  -139.32660512398405 

state, action, next_state, reward =  tensor([[ 5.0000, 49.0606, 11.3758,  0.4536,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9120e+01, 1.1712e+01, 3.8368e-01, 2.7000e+03, 9.2227e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-139.3266], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 27.121130060753924 m 81.0 km/h 100.7462111828626 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6416677907097387 40.0 -4.027136740724727 -140.72349458107846 0.0
reward =  -104.10896353109345 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9120e+01, 1.1712e+01, 3.8368e-01, 2.7000e+03, 9.2227e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 4.9300e+01, 1.1459e+01, 5.0000e-01, 2.2973e+03, 2.1277e+03,
         0.0000e+00, 2.2973e+03]], device='cuda:0') tensor([-104.1090], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 26.22914887221898 m 84.0 km/h 109.80775603144451 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5378307453318918 40.0 -4.027136740724727 -129.48243077869887 0.0
reward =  -92.97173677409171 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9300e+01, 1.1459e+01, 5.0000e-01, 2.2973e+03, 2.1277e+03,
         0.0000e+00, 2.2973e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9471e+01, 1.1209e+01, 4.5102e-01, 3.6244e+02, 3.2518e+03,
         0.0000e+00, 2.2973e+03]], device='cuda:0') tensor([-92.9717], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.3599985030411 m 84.0 km/h 114.97634913914956 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5976888548907242 40.0 -4.027136740724727 -118.61385999168125 0.0
reward =  -82.04330787751525 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9471e+01, 1.1209e+01, 4.5102e-01, 3.6244e+02, 3.2518e+03,
         0.0000e+00, 2.2973e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9660e+01, 1.1012e+01, 4.0143e-01, 0.0000e+00, 4.3386e+03,
         0.0000e+00, 2.2973e+03]], device='cuda:0') tensor([-82.0433], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.07246451505461 m 93.0 km/h 147.98619070261742 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9043530071153655 40.0 -0.9394042674561444 -108.90838985682142 0.0
reward =  -70.75214713139293 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9660e+01, 1.1012e+01, 4.0143e-01, 0.0000e+00, 4.3386e+03,
         0.0000e+00, 2.2973e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 4.9435e+01, 1.1041e+01, 5.0000e-01, 2.2815e+03, 5.3092e+03,
         0.0000e+00, 4.5788e+03]], device='cuda:0') tensor([-70.7521], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.387272792822724 m 84.00000000000001 km/h 133.89455133406764 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8186323729302909 40.0 -3.464110367479015 -98.0281300884688 0.0
reward =  -60.67360808301753 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9435e+01, 1.1041e+01, 5.0000e-01, 2.2815e+03, 5.3092e+03,
         0.0000e+00, 4.5788e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9567e+01, 1.1327e+01, 8.0000e-01, 5.0494e+03, 6.3972e+03,
         0.0000e+00, 9.6282e+03]], device='cuda:0') tensor([-60.6736], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.21079976360969 m 86.0 km/h 124.43814780938324 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.005777804632514 40.0 -0.04466465097384893 -87.474772047888 0.0
reward =  -48.52521450349436 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9567e+01, 1.1327e+01, 8.0000e-01, 5.0494e+03, 6.3972e+03,
         0.0000e+00, 9.6282e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 4.9356e+01, 1.1202e+01, 3.0000e-01, 0.0000e+00, 7.4525e+03,
         0.0000e+00, 9.6282e+03]], device='cuda:0') tensor([-48.5252], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.99133053399055 m 82.0 km/h 116.99144465258799 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0025243747988204 40.0 -0.9706286005530128 -76.06394400857509 0.0
reward =  -36.03204823432929 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9356e+01, 1.1202e+01, 3.0000e-01, 0.0000e+00, 7.4525e+03,
         0.0000e+00, 9.6282e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9589e+01, 1.1217e+01, 5.0000e-01, 2.4219e+04, 8.5936e+03,
         0.0000e+00, 4.6413e+03]], device='cuda:0') tensor([-36.0320], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.005316710666804 m 87.0 km/h 144.83272866640894 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9421256289435609 40.0 -0.9706286005530128 -65.71691640416124 -0.0
reward =  -25.745419375770695 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9589e+01, 1.1217e+01, 5.0000e-01, 2.4219e+04, 8.5936e+03,
         0.0000e+00, 4.6413e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 4.9814e+01, 1.1216e+01, 4.3841e-01, 0.0000e+00, 9.6283e+03,
         0.0000e+00, 4.6413e+03]], device='cuda:0') tensor([-25.7454], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 26.308723380047237 m 83.00000000000001 km/h 92.28563244695833 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.007395525583173149 40.0 -0.009711725465351418 -54.30590385377931 0.0
reward =  -14.308220053661493 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9814e+01, 1.1216e+01, 4.3841e-01, 0.0000e+00, 9.6283e+03,
         0.0000e+00, 4.6413e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9910e+01, 1.0881e+01, 3.0000e-01, 0.0000e+00, 1.0769e+04,
         0.0000e+00, 4.6413e+03]], device='cuda:0') tensor([-14.3082], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.351456785925713 m 85.99999999999999 km/h 131.74261273458382 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6239056528803683 40.0 -0.4691016990995086 -43.27506147827553 0.0
reward =  -4.36806883025541 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9910e+01, 1.0881e+01, 3.0000e-01, 0.0000e+00, 1.0769e+04,
         0.0000e+00, 4.6413e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9704e+01, 1.1062e+01, 5.0000e-01, 2.4924e+04, 1.1872e+04,
         0.0000e+00, 3.6382e+03]], device='cuda:0') tensor([-4.3681], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.163327417426768 m 80.0 km/h 162.97305740906185 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.23631982469010168 40.0 -0.4691016990995086 -31.951564140433476 -81.0
reward =  -73.18434601484289 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9704e+01, 1.1062e+01, 5.0000e-01, 2.4924e+04, 1.1872e+04,
         0.0000e+00, 3.6382e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9682e+01, 1.1410e+01, 4.3026e-01, 0.0000e+00, 1.3005e+04,
         0.0000e+00, 3.6382e+03]], device='cuda:0') tensor([-73.1843], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.6
Length, speed, consumption 25.2127758564422 m 89.0 km/h 88.34662845980768 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.16440475552357967 40.0 -0.4691016990995086 -21.753137951310784 -162.0
reward =  -144.38664440593388 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9682e+01, 1.1410e+01, 4.3026e-01, 0.0000e+00, 1.3005e+04,
         0.0000e+00, 3.6382e+03]], device='cuda:0') tensor([[14]], device='cuda:0') tensor([[4.0000e+00, 4.9721e+01, 1.1065e+01, 3.9237e-01, 0.0000e+00, 1.4025e+04,
         0.0000e+00, 3.6382e+03]], device='cuda:0') tensor([-144.3866], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.733266245654264 m 92.00000000000001 km/h 159.17854721801203 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.3771207449089538 40.0 -2.5968607251742726 -11.683598985619993 0.0
reward =  25.342419544296774 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9721e+01, 1.1065e+01, 3.9237e-01, 0.0000e+00, 1.4025e+04,
         0.0000e+00, 3.6382e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9570e+01, 1.1335e+01, 8.0000e-01, 4.5924e+04, 1.5032e+04,
         0.0000e+00, 7.8937e+03]], device='cuda:0') tensor([25.3424], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.074180548783808 m 99.0 km/h 162.902871720443 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8499534062043135 40.0 -0.6626807758932738 -152.8821161640786 -81.0
reward =  -195.39475034617618 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9570e+01, 1.1335e+01, 8.0000e-01, 4.5924e+04, 1.5032e+04,
         0.0000e+00, 7.8937e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9354e+01, 1.1436e+01, 7.3053e-01, 0.0000e+00, 9.1179e+02,
         0.0000e+00, 4.0254e+03]], device='cuda:0') tensor([-195.3948], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.520883047531157 m 95.0 km/h 132.9477953865226 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.21205751707561082 40.0 -0.6626807758932738 -143.21104469343524 -0.0
reward =  -104.08578298640413 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9354e+01, 1.1436e+01, 7.3053e-01, 0.0000e+00, 9.1179e+02,
         0.0000e+00, 4.0254e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9371e+01, 1.1084e+01, 6.7283e-01, 0.0000e+00, 1.8789e+03,
         0.0000e+00, 4.0254e+03]], device='cuda:0') tensor([-104.0858], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.106170192978862 m 81.0 km/h 111.99974118527669 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9910244123400282 40.0 -0.012500874628082581 -132.0527468298891 0.0
reward =  -91.07422329217715 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9371e+01, 1.1084e+01, 6.7283e-01, 0.0000e+00, 1.8789e+03,
         0.0000e+00, 4.0254e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9594e+01, 1.1144e+01, 5.0000e-01, 0.0000e+00, 2.9947e+03,
         0.0000e+00, 4.0254e+03]], device='cuda:0') tensor([-91.0742], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.686408750327296 m 96.0 km/h 157.0283617692331 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9449344836932118 40.0 -2.1712690730177626 -122.04534354851631 0.0
reward =  -85.16154710522729 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9594e+01, 1.1144e+01, 5.0000e-01, 0.0000e+00, 2.9947e+03,
         0.0000e+00, 4.0254e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9357e+01, 1.1204e+01, 5.0000e-01, 3.0172e+03, 3.9955e+03,
         0.0000e+00, 7.0425e+03]], device='cuda:0') tensor([-85.1615], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.493381430147732 m 93.0 km/h 145.24905631046488 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0159209946331078 40.0 -5.200906014292781 -112.17693783362043 0.0
reward =  -76.3619228532801 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9357e+01, 1.1204e+01, 5.0000e-01, 3.0172e+03, 3.9955e+03,
         0.0000e+00, 7.0425e+03]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 4.9570e+01, 1.1335e+01, 5.0000e-01, 6.0593e+03, 4.9823e+03,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([-76.3619], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.324546118718516 m 79.99999999999999 km/h 100.8578724526362 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.0685642381148343 40.0 -5.200906014292781 -104.0181202858556 -81.0
reward =  -150.15046206203357 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9570e+01, 1.1335e+01, 5.0000e-01, 6.0593e+03, 4.9823e+03,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 4.9660e+01, 1.1012e+01, 4.5656e-01, 0.0000e+00, 3.2372e+02,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([-150.1505], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.129665824357243 m 99.0 km/h 171.811403229713 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.13975344975440065 40.0 -5.200906014292781 -149.62471149457522 -243.0
reward =  -357.96537095862243 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9660e+01, 1.1012e+01, 4.5656e-01, 0.0000e+00, 3.2372e+02,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 4.9556e+01, 1.1322e+01, 3.8313e-01, 0.0000e+00, 1.2375e+03,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([-357.9654], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.40127550421464 m 88.0 km/h 111.42110192257132 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4007745137672941 40.0 -0.03350003214752108 -139.23328060648743 0.0
reward =  -98.86600612486765 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9556e+01, 1.1322e+01, 3.8313e-01, 0.0000e+00, 1.2375e+03,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 4.9710e+01, 1.1062e+01, 0.0000e+00, 0.0000e+00, 2.2767e+03,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([-98.8660], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.035451791707892 m 92.00000000000001 km/h 150.21606882859277 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.90352057995165 -500 -5.610570072170239 -129.43679947060173 0.0
reward =  -635.9508901227236 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9710e+01, 1.1062e+01, 0.0000e+00, 0.0000e+00, 2.2767e+03,
         0.0000e+00, 1.3102e+04]], device='cuda:0') tensor([[2]], device='cuda:0') None tensor([-635.9509], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 23
Sum reward: -2666.094866246598
**************************************Episode 38 done**************************************

state_reset =  tensor([[ 5.0000, 50.0747, 11.7690,  0.6576,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.093114908147957 m 89.0 km/h 100.1991317423262 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.017475416228529 40.0 -0.6333717538463316 -151.44548161018736 0.0
reward =  -111.06137794780517 

state, action, next_state, reward =  tensor([[ 5.0000, 50.0747, 11.7690,  0.6576,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0287e+01, 1.1924e+01, 8.0000e-01, 2.6367e+03, 1.0555e+03,
         0.0000e+00, 2.6367e+03]], device='cuda:0') tensor([-111.0614], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.55694343469537 m 86.0 km/h 116.76247352060376 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9763772049259278 40.0 -1.0426045074897103 -140.7472262189195 0.0
reward =  -100.8134535214833 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0287e+01, 1.1924e+01, 8.0000e-01, 2.6367e+03, 1.0555e+03,
         0.0000e+00, 2.6367e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0492e+01, 1.2089e+01, 8.0000e-01, 2.1485e+03, 2.1253e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([-100.8135], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.157554190314524 m 93.0 km/h 161.34022505769613 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5839082824752759 40.0 -1.0426045074897103 -131.00881814524936 -162.0
reward =  -254.63533093521437 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0492e+01, 1.2089e+01, 8.0000e-01, 2.1485e+03, 2.1253e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 5.0403e+01, 1.1762e+01, 7.3097e-01, 0.0000e+00, 3.0991e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([-254.6353], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 26.256446557655867 m 97.0 km/h 127.89901120075237 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3437186466359638 40.0 -0.03738588604194539 -121.26415756715029 0.0
reward =  -80.95782480655627 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0403e+01, 1.1762e+01, 7.3097e-01, 0.0000e+00, 3.0991e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.0434e+01, 1.2130e+01, 3.0000e-01, 0.0000e+00, 4.0736e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([-80.9578], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.083713281587997 m 81.0 km/h 160.28025869881472 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4594548042011913 40.0 -1.0426045074897103 -110.1158405531112 -0.0
reward =  -71.6178998648021 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0434e+01, 1.2130e+01, 3.0000e-01, 0.0000e+00, 4.0736e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0371e+01, 1.1789e+01, 2.3163e-01, 0.0000e+00, 5.1884e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([-71.6179], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.761558025221 m 83.00000000000001 km/h 93.91208757414148 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0139484498338471 40.0 -0.18619793664222015 -98.94215273494305 0.0
reward =  -58.114402221751426 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0371e+01, 1.1789e+01, 2.3163e-01, 0.0000e+00, 5.1884e+03,
         0.0000e+00, 4.7852e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0602e+01, 1.1826e+01, 5.0000e-01, 2.9781e+04, 6.3058e+03,
         0.0000e+00, 3.0724e+03]], device='cuda:0') tensor([-58.1144], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.16378555278478 m 80.0 km/h 84.22223617947671 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.44686819492136537 40.0 -0.45062663978331874 -87.16844923618989 0.0
reward =  -47.17220768105184 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0602e+01, 1.1826e+01, 5.0000e-01, 2.9781e+04, 6.3058e+03,
         0.0000e+00, 3.0724e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0656e+01, 1.2187e+01, 5.0000e-01, 5.2886e+02, 7.4832e+03,
         0.0000e+00, 3.6013e+03]], device='cuda:0') tensor([-47.1722], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.05363431480633 m 96.0 km/h 169.942080638336 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0013618405540212 40.0 -0.012759070164948642 -77.77333636813752 0.0
reward =  -38.787457278856486 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0656e+01, 1.2187e+01, 5.0000e-01, 5.2886e+02, 7.4832e+03,
         0.0000e+00, 3.6013e+03]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 5.0434e+01, 1.2130e+01, 3.0000e-01, 0.0000e+00, 8.4227e+03,
         0.0000e+00, 3.6013e+03]], device='cuda:0') tensor([-38.7875], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.05363431480633 m 84.0 km/h 102.68710790434783 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0013618405540212 40.0 -8.28908712259501 -67.0360645189348 0.0
reward =  -34.32378980097579 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0434e+01, 1.2130e+01, 3.0000e-01, 0.0000e+00, 8.4227e+03,
         0.0000e+00, 3.6013e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0656e+01, 1.2187e+01, 8.0000e-01, 7.6734e+03, 9.4964e+03,
         0.0000e+00, 1.8711e+03]], device='cuda:0') tensor([-34.3238], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.40666868826339 m 92.00000000000001 km/h 157.4828100140034 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0120285368058324 40.0 -8.28908712259501 -57.094324597440426 0.0
reward =  -26.395440256841265 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0656e+01, 1.2187e+01, 8.0000e-01, 7.6734e+03, 9.4964e+03,
         0.0000e+00, 1.8711e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.0433e+01, 1.2109e+01, 7.3195e-01, 8.2891e+02, 1.0491e+04,
         0.0000e+00, 1.8711e+03]], device='cuda:0') tensor([-26.3954], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.201387791857893 m 85.0 km/h 125.71902406886437 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8924535481999192 40.0 -0.4458745386497551 -46.420795650300605 0.0
reward =  -5.974216640750441 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0433e+01, 1.2109e+01, 7.3195e-01, 8.2891e+02, 1.0491e+04,
         0.0000e+00, 1.8711e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0623e+01, 1.2304e+01, 8.0000e-01, 1.7207e+03, 1.1558e+04,
         0.0000e+00, 3.5917e+03]], device='cuda:0') tensor([-5.9742], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.176694752558497 m 81.0 km/h 101.47274443044853 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.970165141825502 40.0 -0.025482617250577846 -34.78670909360793 0.0
reward =  6.157973430966997 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0623e+01, 1.2304e+01, 8.0000e-01, 1.7207e+03, 1.1558e+04,
         0.0000e+00, 3.5917e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0840e+01, 1.2448e+01, 5.0000e-01, 0.0000e+00, 1.2721e+04,
         0.0000e+00, 3.5917e+03]], device='cuda:0') tensor([6.1580], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.304932355020224 m 87.00000000000001 km/h 151.57023146313477 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6284279805348056 40.0 -6.869822901015727 -24.31570260187542 0.0
reward =  8.186046516574049 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0840e+01, 1.2448e+01, 5.0000e-01, 0.0000e+00, 1.2721e+04,
         0.0000e+00, 3.5917e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0721e+01, 1.2755e+01, 8.0000e-01, 1.7979e+04, 1.3768e+04,
         0.0000e+00, 1.6440e+04]], device='cuda:0') tensor([8.1860], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.04153700159976 m 92.00000000000001 km/h 105.60418557250092 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9714187131691555 40.0 -4.304037770921956 -152.20113769502618 -0.0
reward =  -115.53375675277897 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0721e+01, 1.2755e+01, 8.0000e-01, 1.7979e+04, 1.3768e+04,
         0.0000e+00, 1.6440e+04]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.0946e+01, 1.2761e+01, 7.5503e-01, 0.0000e+00, 9.7989e+02,
         0.0000e+00, 1.1308e+04]], device='cuda:0') tensor([-115.5338], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.04153700159976 m 99.0 km/h 189.42561247639773 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9714187131691555 40.0 -22.16134887751199 -143.095124239899 0.0
reward =  -126.22789183058015 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0946e+01, 1.2761e+01, 7.5503e-01, 0.0000e+00, 9.7989e+02,
         0.0000e+00, 1.1308e+04]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0721e+01, 1.2755e+01, 8.0000e-01, 6.1853e+03, 1.8905e+03,
         0.0000e+00, 4.8387e+02]], device='cuda:0') tensor([-126.2279], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.304932355020224 m 81.0 km/h 96.98189887545516 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6284279805348056 40.0 -0.02582632586614829 -131.84848763766777 0.0
reward =  -91.24588598299911 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0721e+01, 1.2755e+01, 8.0000e-01, 6.1853e+03, 1.8905e+03,
         0.0000e+00, 4.8387e+02]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0840e+01, 1.2448e+01, 5.0000e-01, 0.0000e+00, 3.0152e+03,
         0.0000e+00, 4.8387e+02]], device='cuda:0') tensor([-91.2459], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.47373776316195 m 97.0 km/h 136.1827009394477 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.04819782368174754 40.0 -13.835551089646556 -122.39431692144274 0.0
reward =  -96.27806583477104 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0840e+01, 1.2448e+01, 5.0000e-01, 0.0000e+00, 3.0152e+03,
         0.0000e+00, 4.8387e+02]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0849e+01, 1.2086e+01, 5.0000e-01, 8.3258e+02, 3.9606e+03,
         0.0000e+00, 1.3164e+03]], device='cuda:0') tensor([-96.2781], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.208981081618212 m 99.0 km/h 168.7333810488304 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.05769081669161562 40.0 -1.9354540388013657 -113.22741470994521 0.0
reward =  -75.10517793205496 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0849e+01, 1.2086e+01, 5.0000e-01, 8.3258e+02, 3.9606e+03,
         0.0000e+00, 1.3164e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0842e+01, 1.2445e+01, 8.0000e-01, 5.2545e+03, 4.8773e+03,
         0.0000e+00, 6.5709e+03]], device='cuda:0') tensor([-75.1052], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.009060891486435 m 90.0 km/h 124.25023728486649 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.33349773962448176 40.0 -1.9354540388013657 -103.22379035335064 -243.0
reward =  -307.8257466525275 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0842e+01, 1.2445e+01, 8.0000e-01, 5.2545e+03, 4.8773e+03,
         0.0000e+00, 6.5709e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0946e+01, 1.2761e+01, 7.4715e-01, 0.0000e+00, 5.8776e+03,
         0.0000e+00, 6.5709e+03]], device='cuda:0') tensor([-307.8257], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.04153700159976 m 97.0 km/h 185.01935594180304 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9714187131691555 40.0 -0.03683579796281007 -93.93002404347855 0.0
reward =  -54.93827855461052 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0946e+01, 1.2761e+01, 7.4715e-01, 0.0000e+00, 5.8776e+03,
         0.0000e+00, 6.5709e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 5.0721e+01, 1.2755e+01, 3.0000e-01, 0.0000e+00, 6.8070e+03,
         0.0000e+00, 6.5709e+03]], device='cuda:0') tensor([-54.9383], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.64297732426013 m 87.00000000000001 km/h 107.72263976772487 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6379209735446738 40.0 -3.6781335438661515 -83.3191368748192 0.0
reward =  -46.35934944514067 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0721e+01, 1.2755e+01, 3.0000e-01, 0.0000e+00, 6.8070e+03,
         0.0000e+00, 6.5709e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0842e+01, 1.2445e+01, 5.0000e-01, 3.4854e+03, 7.8681e+03,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([-46.3593], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.009060891486435 m 99.0 km/h 143.3702433189112 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.33349773962448176 40.0 -3.6781335438661515 -74.22493291427867 -243.0
reward =  -280.5695687185203 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0842e+01, 1.2445e+01, 5.0000e-01, 3.4854e+03, 7.8681e+03,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0946e+01, 1.2761e+01, 4.3902e-01, 0.0000e+00, 8.7775e+03,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([-280.5696], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.14680921857188 m 87.99999999999999 km/h 158.48972985206586 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8647947924752108 40.0 -3.6781335438661515 -73.56267087732303 -243.0
reward =  -281.1055992136644 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0946e+01, 1.2761e+01, 4.3902e-01, 0.0000e+00, 8.7775e+03,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 5.0798e+01, 1.3032e+01, 3.7124e-01, 0.0000e+00, 9.6251e+02,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([-281.1056], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 26.11487821299294 m 88.0 km/h 116.27576550415513 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7914365901960613 40.0 -0.03195987482968315 -141.69157172404275 0.0
reward =  -100.93209500867636 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0798e+01, 1.3032e+01, 3.7124e-01, 0.0000e+00, 9.6251e+02,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.0922e+01, 1.2716e+01, 0.0000e+00, 0.0000e+00, 2.0308e+03,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([-100.9321], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.533564208570578 m 80.0 km/h 115.220372664753 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7046056923812494 -500 -4.03117195789466 -130.201467830186 0.0
reward =  -634.9372454804619 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0922e+01, 1.2716e+01, 0.0000e+00, 0.0000e+00, 2.0308e+03,
         0.0000e+00, 1.0056e+04]], device='cuda:0') tensor([[4]], device='cuda:0') None tensor([-634.9372], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 25
Sum reward: -3026.568042415333
**************************************Episode 39 done**************************************

state_reset =  tensor([[ 5.0000, 49.3129, 10.6810,  0.6187,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.022538041519827 m 84.99999999999999 km/h 135.57728472133786 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6833540984927606 40.0 -0.05610421515788245 -151.40221918241514 0.0
reward =  -112.14167749606578 

state, action, next_state, reward =  tensor([[ 5.0000, 49.3129, 10.6810,  0.6187,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 4.9243e+01, 1.0353e+01, 0.0000e+00, 0.0000e+00, 1.0598e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-112.1417], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 27.72752444129519 m 89.00000000000001 km/h 125.97021263350689 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.3157269896315923 -500 -3.2857231019863833 -140.18659131852044 0.0
reward =  -643.7880414101384 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9243e+01, 1.0353e+01, 0.0000e+00, 0.0000e+00, 1.0598e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[3]], device='cuda:0') None tensor([-643.7880], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -755.9297189062041
**************************************Episode 40 done**************************************

state_reset =  tensor([[ 5.0000, 50.6580, 10.5665,  0.4423,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.023809003968612 m 96.0 km/h 153.65389554267134 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.02648463946360629 40.0 -27.0 -152.61607162351177 0.0
reward =  -139.64255626297538 

state, action, next_state, reward =  tensor([[ 5.0000, 50.6580, 10.5665,  0.4423,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 5.0505e+01, 1.0827e+01, 3.7694e-01, 8.1000e+02, 9.3839e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-139.6426], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 26.711208476518586 m 100.0 km/h 139.96774044173105 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5545390306479915 40.0 -0.0013354739980205698 -143.0000365719651 0.0
reward =  -103.55591107661111 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0505e+01, 1.0827e+01, 3.7694e-01, 8.1000e+02, 9.3839e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 5.0287e+01, 1.0985e+01, 3.0000e-01, 0.0000e+00, 1.9000e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-103.5559], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.9315629511571 m 93.0 km/h 133.95018189398343 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0356185470092716 40.0 -2.594824508892334 -132.96201220377523 0.0
reward =  -96.59245525967684 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0287e+01, 1.0985e+01, 3.0000e-01, 0.0000e+00, 1.9000e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0093e+01, 1.0783e+01, 8.0000e-01, 7.8896e+03, 2.9038e+03,
         0.0000e+00, 7.8896e+03]], device='cuda:0') tensor([-96.5925], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 26.90549908619938 m 98.0 km/h 148.14728829820064 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7164089968036104 40.0 -2.594824508892334 -123.0783594782326 -81.0
reward =  -167.38959298392854 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0093e+01, 1.0783e+01, 8.0000e-01, 7.8896e+03, 2.9038e+03,
         0.0000e+00, 7.8896e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9866e+01, 1.0912e+01, 7.3221e-01, 0.0000e+00, 3.8922e+03,
         0.0000e+00, 7.8896e+03]], device='cuda:0') tensor([-167.3896], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.90549908619938 m 81.0 km/h 123.2801526712165 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7164089968036104 40.0 -0.01758011774664612 -111.12035988436622 0.0
reward =  -70.42153100530926 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9866e+01, 1.0912e+01, 7.3221e-01, 0.0000e+00, 3.8922e+03,
         0.0000e+00, 7.8896e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0093e+01, 1.0783e+01, 5.0000e-01, 0.0000e+00, 5.0880e+03,
         0.0000e+00, 7.8896e+03]], device='cuda:0') tensor([-70.4215], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.112307048215715 m 87.99999999999999 km/h 126.19206281784976 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.640892405550913 40.0 -26.009115998323978 -100.8471433646416 0.0
reward =  -87.49715176851649 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0093e+01, 1.0783e+01, 5.0000e-01, 0.0000e+00, 5.0880e+03,
         0.0000e+00, 7.8896e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9884e+01, 1.0915e+01, 8.0000e-01, 4.9942e+03, 6.1153e+03,
         0.0000e+00, 9.9088e+01]], device='cuda:0') tensor([-87.4972], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.306655475659703 m 93.0 km/h 156.440569616843 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8334677021268406 40.0 -26.009115998323978 -91.05101866438625 0.0
reward =  -77.89360236483707 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9884e+01, 1.0915e+01, 8.0000e-01, 4.9942e+03, 6.1153e+03,
         0.0000e+00, 9.9088e+01]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9660e+01, 1.0979e+01, 7.3267e-01, 2.6009e+03, 7.0949e+03,
         0.0000e+00, 9.9088e+01]], device='cuda:0') tensor([-77.8936], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.07714809009937 m 80.00000000000001 km/h 103.0263059469617 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8373845035178809 40.0 -0.20937347603393505 -79.76630202384153 0.0
reward =  -39.13829099635758 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9660e+01, 1.0979e+01, 7.3267e-01, 2.6009e+03, 7.0949e+03,
         0.0000e+00, 9.9088e+01]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9883e+01, 1.0922e+01, 8.0000e-01, 3.0197e+03, 8.2234e+03,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([-39.1383], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.443355859198576 m 91.0 km/h 142.8820228491727 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6369756041598728 40.0 -0.023817350079534626 -69.70079860701571 0.0
reward =  -29.087640352935374 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9883e+01, 1.0922e+01, 8.0000e-01, 3.0197e+03, 8.2234e+03,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0093e+01, 1.0783e+01, 5.0000e-01, 0.0000e+00, 9.2299e+03,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([-29.0876], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 27.286435502167606 m 82.0 km/h 126.033640387664 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.910211447231014 40.0 -0.20937347603393505 -57.72138789874702 -162.0
reward =  -179.02054992754995 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0093e+01, 1.0783e+01, 5.0000e-01, 0.0000e+00, 9.2299e+03,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 5.0339e+01, 1.0777e+01, 4.4151e-01, 0.0000e+00, 1.0428e+04,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([-179.0205], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.294210250825248 m 97.0 km/h 186.62647536211347 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0089540685660892 40.0 -0.20937347603393505 -48.333845949987136 -0.0
reward =  -7.534265357454977 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0339e+01, 1.0777e+01, 4.4151e-01, 0.0000e+00, 1.0428e+04,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0516e+01, 1.1002e+01, 3.6123e-01, 0.0000e+00, 1.1367e+04,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([-7.5343], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.08805205980468 m 99.0 km/h 119.80234668658694 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0004708015400672 40.0 -0.20937347603393505 -39.21091792823998 -270.0
reward =  -270.42076220581396 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0516e+01, 1.1002e+01, 3.6123e-01, 0.0000e+00, 1.1367e+04,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.0341e+01, 1.0778e+01, 3.1012e-01, 0.0000e+00, 1.2279e+04,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([-270.4208], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.357950208172362 m 79.99999999999999 km/h 124.80128363459018 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5677572928448696 40.0 -2.6310531299970172 -27.349840334562415 0.0
reward =  10.58686382828543 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0341e+01, 1.0778e+01, 3.1012e-01, 0.0000e+00, 1.2279e+04,
         0.0000e+00, 3.1187e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0344e+01, 1.1150e+01, 5.0000e-01, 2.3653e+04, 1.3465e+04,
         0.0000e+00, 2.4369e+03]], device='cuda:0') tensor([10.5869], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.188148992491755 m 99.0 km/h 151.46823037233827 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9784011088021507 40.0 -0.3262718660098517 -18.190513428201776 0.0
reward =  20.504813596986217 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0344e+01, 1.1150e+01, 5.0000e-01, 2.3653e+04, 1.3465e+04,
         0.0000e+00, 2.4369e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0179e+01, 1.0908e+01, 5.0000e-01, 9.1565e+02, 1.4381e+04,
         0.0000e+00, 3.3525e+03]], device='cuda:0') tensor([20.5048], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.19431901209097 m 98.0 km/h 156.37741764269762 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9787034689719091 40.0 -6.735717439816844 -8.93545746457652 0.0
reward =  25.30752856457854 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0179e+01, 1.0908e+01, 5.0000e-01, 9.1565e+02, 1.4381e+04,
         0.0000e+00, 3.3525e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0345e+01, 1.1150e+01, 8.0000e-01, 3.5312e+04, 1.5306e+04,
         0.0000e+00, 1.6171e+04]], device='cuda:0') tensor([25.3075], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.336445370018108 m 98.0 km/h 211.2398577085893 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8371774429382 40.0 -4.938944566588016 -152.6927343538709 -270.0
reward =  -386.7945014775207 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0345e+01, 1.1150e+01, 8.0000e-01, 3.5312e+04, 1.5306e+04,
         0.0000e+00, 1.6171e+04]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.0572e+01, 1.1127e+01, 7.0898e-01, 0.0000e+00, 9.3073e+02,
         0.0000e+00, 1.2578e+04]], device='cuda:0') tensor([-386.7945], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.6939074211382 m 94.0 km/h 96.69105609810444 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7398089737602568 40.0 -4.938944566588016 -142.85251449045626 -243.0
reward =  -350.051650083284 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0572e+01, 1.1127e+01, 7.0898e-01, 0.0000e+00, 9.3073e+02,
         0.0000e+00, 1.2578e+04]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 5.0636e+01, 1.1477e+01, 6.6673e-01, 0.0000e+00, 1.9147e+03,
         0.0000e+00, 1.2578e+04]], device='cuda:0') tensor([-350.0517], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 28.056294375884153 m 94.0 km/h 209.41213298961165 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.969915148765567 40.0 -0.026680669034559193 -132.10755068692617 0.0
reward =  -93.1041465047263 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0636e+01, 1.1477e+01, 6.6673e-01, 0.0000e+00, 1.9147e+03,
         0.0000e+00, 1.2578e+04]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 5.0508e+01, 1.1135e+01, 3.0000e-01, 0.0000e+00, 2.9892e+03,
         0.0000e+00, 1.2578e+04]], device='cuda:0') tensor([-93.1041], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.19471470646282 m 90.0 km/h 75.72608118601636 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.30676504976198077 40.0 -19.030640560069624 -122.02966480434105 0.0
reward =  -100.7535403146487 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0508e+01, 1.1135e+01, 3.0000e-01, 0.0000e+00, 2.9892e+03,
         0.0000e+00, 1.2578e+04]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 5.0690e+01, 1.0923e+01, 3.0000e-01, 3.1220e+03, 3.9970e+03,
         0.0000e+00, 7.9694e+02]], device='cuda:0') tensor([-100.7535], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 26.194502903159293 m 94.0 km/h 117.63656129917928 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2577317390803329 40.0 -0.15778322072536846 -111.99772752228004 0.0
reward =  -71.89777900392508 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0690e+01, 1.0923e+01, 3.0000e-01, 3.1220e+03, 3.9970e+03,
         0.0000e+00, 7.9694e+02]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 5.0891e+01, 1.0730e+01, 3.0000e-01, 2.2186e+03, 5.0002e+03,
         0.0000e+00, 3.0156e+03]], device='cuda:0') tensor([-71.8978], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.194502903159293 m 94.0 km/h 170.72871613479495 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2577317390803329 40.0 -2.5230741318062284 -101.96579024021904 0.0
reward =  -64.74659611110559 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0891e+01, 1.0730e+01, 3.0000e-01, 2.2186e+03, 5.0002e+03,
         0.0000e+00, 3.0156e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0690e+01, 1.0923e+01, 8.0000e-01, 5.5427e+04, 6.0034e+03,
         0.0000e+00, 7.7461e+03]], device='cuda:0') tensor([-64.7466], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.86956127025777 m 83.00000000000001 km/h 99.75348011267494 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9303048920657171 40.0 -0.07561126060255735 -90.74525764107108 0.0
reward =  -51.751173793739355 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0690e+01, 1.0923e+01, 8.0000e-01, 5.5427e+04, 6.0034e+03,
         0.0000e+00, 7.7461e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.0602e+01, 1.0583e+01, 0.0000e+00, 0.0000e+00, 7.1255e+03,
         0.0000e+00, 7.7461e+03]], device='cuda:0') tensor([-51.7512], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.8237767106642 m 83.00000000000001 km/h 128.2049323776313 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9604965556840075 -500 -3.7149389286995005 -79.54458340512036 0.0
reward =  -582.2990257781358 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0602e+01, 1.0583e+01, 0.0000e+00, 0.0000e+00, 7.1255e+03,
         0.0000e+00, 7.7461e+03]], device='cuda:0') tensor([[4]], device='cuda:0') None tensor([-582.2990], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 23
Sum reward: -2913.1935166392022
**************************************Episode 41 done**************************************

state_reset =  tensor([[ 4.0000, 52.4655, 12.8080,  0.5920,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.243773721378794 m 83.00000000000001 km/h 123.66583690870793 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.37224763922824755 40.0 -0.5070616775282756 -150.617158385908 0.0
reward =  -111.49646770266452 

state, action, next_state, reward =  tensor([[ 4.0000, 52.4655, 12.8080,  0.5920,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.2434e+01, 1.3192e+01, 8.0000e-01, 3.7141e+03, 1.1383e+03,
         0.0000e+00, 3.7141e+03]], device='cuda:0') tensor([-111.4965], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 37.344208157563756 m 82.0 km/h 121.04425874801127 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.072489881242316 40.0 -2.134370395715221 -134.2221401703922 0.0
reward =  -95.28402068486511 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.2434e+01, 1.3192e+01, 8.0000e-01, 3.7141e+03, 1.1383e+03,
         0.0000e+00, 3.7141e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.2098e+01, 1.3179e+01, 8.0000e-01, 3.2546e+03, 2.7778e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([-95.2840], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.077283987013097 m 81.0 km/h 122.54714078262097 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.03352947199106216 40.0 -2.134370395715221 -123.0766806206086 -81.0
reward =  -166.24458048831488 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.2098e+01, 1.3179e+01, 8.0000e-01, 3.2546e+03, 2.7778e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.2262e+01, 1.2927e+01, 7.4774e-01, 0.0000e+00, 3.8923e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([-166.2446], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.78832447995141 m 84.0 km/h 120.87006545023124 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.10012479773404134 40.0 -2.134370395715221 -112.02454155777228 -0.0
reward =  -74.05878715575346 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.2262e+01, 1.2927e+01, 7.4774e-01, 0.0000e+00, 3.8923e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.2083e+01, 1.3166e+01, 6.9472e-01, 0.0000e+00, 4.9975e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([-74.0588], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.316064029315427 m 99.0 km/h 153.4355585712498 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9485771054071348 40.0 -0.012866376965800463 -102.81870009256667 0.0
reward =  -63.78014357493961 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.2083e+01, 1.3166e+01, 6.9472e-01, 0.0000e+00, 4.9975e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.2274e+01, 1.3367e+01, 5.0000e-01, 0.0000e+00, 5.9181e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([-63.7801], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.07297070942185 m 87.00000000000001 km/h 130.4785600717048 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.30999662118253296 40.0 -2.134370395715221 -92.44367773004727 -0.0
reward =  -54.26805150457996 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2274e+01, 1.3367e+01, 5.0000e-01, 0.0000e+00, 5.9181e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.2366e+01, 1.3030e+01, 4.4436e-01, 0.0000e+00, 6.9556e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([-54.2681], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 25.260973897553075 m 81.0 km/h 118.61139958079269 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9333754821465683 40.0 -0.009340604449578172 -81.21657822002369 0.0
reward =  -42.159294306619834 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.2366e+01, 1.3030e+01, 4.4436e-01, 0.0000e+00, 6.9556e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.2482e+01, 1.3350e+01, 3.0000e-01, 0.0000e+00, 8.0783e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([-42.1593], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 29.19884714436775 m 97.99999999999999 km/h 151.74056805517574 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0330228722082737 40.0 -0.022464881543805087 -70.49047110576616 0.0
reward =  -29.479913115101695 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2482e+01, 1.3350e+01, 3.0000e-01, 0.0000e+00, 8.0783e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.2364e+01, 1.2965e+01, 0.0000e+00, 0.0000e+00, 9.1510e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([-29.4799], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.26147307767419 m 90.0 km/h 137.15360734785463 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8061658941411152 -500 -3.8256405611232442 -60.38588187469648 0.0
reward =  -565.0176883299608 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.2364e+01, 1.2965e+01, 0.0000e+00, 0.0000e+00, 9.1510e+03,
         0.0000e+00, 6.9687e+03]], device='cuda:0') tensor([[3]], device='cuda:0') None tensor([-565.0177], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 9
Sum reward: -1201.7889468628
**************************************Episode 42 done**************************************

state_reset =  tensor([[ 4.0000, 49.5072,  8.5113,  0.5430,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.190090136544338 m 90.0 km/h 144.99329113120618 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.1820110526155401 40.0 -5.0554341629127 -151.92396394538227 0.0
reward =  -116.79738705567942 

state, action, next_state, reward =  tensor([[ 4.0000, 49.5072,  8.5113,  0.5430,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9381e+01, 8.8010e+00, 8.0000e-01, 3.0703e+04, 1.0076e+03,
         0.0000e+00, 1.2811e+04]], device='cuda:0') tensor([-116.7974], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.6
Length, speed, consumption 25.01063101022136 m 86.0 km/h 126.02404710687776 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4129645270675584 40.0 -5.0554341629127 -141.4543974759873 -162.0
reward =  -268.09686711183247 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9381e+01, 8.8010e+00, 8.0000e-01, 3.0703e+04, 1.0076e+03,
         0.0000e+00, 1.2811e+04]], device='cuda:0') tensor([[14]], device='cuda:0') tensor([[4.0000e+00, 4.9318e+01, 9.1323e+00, 7.4640e-01, 0.0000e+00, 2.0546e+03,
         0.0000e+00, 1.2811e+04]], device='cuda:0') tensor([-268.0969], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.06592582072844 m 99.0 km/h 171.31716704775627 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.01605969971067505 40.0 -0.017336455201290346 -132.33951535935876 0.0
reward =  -92.34079211484936 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9318e+01, 9.1323e+00, 7.4640e-01, 0.0000e+00, 2.0546e+03,
         0.0000e+00, 1.2811e+04]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9185e+01, 9.4111e+00, 5.0000e-01, 0.0000e+00, 2.9660e+03,
         0.0000e+00, 1.2811e+04]], device='cuda:0') tensor([-92.3408], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.122378410372654 m 97.0 km/h 146.50240363072925 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9001054963715956 40.0 -0.7043782005082231 -122.64461203179776 0.0
reward =  -84.24909572867759 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9185e+01, 9.4111e+00, 5.0000e-01, 0.0000e+00, 2.9660e+03,
         0.0000e+00, 1.2811e+04]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9092e+01, 9.0814e+00, 5.0000e-01, 6.2623e+03, 3.9355e+03,
         0.0000e+00, 4.1088e+03]], device='cuda:0') tensor([-84.2491], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.207399498876295 m 100.0 km/h 163.852318439492 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8969268236120465 40.0 -0.7043782005082231 -113.5699482122023 -0.0
reward =  -73.37739958909847 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9092e+01, 9.0814e+00, 5.0000e-01, 6.2623e+03, 3.9355e+03,
         0.0000e+00, 4.1088e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9315e+01, 9.1460e+00, 4.2976e-01, 0.0000e+00, 4.8430e+03,
         0.0000e+00, 4.1088e+03]], device='cuda:0') tensor([-73.3774], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.207399498876295 m 94.0 km/h 137.59831732706814 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8969268236120465 40.0 -5.3584919870665395 -103.91605053178161 0.0
reward =  -70.1714693424602 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9315e+01, 9.1460e+00, 4.2976e-01, 0.0000e+00, 4.8430e+03,
         0.0000e+00, 4.1088e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9092e+01, 9.0814e+00, 8.0000e-01, 4.1300e+04, 5.8084e+03,
         0.0000e+00, 1.3417e+04]], device='cuda:0') tensor([-70.1715], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.403614719457646 m 86.0 km/h 129.4099739931224 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8423764026558958 40.0 -0.07440904571398586 -151.3659287220875 0.0
reward =  -112.28271417045737 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9092e+01, 9.0814e+00, 8.0000e-01, 4.1300e+04, 5.8084e+03,
         0.0000e+00, 1.3417e+04]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 4.9021e+01, 8.7499e+00, 0.0000e+00, 0.0000e+00, 1.0634e+03,
         0.0000e+00, 3.2538e+02]], device='cuda:0') tensor([-112.2827], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.259304778975952 m 93.0 km/h 141.19341391240545 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9472585772234597 -500 -23.746210790450785 -141.58813332377423 0.0
reward =  -664.3870855370014 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9021e+01, 8.7499e+00, 0.0000e+00, 0.0000e+00, 1.0634e+03,
         0.0000e+00, 3.2538e+02]], device='cuda:0') tensor([[21]], device='cuda:0') None tensor([-664.3871], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 8
Sum reward: -1481.7028106500563
**************************************Episode 43 done**************************************

state_reset =  tensor([[ 4.0000, 50.1406,  8.7194,  0.6544,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.961131452126757 m 87.0 km/h 128.90492683309876 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.026033788276673294 40.0 -0.009753374387446412 -151.25746284739583 0.0
reward =  -111.2411824335066 

state, action, next_state, reward =  tensor([[ 4.0000, 50.1406,  8.7194,  0.6544,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9962e+01, 8.9543e+00, 5.0000e-01, 0.0000e+00, 1.0743e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-111.2412], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.436861934358575 m 94.0 km/h 145.24163838776343 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9871481093268608 40.0 -1.2101389803347493 -141.5156859363649 0.0
reward =  -103.7129730260265 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9962e+01, 8.9543e+00, 5.0000e-01, 0.0000e+00, 1.0743e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9860e+01, 8.6368e+00, 8.0000e-01, 5.1203e+03, 2.0484e+03,
         0.0000e+00, 5.1203e+03]], device='cuda:0') tensor([-103.7130], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.79989491954658 m 91.0 km/h 140.03161967899933 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7601484923885297 40.0 -1.643675109110601 -131.30913410006073 0.0
reward =  -92.1926607167828 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9860e+01, 8.6368e+00, 8.0000e-01, 5.1203e+03, 2.0484e+03,
         0.0000e+00, 5.1203e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0089e+01, 8.6914e+00, 8.0000e-01, 8.6707e+02, 3.0691e+03,
         0.0000e+00, 5.9874e+03]], device='cuda:0') tensor([-92.1927], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.21174983645462 m 81.0 km/h 113.09510476142448 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6322408778383234 40.0 -0.0251508069915431 -120.10391195052536 0.0
reward =  -79.49682187967858 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0089e+01, 8.6914e+00, 8.0000e-01, 8.6707e+02, 3.0691e+03,
         0.0000e+00, 5.9874e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0041e+01, 9.0364e+00, 5.0000e-01, 0.0000e+00, 4.1896e+03,
         0.0000e+00, 5.9874e+03]], device='cuda:0') tensor([-79.4968], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.21174983645462 m 91.0 km/h 143.46120116361516 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6322408778383234 40.0 -2.077704058907524 -110.13003289434549 0.0
reward =  -72.83997783109133 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0041e+01, 9.0364e+00, 5.0000e-01, 0.0000e+00, 4.1896e+03,
         0.0000e+00, 5.9874e+03]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0089e+01, 8.6914e+00, 5.0000e-01, 8.6806e+02, 5.1870e+03,
         0.0000e+00, 6.8554e+03]], device='cuda:0') tensor([-72.8400], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.79989491954658 m 81.0 km/h 116.52474436776492 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7601484923885297 40.0 -0.014887200407797003 -98.66341293010257 0.0
reward =  -59.438448622898896 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0089e+01, 8.6914e+00, 5.0000e-01, 8.6806e+02, 5.1870e+03,
         0.0000e+00, 6.8554e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9860e+01, 8.6368e+00, 3.0000e-01, 0.0000e+00, 6.3337e+03,
         0.0000e+00, 6.8554e+03]], device='cuda:0') tensor([-59.4384], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.436861934358575 m 94.0 km/h 143.1252073399823 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9871481093268608 40.0 -0.2465009945659731 -88.92163601907163 0.0
reward =  -48.18098890431074 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9860e+01, 8.6368e+00, 3.0000e-01, 0.0000e+00, 6.3337e+03,
         0.0000e+00, 6.8554e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9962e+01, 8.9543e+00, 8.0000e-01, 7.9298e+03, 7.3078e+03,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([-48.1810], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.6
Length, speed, consumption 25.019745901227473 m 91.0 km/h 135.79325412684 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.11996165616074345 40.0 -0.2465009945659731 -79.023714563641 -162.0
reward =  -201.3901772143677 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9962e+01, 8.9543e+00, 8.0000e-01, 7.9298e+03, 7.3078e+03,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([[14]], device='cuda:0') tensor([[4.0000e+00, 5.0119e+01, 8.7031e+00, 7.4222e-01, 0.0000e+00, 8.2976e+03,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([-201.3902], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.00131818505674 m 87.0 km/h 129.58288986846688 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8073695205923566 40.0 -0.03871215004371591 -68.67834152154853 0.0
reward =  -29.524423192184607 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0119e+01, 8.7031e+00, 7.4222e-01, 0.0000e+00, 8.2976e+03,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 4.9903e+01, 8.6083e+00, 3.0000e-01, 0.0000e+00, 9.3322e+03,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([-29.5244], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.040376054164792 m 95.0 km/h 145.4120590225864 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.909096550561497 40.0 -0.2465009945659731 -59.18935691154924 -162.0
reward =  -180.5267613555537 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9903e+01, 8.6083e+00, 3.0000e-01, 0.0000e+00, 9.3322e+03,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 5.0104e+01, 8.7659e+00, 2.3808e-01, 0.0000e+00, 1.0281e+04,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([-180.5268], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 26.04668107466232 m 89.00000000000001 km/h 145.4383058055932 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.0002530390774528496 40.0 -0.2465009945659731 -48.6536207465173 -270.0
reward =  -278.89986870200585 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0104e+01, 8.7659e+00, 2.3808e-01, 0.0000e+00, 1.0281e+04,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9924e+01, 8.9990e+00, 1.7365e-01, 0.0000e+00, 1.1335e+04,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([-278.8999], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.140066849744613 m 82.0 km/h 111.87785893559153 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8084212610355113 40.0 -1.7727120424989755 -37.61651822711723 0.0
reward =  -0.1976515306517186 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9924e+01, 8.9990e+00, 1.7365e-01, 0.0000e+00, 1.1335e+04,
         0.0000e+00, 3.1930e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9907e+01, 8.6489e+00, 8.0000e-01, 9.5141e+03, 1.2438e+04,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([-0.1977], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.061322773119926 m 89.0 km/h 134.61445994211803 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7424191091193608 40.0 -1.7727120424989755 -35.454240849979506 -0.0
reward =  3.515466216640881 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9907e+01, 8.6489e+00, 8.0000e-01, 9.5141e+03, 1.2438e+04,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0129e+01, 8.7075e+00, 7.4263e-01, 0.0000e+00, 7.9749e+02,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([3.5155], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.437828294832833 m 80.99999999999999 km/h 112.96776666804675 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9737492185869976 40.0 -1.7727120424989755 -142.71941164498872 -0.0
reward =  -105.4658729060747 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0129e+01, 8.7075e+00, 7.4263e-01, 0.0000e+00, 7.9749e+02,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 4.9943e+01, 8.4993e+00, 6.9375e-01, 0.0000e+00, 1.9281e+03,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([-105.4659], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.87278606972189 m 87.0 km/h 137.91798224176392 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6618170739029884 40.0 -0.013306813721768673 -132.01343120234517 0.0
reward =  -91.36492094216396 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9943e+01, 8.4993e+00, 6.9375e-01, 0.0000e+00, 1.9281e+03,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9901e+01, 8.8546e+00, 5.0000e-01, 0.0000e+00, 2.9987e+03,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([-91.3649], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.21750448679595 m 84.0 km/h 117.23714346410652 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7944534970662859 40.0 -1.7771297274044338 -121.20592927943262 0.0
reward =  -82.18860550977078 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9901e+01, 8.8546e+00, 5.0000e-01, 0.0000e+00, 2.9987e+03,
         0.0000e+00, 6.2454e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0122e+01, 8.9288e+00, 8.0000e-01, 1.4829e+04, 4.0794e+03,
         0.0000e+00, 6.2543e+03]], device='cuda:0') tensor([-82.1886], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.393491556706646 m 88.0 km/h 146.21886064690113 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5498562015336124 40.0 -4.815044875533081 -110.81768273350717 0.0
reward =  -76.18258381057387 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0122e+01, 8.9288e+00, 8.0000e-01, 1.4829e+04, 4.0794e+03,
         0.0000e+00, 6.2543e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0203e+01, 8.5954e+00, 8.0000e-01, 6.0758e+03, 5.1182e+03,
         0.0000e+00, 1.2330e+04]], device='cuda:0') tensor([-76.1826], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.35173807434854 m 99.0 km/h 146.3592797363942 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.048209568637465124 40.0 -0.07368969026423917 -101.59886888828953 0.0
reward =  -61.72076814719124 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0203e+01, 8.5954e+00, 8.0000e-01, 6.0758e+03, 5.1182e+03,
         0.0000e+00, 1.2330e+04]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 5.0014e+01, 8.7950e+00, 0.0000e+00, 0.0000e+00, 6.0401e+03,
         0.0000e+00, 1.2330e+04]], device='cuda:0') tensor([-61.7208], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.177283014926868 m 81.0 km/h 109.16737650941846 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9724899578803079 -500 -0.8988037644883972 -96.30089751066161 0.0
reward =  -598.1721912330303 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0014e+01, 8.7950e+00, 0.0000e+00, 0.0000e+00, 6.0401e+03,
         0.0000e+00, 1.2330e+04]], device='cuda:0') tensor([[0]], device='cuda:0') None tensor([-598.1722], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 19
Sum reward: -2269.2214117412227
**************************************Episode 44 done**************************************

state_reset =  tensor([[ 4.0000, 50.5840,  9.9983,  0.3367,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 26.362781147471672 m 94.0 km/h 102.83080340322836 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2988081635794183 40.0 -27.0 -151.90361573075555 0.0
reward =  -139.20242389433497 

state, action, next_state, reward =  tensor([[ 4.0000, 50.5840,  9.9983,  0.3367,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0729e+01, 9.7020e+00, 2.9060e-01, 2.4300e+03, 1.0096e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-139.2024], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.6
Length, speed, consumption 25.2266475519788 m 98.0 km/h 151.92689436680527 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.997297291727051 40.0 -27.0 -142.6366839769674 0.0
reward =  -128.63938668524034 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0729e+01, 9.7020e+00, 2.9060e-01, 2.4300e+03, 1.0096e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[14]], device='cuda:0') tensor([[4.0000e+00, 5.0877e+01, 9.9734e+00, 2.2542e-01, 1.6200e+03, 1.9363e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-128.6394], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.2266475519788 m 83.99999999999999 km/h 125.06461634715407 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.997297291727051 40.0 -27.0 -131.82526359754792 0.0
reward =  -119.82256088927497 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0877e+01, 9.9734e+00, 2.2542e-01, 1.6200e+03, 1.9363e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0729e+01, 9.7020e+00, 1.7176e-01, 2.4300e+03, 3.0175e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-119.8226], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.716800728204884 m 82.0 km/h 130.01489909390372 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6077609884353006 40.0 -3.4996573177839565 -120.09593644857992 0.0
reward =  -84.20335475479918 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0729e+01, 9.7020e+00, 1.7176e-01, 2.4300e+03, 3.0175e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0488e+01, 9.7078e+00, 8.0000e-01, 9.6993e+03, 4.1904e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([-84.2034], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.148155672325558 m 99.0 km/h 164.84199882119475 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6645188337172637 40.0 -3.4996573177839565 -110.95115256773425 -243.0
reward =  -316.78629105180096 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0488e+01, 9.7078e+00, 8.0000e-01, 9.6993e+03, 4.1904e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0714e+01, 9.7416e+00, 7.2950e-01, 0.0000e+00, 5.1049e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([-316.7863], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.125211590263547 m 96.0 km/h 138.99119953041733 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6619724140313616 40.0 -0.03701078988932145 -101.52919822138543 0.0
reward =  -62.22818142530611 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0714e+01, 9.7416e+00, 7.2950e-01, 0.0000e+00, 5.1049e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 5.0489e+01, 9.7088e+00, 3.0000e-01, 0.0000e+00, 6.0471e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([-62.2282], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.209725031832974 m 98.0 km/h 144.27402444823332 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6142686206568032 40.0 -3.4996573177839565 -92.26848290356924 -162.0
reward =  -217.1538716006964 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0489e+01, 9.7088e+00, 3.0000e-01, 0.0000e+00, 6.0471e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 5.0715e+01, 9.7196e+00, 2.3814e-01, 0.0000e+00, 6.9732e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([-217.1539], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.223105262184305 m 100.0 km/h 165.80467998980467 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6146435439551552 40.0 -2.4565551531553975 -83.18816500918288 0.0
reward =  -46.259363706293435 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0715e+01, 9.7196e+00, 2.3814e-01, 0.0000e+00, 6.9732e+03,
         0.0000e+00, 9.6993e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0488e+01, 9.7087e+00, 8.0000e-01, 8.9326e+03, 7.8812e+03,
         0.0000e+00, 7.6131e+03]], device='cuda:0') tensor([-46.2594], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 27.29228748678827 m 79.99999999999999 km/h 114.500374674063 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.3216476750453154 40.0 -26.27569714778383 -70.90663564012817 0.0
reward =  -57.503980462957315 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0488e+01, 9.7087e+00, 8.0000e-01, 8.9326e+03, 7.8812e+03,
         0.0000e+00, 7.6131e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0638e+01, 9.4027e+00, 8.0000e-01, 2.2500e+03, 9.1093e+03,
         0.0000e+00, 7.2430e+01]], device='cuda:0') tensor([-57.5040], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.334670745286086 m 89.0 km/h 131.41927618646915 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0086435111079073 40.0 -1.4103221267846349 -60.65890365327088 0.0
reward =  -23.077869291163424 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0638e+01, 9.4027e+00, 8.0000e-01, 2.2500e+03, 9.1093e+03,
         0.0000e+00, 7.2430e+01]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0497e+01, 9.1208e+00, 8.0000e-01, 5.4482e+03, 1.0134e+04,
         0.0000e+00, 5.5206e+03]], device='cuda:0') tensor([-23.0779], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.147742996705137 m 87.0 km/h 144.74839484496437 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9781743970100802 40.0 -1.4103221267846349 -50.25294103394462 -270.0
reward =  -280.6850887637192 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0497e+01, 9.1208e+00, 8.0000e-01, 5.4482e+03, 1.0134e+04,
         0.0000e+00, 5.5206e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.0659e+01, 9.3692e+00, 7.3809e-01, 0.0000e+00, 1.1175e+04,
         0.0000e+00, 5.5206e+03]], device='cuda:0') tensor([-280.6851], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.147742996705137 m 87.0 km/h 115.13466351029219 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9781743970100802 40.0 -3.4151778648211257 -39.84697841461837 0.0
reward =  -4.240330676449574 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0659e+01, 9.3692e+00, 7.3809e-01, 0.0000e+00, 1.1175e+04,
         0.0000e+00, 5.5206e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0497e+01, 9.1208e+00, 8.0000e-01, 1.0694e+04, 1.2215e+04,
         0.0000e+00, 9.5304e+03]], device='cuda:0') tensor([-4.2403], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.247484291443392 m 93.0 km/h 115.24961844982253 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8600420647102828 40.0 -1.1203435993966342 -152.22678027427997 0.0
reward =  -114.2071659383869 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0497e+01, 9.1208e+00, 8.0000e-01, 1.0694e+04, 1.2215e+04,
         0.0000e+00, 9.5304e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0290e+01, 8.9764e+00, 8.0000e-01, 2.0950e+03, 9.7732e+02,
         0.0000e+00, 4.9407e+03]], device='cuda:0') tensor([-114.2072], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.072690101359594 m 92.00000000000001 km/h 164.5144823398598 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8909848568653501 40.0 -1.1203435993966342 -142.41572762592187 -0.0
reward =  -104.42705608218387 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0290e+01, 8.9764e+00, 8.0000e-01, 2.0950e+03, 9.7732e+02,
         0.0000e+00, 4.9407e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0260e+01, 8.6267e+00, 7.2985e-01, 0.0000e+00, 1.9584e+03,
         0.0000e+00, 4.9407e+03]], device='cuda:0') tensor([-104.4271], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.072690101359594 m 92.00000000000001 km/h 115.4881314110368 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8909848568653501 40.0 -0.06806051230927394 -132.60467497756377 0.0
reward =  -91.7817506330077 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0260e+01, 8.6267e+00, 7.2985e-01, 0.0000e+00, 1.9584e+03,
         0.0000e+00, 4.9407e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.0290e+01, 8.9764e+00, 0.0000e+00, 0.0000e+00, 2.9395e+03,
         0.0000e+00, 4.9407e+03]], device='cuda:0') tensor([-91.7818], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.1307966966879 m 92.00000000000001 km/h 137.681246760577 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9490923857870698 -500 -5.461413542768987 -122.77088496581634 0.0
reward =  -629.1813908943724 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0290e+01, 8.9764e+00, 0.0000e+00, 0.0000e+00, 2.9395e+03,
         0.0000e+00, 4.9407e+03]], device='cuda:0') tensor([[10]], device='cuda:0') None tensor([-629.1814], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 16
Sum reward: -2419.4000667499868
**************************************Episode 45 done**************************************

state_reset =  tensor([[ 5.0000, 50.6743, 10.9027,  0.5375,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 27.852094515811686 m 88.0 km/h 99.85456922971272 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3587334508137137 40.0 -0.04901836700251466 -150.60596133444068 0.0
reward =  -110.29624625062948 

state, action, next_state, reward =  tensor([[ 5.0000, 50.6743, 10.9027,  0.5375,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   50.8984,   10.7256,    0.0000,    0.0000, 1139.4038,
            0.0000,    0.0000]], device='cuda:0') tensor([-110.2962], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.396184194276252 m 99.0 km/h 126.05923965777745 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9956902015120374 -500 -4.67897084036872 -141.37098526379475 0.0
reward =  -645.0542659026514 

state, action, next_state, reward =  tensor([[   3.0000,   50.8984,   10.7256,    0.0000,    0.0000, 1139.4038,
            0.0000,    0.0000]], device='cuda:0') tensor([[3]], device='cuda:0') None tensor([-645.0543], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -755.3505121532809
**************************************Episode 46 done**************************************

state_reset =  tensor([[ 4.0000, 51.3295, 11.1775,  0.2217,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 29.471558479228047 m 82.0 km/h 125.46695591930708 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.1001364855758706 40.0 -5.872329783740057 -149.0612670091194 0.0
reward =  -116.03373327843534 

state, action, next_state, reward =  tensor([[ 4.0000, 51.3295, 11.1775,  0.2217,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.1113e+01, 1.0933e+01, 5.0000e-01, 1.4445e+04, 1.2939e+03,
         0.0000e+00, 1.4445e+04]], device='cuda:0') tensor([-116.0337], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 26.713043568159318 m 85.0 km/h 131.95303553207765 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7991025014975295 40.0 -5.254306602090398 -137.74750738025193 0.0
reward =  -103.80091648383986 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.1113e+01, 1.0933e+01, 5.0000e-01, 1.4445e+04, 1.2939e+03,
         0.0000e+00, 1.4445e+04]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.1151e+01, 1.0555e+01, 8.0000e-01, 1.5239e+04, 2.4252e+03,
         0.0000e+00, 1.3209e+04]], device='cuda:0') tensor([-103.8009], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 26.541417384723097 m 89.99999999999999 km/h 129.82535773136857 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.782095195184577 40.0 -0.04413988264171898 -127.13094042636268 0.0
reward =  -86.39298511381983 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.1151e+01, 1.0555e+01, 8.0000e-01, 1.5239e+04, 2.4252e+03,
         0.0000e+00, 1.3209e+04]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.1110e+01, 1.0930e+01, 3.0000e-01, 0.0000e+00, 3.4869e+03,
         0.0000e+00, 1.3209e+04]], device='cuda:0') tensor([-86.3930], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.3 0.0
Length, speed, consumption 27.484585202512708 m 81.0 km/h 149.78629649350432 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0318722116506949 40.0 -26.949083035891054 -114.91556922524593 0.0
reward =  -102.89652447278768 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1110e+01, 1.0930e+01, 3.0000e-01, 0.0000e+00, 3.4869e+03,
         0.0000e+00, 1.3209e+04]], device='cuda:0') tensor([[5]], device='cuda:0') tensor([[2.0000e+00, 5.0898e+01, 1.0726e+01, 3.0000e-01, 9.8804e+02, 4.7084e+03,
         0.0000e+00, 5.0917e+00]], device='cuda:0') tensor([-102.8965], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.396184194276252 m 88.0 km/h 102.93763330149878 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9956902015120374 40.0 -2.4942526197071753 -104.52622114576927 0.0
reward =  -66.0247835639644 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0898e+01, 1.0726e+01, 3.0000e-01, 9.8804e+02, 4.7084e+03,
         0.0000e+00, 5.0917e+00]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.1012e+01, 1.1040e+01, 8.0000e-01, 7.6834e+03, 5.7474e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([-66.0248], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.398051548204624 m 85.99999999999999 km/h 157.49424211782423 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5868393251469836 40.0 -2.4942526197071753 -93.89447863721848 -81.0
reward =  -137.97557058207263 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.1012e+01, 1.1040e+01, 8.0000e-01, 7.6834e+03, 5.7474e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.0789e+01, 1.1112e+01, 7.3197e-01, 0.0000e+00, 6.8106e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([-137.9756], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.313188500721544 m 89.0 km/h 115.46617000071093 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9906438924801 40.0 -2.4942526197071753 -83.6554360976008 -0.0
reward =  -45.15904482482787 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0789e+01, 1.1112e+01, 7.3197e-01, 0.0000e+00, 6.8106e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0936e+01, 1.1388e+01, 6.8226e-01, 0.0000e+00, 7.8345e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([-45.1590], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.62199315630819 m 80.0 km/h 109.3868514564864 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9659262770065735 40.0 -0.013273877861559601 -71.67553917726211 0.0
reward =  -32.65473933213024 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0936e+01, 1.1388e+01, 6.8226e-01, 0.0000e+00, 7.8345e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0699e+01, 1.1327e+01, 5.0000e-01, 0.0000e+00, 9.0324e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([-32.6547], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 26.336830327341634 m 95.0 km/h 173.561332157704 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2440724064631958 40.0 -2.4942526197071753 -61.69526663216422 -270.0
reward =  -293.9454468454082 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0699e+01, 1.1327e+01, 5.0000e-01, 0.0000e+00, 9.0324e+03,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.0881e+01, 1.1088e+01, 4.2226e-01, 0.0000e+00, 1.0030e+04,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([-293.9454], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.02394240313652 m 98.0 km/h 174.3288697005467 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9767927865345228 40.0 -1.735155062358781 -52.50279799427734 0.0
reward =  -15.21474584317064 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0881e+01, 1.1088e+01, 4.2226e-01, 0.0000e+00, 1.0030e+04,
         0.0000e+00, 7.6885e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0683e+01, 1.0919e+01, 5.0000e-01, 6.4321e+03, 1.0950e+04,
         0.0000e+00, 6.1703e+03]], device='cuda:0') tensor([-15.2147], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.02394240313652 m 92.00000000000001 km/h 118.48816521501828 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9767927865345228 40.0 -1.735155062358781 -42.71082053218044 -270.0
reward =  -273.4691828080047 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0683e+01, 1.0919e+01, 5.0000e-01, 6.4321e+03, 1.0950e+04,
         0.0000e+00, 6.1703e+03]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 5.0881e+01, 1.1088e+01, 4.4957e-01, 0.0000e+00, 1.1929e+04,
         0.0000e+00, 6.1703e+03]], device='cuda:0') tensor([-273.4692], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.14911088103534 m 94.0 km/h 114.9275848532581 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.16086745309968362 40.0 -0.04004189184258822 -34.70310124717562 0.0
reward =  5.095989407882108 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0881e+01, 1.1088e+01, 4.4957e-01, 0.0000e+00, 1.1929e+04,
         0.0000e+00, 6.1703e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 5.0718e+01, 1.1335e+01, 0.0000e+00, 0.0000e+00, 1.6239e+02,
         0.0000e+00, 6.1703e+03]], device='cuda:0') tensor([5.0960], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.362875938802485 m 90.0 km/h 131.48590461616794 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0371451855583669 -500 -20.912661463703806 -149.83099452951285 0.0
reward =  -669.7065108076583 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0718e+01, 1.1335e+01, 0.0000e+00, 0.0000e+00, 1.6239e+02,
         0.0000e+00, 6.1703e+03]], device='cuda:0') tensor([[7]], device='cuda:0') None tensor([-669.7065], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 13
Sum reward: -1938.1781945482376
**************************************Episode 47 done**************************************

state_reset =  tensor([[ 4.0000, 50.8170,  8.7823,  0.4415,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 25.386449529213422 m 90.0 km/h 129.37179071679188 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6146677269894862 40.0 -0.03856900649002934 -151.84542018831465 0.0
reward =  -112.49865692179416 

state, action, next_state, reward =  tensor([[ 4.0000, 50.8170,  8.7823,  0.4415,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[4]], device='cuda:0') tensor([[   2.0000,   50.5928,    8.7144,    0.0000,    0.0000, 1015.4580,
            0.0000,    0.0000]], device='cuda:0') tensor([-112.4987], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 26.1950745170045 m 94.0 km/h 157.02800832873032 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5820979071394796 -500 -16.509069258432064 -141.81326399031292 0.0
reward =  -658.9044311558844 

state, action, next_state, reward =  tensor([[   2.0000,   50.5928,    8.7144,    0.0000,    0.0000, 1015.4580,
            0.0000,    0.0000]], device='cuda:0') tensor([[3]], device='cuda:0') None tensor([-658.9044], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -771.4030880776785
**************************************Episode 48 done**************************************

state_reset =  tensor([[ 5.0000, 49.3206,  9.0723,  0.7157,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.11554419174815 m 100.0 km/h 136.13738774547738 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.204670778660106 40.0 -0.015528021623463506 -152.59840409097066 0.0
reward =  -112.81860289125423 

state, action, next_state, reward =  tensor([[ 5.0000, 49.3206,  9.0723,  0.7157,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9144e+01, 9.3088e+00, 5.0000e-01, 0.0000e+00, 9.4016e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-112.8186], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.01188180005514 m 84.99999999999999 km/h 149.3917140496588 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7714810274052317 40.0 -18.032237055077513 -142.00513650506494 0.0
reward =  -119.26589253273723 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9144e+01, 9.3088e+00, 5.0000e-01, 0.0000e+00, 9.4016e+02,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 4.9205e+01, 9.6397e+00, 5.0000e-01, 8.9678e+02, 1.9995e+03,
         0.0000e+00, 8.9678e+02]], device='cuda:0') tensor([-119.2659], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.552648157671864 m 93.0 km/h 117.67691605542429 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7658087897363375 40.0 -6.531292606854017 -132.11378883112747 0.0
reward =  -99.41089022771783 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9205e+01, 9.6397e+00, 5.0000e-01, 8.9678e+02, 1.9995e+03,
         0.0000e+00, 8.9678e+02]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9150e+01, 9.2985e+00, 8.0000e-01, 1.4866e+04, 2.9886e+03,
         0.0000e+00, 1.5763e+04]], device='cuda:0') tensor([-99.4109], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.08139322940787 m 100.0 km/h 180.87705101045316 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.19899854099121178 40.0 -6.531292606854017 -130.62585213708036 -270.0
reward =  -366.95814620294317 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9150e+01, 9.2985e+00, 8.0000e-01, 1.4866e+04, 2.9886e+03,
         0.0000e+00, 1.5763e+04]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 4.9321e+01, 9.0723e+00, 7.2285e-01, 0.0000e+00, 7.5414e+02,
         0.0000e+00, 1.5763e+04]], device='cuda:0') tensor([-366.9581], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 26.11554419174815 m 99.0 km/h 133.90053812714996 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.204670778660106 40.0 -0.06633752744332096 -144.9620736071882 0.0
reward =  -105.23308191329161 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9321e+01, 9.0723e+00, 7.2285e-01, 0.0000e+00, 7.5414e+02,
         0.0000e+00, 1.5763e+04]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 4.9144e+01, 9.3088e+00, 0.0000e+00, 0.0000e+00, 1.7038e+03,
         0.0000e+00, 1.5763e+04]], device='cuda:0') tensor([-105.2331], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 26.11554419174815 m 89.99999999999999 km/h 157.03937806910645 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.204670778660106 -500 -6.531292606854017 -134.51585593048895 -270.0
reward =  -910.8424777586829 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9144e+01, 9.3088e+00, 0.0000e+00, 0.0000e+00, 1.7038e+03,
         0.0000e+00, 1.5763e+04]], device='cuda:0') tensor([[21]], device='cuda:0') None tensor([-910.8425], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 6
Sum reward: -1714.5290915266269
**************************************Episode 49 done**************************************

state_reset =  tensor([[ 5.0000, 50.4881,  9.8678,  0.3102,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.899505551192295 m 85.00000000000001 km/h 123.47676997469955 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0350904910154908 40.0 -6.329720289495432 -151.0307976489068 0.0
reward =  -116.32542744738674 

state, action, next_state, reward =  tensor([[ 5.0000, 50.4881,  9.8678,  0.3102,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0630e+01, 1.0158e+01, 8.0000e-01, 1.5359e+04, 1.0969e+03,
         0.0000e+00, 1.5359e+04]], device='cuda:0') tensor([-116.3254], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 26.435479938144713 m 94.0 km/h 151.4807471522972 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0466233979303134 40.0 -1.210773204217976 -140.90657128961732 0.0
reward =  -103.16396789176561 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0630e+01, 1.0158e+01, 8.0000e-01, 1.5359e+04, 1.0969e+03,
         0.0000e+00, 1.5359e+04]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0451e+01, 9.9119e+00, 8.0000e-01, 6.5528e+03, 2.1093e+03,
         0.0000e+00, 5.1215e+03]], device='cuda:0') tensor([-103.1640], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.81408230426683 m 83.99999999999999 km/h 80.90114546320874 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2416515764864022 40.0 -1.9625931821168012 -129.84339315921727 0.0
reward =  -91.56433476484767 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0451e+01, 9.9119e+00, 8.0000e-01, 6.5528e+03, 2.1093e+03,
         0.0000e+00, 5.1215e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0327e+01, 1.0220e+01, 8.0000e-01, 1.5036e+03, 3.2157e+03,
         0.0000e+00, 6.6252e+03]], device='cuda:0') tensor([-91.5643], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.81408230426683 m 87.0 km/h 173.21187667028644 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2416515764864022 40.0 -0.022395738706729108 -119.16170392986547 0.0
reward =  -79.42575124505859 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0327e+01, 1.0220e+01, 8.0000e-01, 1.5036e+03, 3.2157e+03,
         0.0000e+00, 6.6252e+03]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0451e+01, 9.9119e+00, 5.0000e-01, 0.0000e+00, 4.2838e+03,
         0.0000e+00, 6.6252e+03]], device='cuda:0') tensor([-79.4258], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.81408230426683 m 81.00000000000001 km/h 75.33712254324861 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2416515764864022 40.0 -2.6627063076001014 -107.68877846130243 0.0
reward =  -70.10983319241613 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0451e+01, 9.9119e+00, 5.0000e-01, 0.0000e+00, 4.2838e+03,
         0.0000e+00, 6.6252e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0327e+01, 1.0220e+01, 5.0000e-01, 1.4002e+03, 5.4311e+03,
         0.0000e+00, 8.0254e+03]], device='cuda:0') tensor([-70.1098], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.092462813391986 m 85.99999999999999 km/h 175.90759428190748 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8739668321072404 40.0 -0.04249327420389114 -97.1849568184872 0.0
reward =  -58.10141692479833 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0327e+01, 1.0220e+01, 5.0000e-01, 1.4002e+03, 5.4311e+03,
         0.0000e+00, 8.0254e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.0264e+01, 9.8811e+00, 0.0000e+00, 0.0000e+00, 6.4815e+03,
         0.0000e+00, 8.0254e+03]], device='cuda:0') tensor([-58.1014], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.167453594530816 m 91.0 km/h 90.17220232391372 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8724520625048294 -500 -5.252661928385391 -87.22860155032114 0.0
reward =  -591.6088114162018 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0264e+01, 9.8811e+00, 0.0000e+00, 0.0000e+00, 6.4815e+03,
         0.0000e+00, 8.0254e+03]], device='cuda:0') tensor([[7]], device='cuda:0') None tensor([-591.6088], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 7
Sum reward: -1110.2995428824747
**************************************Episode 50 done**************************************

state_reset =  tensor([[ 5.0000, 50.7136,  9.7416,  0.4613,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.148155672325558 m 88.0 km/h 122.0970976247344 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6645188337172637 40.0 -14.170548958245602 -151.71211813404864 0.0
reward =  -126.54718592601151 

state, action, next_state, reward =  tensor([[ 5.0000, 50.7136,  9.7416,  0.4613,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0488e+01, 9.7078e+00, 5.0000e-01, 1.2829e+03, 1.0288e+03,
         0.0000e+00, 1.2829e+03]], device='cuda:0') tensor([-126.5472], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.148155672325558 m 85.0 km/h 135.88659873671548 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.6645188337172637 40.0 -14.170548958245602 -141.06113455518135 0.0
reward =  -114.56716467970969 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0488e+01, 9.7078e+00, 5.0000e-01, 1.2829e+03, 1.0288e+03,
         0.0000e+00, 1.2829e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0714e+01, 9.7416e+00, 4.4188e-01, 0.0000e+00, 2.0939e+03,
         0.0000e+00, 1.2829e+03]], device='cuda:0') tensor([-114.5672], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.125211590263547 m 93.0 km/h 132.61786418573578 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6619724140313616 40.0 -2.218194460543225 -131.33524619765998 0.0
reward =  -94.21541307223457 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0714e+01, 9.7416e+00, 4.4188e-01, 0.0000e+00, 2.0939e+03,
         0.0000e+00, 1.2829e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0489e+01, 9.7088e+00, 8.0000e-01, 5.8534e+03, 3.0665e+03,
         0.0000e+00, 7.1364e+03]], device='cuda:0') tensor([-94.2154], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.215504316561262 m 90.0 km/h 149.25401065925152 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4681330856773711 40.0 -3.573059914558503 -121.24904447103546 0.0
reward =  -84.3539712999166 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0489e+01, 9.7088e+00, 8.0000e-01, 5.8534e+03, 3.0665e+03,
         0.0000e+00, 7.1364e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0713e+01, 9.6598e+00, 8.0000e-01, 2.7097e+03, 4.0751e+03,
         0.0000e+00, 9.8461e+03]], device='cuda:0') tensor([-84.3540], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.215504316561262 m 81.99999999999999 km/h 107.09963809617895 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4681330856773711 40.0 -0.025407191519189888 -110.17882306376467 0.0
reward =  -70.67236334096123 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0713e+01, 9.6598e+00, 8.0000e-01, 2.7097e+03, 4.0751e+03,
         0.0000e+00, 9.8461e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0489e+01, 9.7088e+00, 5.0000e-01, 0.0000e+00, 5.1821e+03,
         0.0000e+00, 9.8461e+03]], device='cuda:0') tensor([-70.6724], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.215504316561262 m 83.00000000000001 km/h 135.64182529345013 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4681330856773711 40.0 -4.842660754886707 -99.24197781802727 0.0
reward =  -63.6165054872366 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0489e+01, 9.7088e+00, 5.0000e-01, 0.0000e+00, 5.1821e+03,
         0.0000e+00, 9.8461e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0713e+01, 9.6598e+00, 8.0000e-01, 1.5163e+04, 6.2758e+03,
         0.0000e+00, 1.2385e+04]], device='cuda:0') tensor([-63.6165], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.222839522177388 m 90.0 km/h 122.21464095731807 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4706795053632732 40.0 -19.601759337295295 -96.85321509773414 0.0
reward =  -76.9256539403927 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0713e+01, 9.6598e+00, 8.0000e-01, 1.5163e+04, 6.2758e+03,
         0.0000e+00, 1.2385e+04]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[  2.0000,  50.4884,   9.7078,   0.8000, 739.8241, 770.0373,   0.0000,
         739.8241]], device='cuda:0') tensor([-76.9257], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.222839522177388 m 93.0 km/h 155.77685350277238 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4706795053632732 40.0 -0.43440048091649536 -144.53594709638574 0.0
reward =  -104.49966807193897 

state, action, next_state, reward =  tensor([[  2.0000,  50.4884,   9.7078,   0.8000, 739.8241, 770.0373,   0.0000,
         739.8241]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0713e+01, 9.6598e+00, 8.0000e-01, 2.8290e+03, 1.7464e+03,
         0.0000e+00, 3.5688e+03]], device='cuda:0') tensor([-104.4997], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.22852928907273 m 84.0 km/h 110.83835686204414 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.46850800897572303 40.0 -0.02524440691760753 -133.72372025821173 0.0
reward =  -94.21747267410507 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0713e+01, 9.6598e+00, 8.0000e-01, 2.8290e+03, 1.7464e+03,
         0.0000e+00, 3.5688e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0488e+01, 9.7087e+00, 5.0000e-01, 0.0000e+00, 2.8276e+03,
         0.0000e+00, 3.5688e+03]], device='cuda:0') tensor([-94.2175], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 27.29228748678827 m 83.00000000000001 km/h 119.99695489196296 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.3216476750453154 40.0 -1.6133973814787168 -121.88610158924334 0.0
reward =  -83.82114664576737 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0488e+01, 9.7087e+00, 5.0000e-01, 0.0000e+00, 2.8276e+03,
         0.0000e+00, 3.5688e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0638e+01, 9.4027e+00, 5.0000e-01, 2.3580e+03, 4.0114e+03,
         0.0000e+00, 5.9268e+03]], device='cuda:0') tensor([-83.8211], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.91347551646588 m 85.0 km/h 135.24304548679956 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.482077290426353 40.0 -4.166980628696469 -110.48745313521071 0.0
reward =  -74.17235647348083 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0638e+01, 9.4027e+00, 5.0000e-01, 2.3580e+03, 4.0114e+03,
         0.0000e+00, 5.9268e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0523e+01, 9.7380e+00, 8.0000e-01, 5.1072e+03, 5.1513e+03,
         0.0000e+00, 1.1034e+04]], device='cuda:0') tensor([-74.1724], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.91347551646588 m 90.0 km/h 126.74227842378501 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.482077290426353 40.0 -18.822708862425607 -99.72206292862437 0.0
reward =  -79.02684908147633 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0523e+01, 9.7380e+00, 8.0000e-01, 5.1072e+03, 5.1513e+03,
         0.0000e+00, 1.1034e+04]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0638e+01, 9.4027e+00, 8.0000e-01, 2.4560e+03, 6.2278e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([-79.0268], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.334670745286086 m 98.0 km/h 150.33695411433345 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0086435111079073 40.0 -0.023522555725619353 -90.41544918545806 0.0
reward =  -51.447615252291584 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0638e+01, 9.4027e+00, 8.0000e-01, 2.4560e+03, 6.2278e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0497e+01, 9.1208e+00, 5.0000e-01, 0.0000e+00, 7.1585e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([-51.4476], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.147742996705137 m 91.0 km/h 152.75159548943225 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9781743970100802 40.0 -18.822708862425607 -80.46689151643184 0.0
reward =  -58.31142598184737 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0497e+01, 9.1208e+00, 5.0000e-01, 0.0000e+00, 7.1585e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 5.0659e+01, 9.3692e+00, 4.3467e-01, 1.1294e+03, 8.1533e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([-58.3114], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.03946076214655 m 88.0 km/h 121.33782067929424 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8291995728863077 40.0 -18.822708862425607 -70.22347575009917 0.0
reward =  -48.216985039638466 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0659e+01, 9.3692e+00, 4.3467e-01, 1.1294e+03, 8.1533e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0655e+01, 9.7244e+00, 3.8300e-01, 1.6940e+03, 9.1777e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([-48.2170], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 26.201449727427597 m 87.00000000000001 km/h 147.0635826260155 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6108346847143327 40.0 -2.9226979485713054 -59.38149655254292 0.0
reward =  -22.91502918582856 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0655e+01, 9.7244e+00, 3.8300e-01, 1.6940e+03, 9.1777e+03,
         0.0000e+00, 8.1773e+02]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0420e+01, 9.7355e+00, 5.0000e-01, 7.7277e+03, 1.0262e+04,
         0.0000e+00, 8.5454e+03]], device='cuda:0') tensor([-22.9150], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 29.71097576121596 m 83.00000000000001 km/h 130.45204004796878 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.1041228558418794 40.0 -16.253883327163397 -58.45395897142611 0.0
reward =  -33.60371944274763 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0420e+01, 9.7355e+00, 5.0000e-01, 7.7277e+03, 1.0262e+04,
         0.0000e+00, 8.5454e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0509e+01, 1.0131e+01, 8.0000e-01, 3.5208e+04, 1.1959e+03,
         0.0000e+00, 3.5208e+04]], device='cuda:0') tensor([-33.6037], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 27.850305167764173 m 96.0 km/h 130.89626601860365 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8099413394896744 40.0 -21.770116028510675 -151.55613556208843 0.0
reward =  -134.13619293008878 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0509e+01, 1.0131e+01, 8.0000e-01, 3.5208e+04, 1.1959e+03,
         0.0000e+00, 3.5208e+04]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0523e+01, 9.7380e+00, 8.0000e-01, 8.7492e+02, 1.0444e+03,
         0.0000e+00, 5.2299e+02]], device='cuda:0') tensor([-134.1362], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 27.218287665217105 m 82.0 km/h 115.00430721746048 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4772427588751866 40.0 -14.257587268709456 -139.60664341638338 0.0
reward =  -114.34147344396803 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0523e+01, 9.7380e+00, 8.0000e-01, 8.7492e+02, 1.0444e+03,
         0.0000e+00, 5.2299e+02]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0642e+01, 9.4010e+00, 8.0000e-01, 7.5125e+02, 2.2393e+03,
         0.0000e+00, 1.2742e+03]], device='cuda:0') tensor([-114.3415], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.34305427408891 m 98.0 km/h 135.11366932601706 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9635585403804156 40.0 -14.257587268709456 -130.2969500095752 0.0
reward =  -103.59097873790424 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0642e+01, 9.4010e+00, 8.0000e-01, 7.5125e+02, 2.2393e+03,
         0.0000e+00, 1.2742e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.0815e+01, 9.6361e+00, 7.4177e-01, 1.4258e+03, 3.1703e+03,
         0.0000e+00, 1.2742e+03]], device='cuda:0') tensor([-103.5910], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.01908139027671 m 83.0 km/h 135.74658205580178 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5259004578888847 40.0 -14.257587268709456 -119.4453002499371 0.0
reward =  -93.17698706075768 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0815e+01, 9.6361e+00, 7.4177e-01, 1.4258e+03, 3.1703e+03,
         0.0000e+00, 1.2742e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.0718e+01, 9.9571e+00, 6.8401e-01, 0.0000e+00, 4.2555e+03,
         0.0000e+00, 1.2742e+03]], device='cuda:0') tensor([-93.1770], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.05958949574566 m 80.0 km/h 130.0492467394193 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9861385807554668 40.0 -2.915714924402362 -108.16848497685154 0.0
reward =  -72.07033848200938 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0718e+01, 9.9571e+00, 6.8401e-01, 0.0000e+00, 4.2555e+03,
         0.0000e+00, 1.2742e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0554e+01, 9.7127e+00, 8.0000e-01, 7.2572e+03, 5.3832e+03,
         0.0000e+00, 8.5314e+03]], device='cuda:0') tensor([-72.0703], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 26.58303364212984 m 79.99999999999999 km/h 133.1714655082361 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.20545738281379686 40.0 -0.07397941913643338 -96.20611983789313 0.0
reward =  -56.074641874215764 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0554e+01, 9.7127e+00, 8.0000e-01, 7.2572e+03, 5.3832e+03,
         0.0000e+00, 8.5314e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.0404e+01, 1.0005e+01, 0.0000e+00, 0.0000e+00, 6.5794e+03,
         0.0000e+00, 8.5314e+03]], device='cuda:0') tensor([-56.0746], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.293598963231915 m 100.0 km/h 127.06678755145789 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.3208061281879083 -500 -1.1576188922567872 -86.74042421112964 0.0
reward =  -588.2188492315743 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0404e+01, 1.0005e+01, 0.0000e+00, 0.0000e+00, 6.5794e+03,
         0.0000e+00, 8.5314e+03]], device='cuda:0') tensor([[10]], device='cuda:0') None tensor([-588.2188], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 24
Sum reward: -2442.7399873561035
**************************************Episode 51 done**************************************

state_reset =  tensor([[ 5.0000, 51.3388, 12.3801,  0.1044,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.45280521332937 m 89.0 km/h 134.77970508346687 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.02738035892314423 -37.939395062976814 -2.1011961630267035 -151.70448328449598 0.0
reward =  -191.77245486942263 

state, action, next_state, reward =  tensor([[ 5.0000, 51.3388, 12.3801,  0.1044,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.1385e+01, 1.2739e+01, 5.0000e-01, 4.3673e+04, 1.0296e+03,
         0.0000e+00, 6.9024e+03]], device='cuda:0') tensor([-191.7725], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.050885740388132 m 91.0 km/h 137.04953978989775 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.055713321411193464 40.0 -2.1011961630267035 -141.79424277181496 -0.0
reward =  -103.83972561343049 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.1385e+01, 1.2739e+01, 5.0000e-01, 4.3673e+04, 1.0296e+03,
         0.0000e+00, 6.9024e+03]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.1345e+01, 1.2384e+01, 4.4161e-01, 0.0000e+00, 2.0206e+03,
         0.0000e+00, 6.9024e+03]], device='cuda:0') tensor([-103.8397], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.018421571604563 m 83.00000000000001 km/h 130.008910336594 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9521360292683341 40.0 -2.9613510351067873 -130.94287919858888 0.0
reward =  -94.856366262964 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.1345e+01, 1.2384e+01, 4.4161e-01, 0.0000e+00, 2.0206e+03,
         0.0000e+00, 6.9024e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.1134e+01, 1.2510e+01, 8.0000e-01, 1.7515e+04, 3.1057e+03,
         0.0000e+00, 8.6227e+03]], device='cuda:0') tensor([-94.8564], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.11687413484448 m 92.00000000000001 km/h 131.2497143130198 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9508973005095389 40.0 -4.148120754775177 -121.11453714582368 0.0
reward =  -84.31176060008931 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1134e+01, 1.2510e+01, 8.0000e-01, 1.7515e+04, 3.1057e+03,
         0.0000e+00, 8.6227e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.1345e+01, 1.2379e+01, 8.0000e-01, 2.3735e+03, 4.0885e+03,
         0.0000e+00, 1.0996e+04]], device='cuda:0') tensor([-84.3118], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.342632211870608 m 81.0 km/h 121.0897429208174 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.06869573274444672 40.0 -4.516368693111846 -109.85114505165895 0.0
reward =  -74.43620947751523 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.1345e+01, 1.2379e+01, 8.0000e-01, 2.3735e+03, 4.0885e+03,
         0.0000e+00, 1.0996e+04]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.1382e+01, 1.2739e+01, 8.0000e-01, 7.3650e+02, 5.2149e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([-74.4362], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.0
Length, speed, consumption 25.013282371162816 m 96.0 km/h 147.01994559219344 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.06993446150324191 40.0 -4.516368693111846 -100.47116416247289 -0.0
reward =  -64.9175983940815 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1382e+01, 1.2739e+01, 8.0000e-01, 7.3650e+02, 5.2149e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([[12]], device='cuda:0') tensor([[4.0000e+00, 5.1345e+01, 1.2384e+01, 7.3746e-01, 0.0000e+00, 6.1529e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([-64.9176], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.984419330606812 m 98.0 km/h 150.91690628515525 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.36531493128569564 40.0 -4.516368693111846 -90.9258672655153 -243.0
reward =  -298.8075508899128 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.1345e+01, 1.2384e+01, 7.3746e-01, 0.0000e+00, 6.1529e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.1325e+01, 1.2011e+01, 6.7077e-01, 0.0000e+00, 7.1074e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([-298.8076], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.0
Length, speed, consumption 25.12472536272795 m 92.00000000000001 km/h 142.5018145399389 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.32712229059886916 40.0 -4.516368693111846 -90.32737386223691 -0.0
reward =  -54.51662026474988 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.1325e+01, 1.2011e+01, 6.7077e-01, 0.0000e+00, 7.1074e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([[17]], device='cuda:0') tensor([[5.0000e+00, 5.1337e+01, 1.2372e+01, 6.0988e-01, 0.0000e+00, 9.2329e+02,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([-54.5166], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.08194866665807 m 91.0 km/h 145.09950441866872 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9438279623650422 40.0 -0.054798236623002004 -142.84454998805282 0.0
reward =  -103.84317618704085 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.1337e+01, 1.2372e+01, 6.0988e-01, 0.0000e+00, 9.2329e+02,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 5.1127e+01, 1.2507e+01, 0.0000e+00, 0.0000e+00, 1.9155e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([-103.8432], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.672389000659024 m 94.0 km/h 136.3195637927338 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9824267233111735 -500 -5.776242286343244 -133.012571221843 0.0
reward =  -637.806386784875 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.1127e+01, 1.2507e+01, 0.0000e+00, 0.0000e+00, 1.9155e+03,
         0.0000e+00, 1.1733e+04]], device='cuda:0') tensor([[8]], device='cuda:0') None tensor([-637.8064], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 10
Sum reward: -1709.1078493440818
**************************************Episode 52 done**************************************

state_reset =  tensor([[ 5.0000, 50.5544,  9.6721,  0.1876,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 28.033399069702252 m 91.0 km/h 148.50702572063256 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.3897388565406692 40.0 -25.186630765963056 -150.9098641042936 0.0
reward =  -136.48623372679734 

state, action, next_state, reward =  tensor([[ 5.0000, 50.5544,  9.6721,  0.1876,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0316e+01, 9.8028e+00, 5.0000e-01, 3.6872e+04, 1.1090e+03,
         0.0000e+00, 1.8134e+02]], device='cuda:0') tensor([-136.4862], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.858581565303723 m 90.0 km/h 139.5851714138574 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5080960428448418 40.0 -1.3073556271089666 -140.16643147817211 0.0
reward =  -100.96569106243624 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0316e+01, 9.8028e+00, 5.0000e-01, 3.6872e+04, 1.1090e+03,
         0.0000e+00, 1.8134e+02]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0553e+01, 9.7260e+00, 8.0000e-01, 5.1334e+03, 2.1834e+03,
         0.0000e+00, 5.3147e+03]], device='cuda:0') tensor([-100.9657], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.11706995935153 m 96.0 km/h 196.67541390949472 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.012969664177962113 40.0 -1.3073556271089666 -130.74753024341533 -270.0
reward =  -362.0678555347023 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0553e+01, 9.7260e+00, 8.0000e-01, 5.1334e+03, 2.1834e+03,
         0.0000e+00, 5.3147e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 5.0378e+01, 9.9509e+00, 7.1599e-01, 0.0000e+00, 3.1252e+03,
         0.0000e+00, 5.3147e+03]], device='cuda:0') tensor([-362.0679], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.11706995935153 m 99.0 km/h 106.80465634401178 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.012969664177962113 40.0 -0.017036513340431568 -121.61405025819657 0.0
reward =  -81.61811710735904 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0378e+01, 9.9509e+00, 7.1599e-01, 0.0000e+00, 3.1252e+03,
         0.0000e+00, 5.3147e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0553e+01, 9.7260e+00, 5.0000e-01, 0.0000e+00, 4.0386e+03,
         0.0000e+00, 5.3147e+03]], device='cuda:0') tensor([-81.6181], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.785655692736658 m 80.0 km/h 135.06943875629105 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.17794541706922815 40.0 -2.5611830823660915 -110.01050519646508 0.0
reward =  -72.39374286176195 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0553e+01, 9.7260e+00, 5.0000e-01, 0.0000e+00, 4.0386e+03,
         0.0000e+00, 5.3147e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0404e+01, 1.0005e+01, 5.0000e-01, 2.5077e+03, 5.1989e+03,
         0.0000e+00, 7.8224e+03]], device='cuda:0') tensor([-72.3937], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.785655692736658 m 88.0 km/h 113.64035677555295 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.17794541706922815 40.0 -25.869467550022456 -99.46182786761827 0.0
reward =  -85.50924083470994 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0404e+01, 1.0005e+01, 5.0000e-01, 2.5077e+03, 5.1989e+03,
         0.0000e+00, 7.8224e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0553e+01, 9.7260e+00, 8.0000e-01, 4.9369e+03, 6.2538e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-85.5092], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.088337027038417 m 94.0 km/h 135.06356266273082 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5556416978267161 40.0 -25.869467550022456 -89.85352858066737 0.0
reward =  -76.27863782851654 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0553e+01, 9.7260e+00, 8.0000e-01, 4.9369e+03, 6.2538e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 5.0637e+01, 9.3959e+00, 7.4237e-01, 2.3283e+03, 7.2146e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-76.2786], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.46254663785049 m 89.0 km/h 129.66980157759843 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.12043118104589987 40.0 -25.869467550022456 -79.55407151367166 0.0
reward =  -65.30310788264822 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0637e+01, 9.3959e+00, 7.4237e-01, 2.3283e+03, 7.2146e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.0466e+01, 9.6367e+00, 6.8622e-01, 7.7608e+02, 8.2446e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-65.3031], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.46254663785049 m 94.0 km/h 148.41199472504695 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.12043118104589987 40.0 -25.869467550022456 -69.80245790768636 0.0
reward =  -55.79235663875472 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0466e+01, 9.6367e+00, 6.8622e-01, 7.7608e+02, 8.2446e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.0637e+01, 9.3959e+00, 6.2195e-01, 7.7608e+02, 9.2198e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-55.7924], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.261936327301594 m 83.00000000000001 km/h 112.53070534264515 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.878164092692911 40.0 -25.869467550022456 -58.845473476567605 0.0
reward =  -43.83677693389715 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0637e+01, 9.3959e+00, 6.2195e-01, 7.7608e+02, 9.2198e+03,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 5.0834e+01, 9.5736e+00, 5.7361e-01, 2.5869e+03, 1.0315e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-43.8368], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.168479761205095 m 99.0 km/h 149.8611835301811 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7092663894290349 40.0 -0.0009460670653906322 -49.693299017947574 0.0
reward =  -10.403511474441999 

state, action, next_state, reward =  tensor([[4.0000e+00, 5.0834e+01, 9.5736e+00, 5.7361e-01, 2.5869e+03, 1.0315e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0905e+01, 9.2331e+00, 5.0000e-01, 0.0000e+00, 1.1231e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-10.4035], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.168479761205095 m 86.0 km/h 133.1663912187428 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7092663894290349 40.0 -25.869467550022456 -39.15765632721055 0.0
reward =  -24.317857487803977 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0905e+01, 9.2331e+00, 5.0000e-01, 0.0000e+00, 1.1231e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 5.0834e+01, 9.5736e+00, 4.4300e-01, 7.7608e+02, 1.2284e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-24.3179], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.13081421781233 m 79.99999999999999 km/h 121.62162054513222 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.03398881651392672 40.0 -25.869467550022456 -27.848789929195007 0.0
reward =  -13.75224629573139 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0834e+01, 9.5736e+00, 4.4300e-01, 7.7608e+02, 1.2284e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 5.1034e+01, 9.4063e+00, 3.9102e-01, 2.3283e+03, 1.3415e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([-13.7522], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.086778053823714 m 95.0 km/h 136.11444254297606 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.4455390701399511 40.0 -5.301163874247031 -18.342221403535497 0.0
reward =  16.802153792357423 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.1034e+01, 9.4063e+00, 3.9102e-01, 2.3283e+03, 1.3415e+04,
         0.0000e+00, 1.1305e+02]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.1258e+01, 9.4474e+00, 8.0000e-01, 6.5911e+03, 1.4366e+04,
         0.0000e+00, 2.1699e+03]], device='cuda:0') tensor([16.8022], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.07219989636143 m 82.0 km/h 114.76520470248035 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7714268188721035 40.0 -0.09400356926563745 -6.895889741718275 0.0
reward =  32.23867987014398 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1258e+01, 9.4474e+00, 8.0000e-01, 6.5911e+03, 1.4366e+04,
         0.0000e+00, 2.1699e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.1052e+01, 9.2688e+00, 8.0000e-01, 7.1812e+02, 1.5510e+04,
         0.0000e+00, 2.8880e+03]], device='cuda:0') tensor([32.2387], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.07219989636143 m 85.0 km/h 131.7533750212744 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7714268188721035 40.0 -18.75575920662015 -1.880071385312749 0.0
reward =  20.1355962269392 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.1052e+01, 9.2688e+00, 8.0000e-01, 7.1812e+02, 1.5510e+04,
         0.0000e+00, 2.8880e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.1258e+01, 9.4474e+00, 8.0000e-01, 8.2442e+02, 6.0265e+02,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([20.1356], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.523728859563896 m 86.0 km/h 120.26328412064987 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.07429960921604419 40.0 -0.024779647184258225 -145.28912325525633 0.0
reward =  -105.23960329322455 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.1258e+01, 9.4474e+00, 8.0000e-01, 8.2442e+02, 6.0265e+02,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.1485e+01, 9.3888e+00, 5.0000e-01, 0.0000e+00, 1.6711e+03,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([-105.2396], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.44222234296967 m 80.0 km/h 123.5022493523781 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.15454478146292852 40.0 -18.75575920662015 -133.84012320091998 0.0
reward =  -112.75042718900306 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.1485e+01, 9.3888e+00, 5.0000e-01, 0.0000e+00, 1.6711e+03,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 5.1257e+01, 9.4181e+00, 4.4656e-01, 1.1253e+03, 2.8160e+03,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([-112.7504], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 28.089256463465624 m 95.0 km/h 154.932389792101 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.24837484868655096 40.0 -0.03725491952508838 -123.19577338318564 0.0
reward =  -83.48140315139727 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.1257e+01, 9.4181e+00, 4.4656e-01, 1.1253e+03, 2.8160e+03,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[3.0000e+00, 5.1006e+01, 9.4708e+00, 0.0000e+00, 0.0000e+00, 3.8804e+03,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([-83.4814], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 26.561250200850445 m 81.0 km/h 111.8552278685918 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.28860325291685063 -500 -4.7107763061746235 -111.39077329391877 0.0
reward =  -615.8129463471765 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.1006e+01, 9.4708e+00, 0.0000e+00, 0.0000e+00, 3.8804e+03,
         0.0000e+00, 8.2442e+02]], device='cuda:0') tensor([[7]], device='cuda:0') None tensor([-615.8129], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 20
Sum reward: -1976.8333257609215
**************************************Episode 53 done**************************************

state_reset =  tensor([[ 5.0000, 49.8437,  8.7090,  0.4379,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.8364577186674 m 90.0 km/h 119.93525431220466 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.8890140092994063 40.0 -10.7931950173751 -151.66541691253303 0.0
reward =  -121.56959792060871 

state, action, next_state, reward =  tensor([[ 5.0000, 49.8437,  8.7090,  0.4379,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 5.0063e+01, 8.8298e+00, 5.0000e-01, 1.6207e+03, 1.0335e+03,
         0.0000e+00, 1.6207e+03]], device='cuda:0') tensor([-121.5696], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.117590224494347 m 93.0 km/h 147.26114852268412 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9458909430457745 40.0 -10.7931950173751 -141.94247876111586 0.0
reward =  -113.68156472153674 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0063e+01, 8.8298e+00, 5.0000e-01, 1.6207e+03, 1.0335e+03,
         0.0000e+00, 1.6207e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9869e+01, 8.6494e+00, 4.3709e-01, 1.0793e+03, 2.0058e+03,
         0.0000e+00, 1.6207e+03]], device='cuda:0') tensor([-113.6816], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.056908484504326 m 87.99999999999999 km/h 120.98708878114607 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7161464950462594 40.0 -2.3847891606484803 -131.69192529018227 0.0
reward =  -94.79286094587701 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9869e+01, 8.6494e+00, 4.3709e-01, 1.0793e+03, 2.0058e+03,
         0.0000e+00, 1.6207e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9644e+01, 8.6255e+00, 8.0000e-01, 5.8489e+03, 3.0308e+03,
         0.0000e+00, 7.4696e+03]], device='cuda:0') tensor([-94.7929], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.056908484504326 m 90.0 km/h 146.83195033289405 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7161464950462594 40.0 -2.3847891606484803 -121.66916189638056 -243.0
reward =  -326.3378045619828 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9644e+01, 8.6255e+00, 8.0000e-01, 5.8489e+03, 3.0308e+03,
         0.0000e+00, 7.4696e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9869e+01, 8.6494e+00, 7.3743e-01, 0.0000e+00, 4.0331e+03,
         0.0000e+00, 7.4696e+03]], device='cuda:0') tensor([-326.3378], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.117590224494347 m 86.00000000000001 km/h 122.81742718910125 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9458909430457745 40.0 -3.1964730667270964 -111.15482180240619 0.0
reward =  -73.4054039260875 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9869e+01, 8.6494e+00, 7.3743e-01, 0.0000e+00, 4.0331e+03,
         0.0000e+00, 7.4696e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0063e+01, 8.8298e+00, 8.0000e-01, 1.6234e+03, 5.0845e+03,
         0.0000e+00, 9.0929e+03]], device='cuda:0') tensor([-73.4054], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.64439129510398 m 89.99999999999999 km/h 132.58654371312005 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7670485914750746 40.0 -4.420509501407173 -100.89706528436459 0.0
reward =  -66.08462337724683 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0063e+01, 8.8298e+00, 8.0000e-01, 1.6234e+03, 5.0845e+03,
         0.0000e+00, 9.0929e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 5.0080e+01, 8.4715e+00, 8.0000e-01, 2.4481e+03, 6.1103e+03,
         0.0000e+00, 1.1541e+04]], device='cuda:0') tensor([-66.0846], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.226059418400403 m 98.0 km/h 150.68196799815937 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.4109386126473197 40.0 -21.097490084295206 -91.63034957964607 0.0
reward =  -73.1387782765886 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0080e+01, 8.4715e+00, 8.0000e-01, 2.4481e+03, 6.1103e+03,
         0.0000e+00, 1.1541e+04]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9860e+01, 8.5553e+00, 8.0000e-01, 9.1227e+02, 7.0370e+03,
         0.0000e+00, 5.9025e+02]], device='cuda:0') tensor([-73.1388], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 25.222377209569704 m 83.00000000000001 km/h 130.48015576755913 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.3388766053048079 40.0 -0.1298925903530437 -80.69052332007367 0.0
reward =  -40.481539305121906 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9860e+01, 8.5553e+00, 8.0000e-01, 9.1227e+02, 7.0370e+03,
         0.0000e+00, 5.9025e+02]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 5.0076e+01, 8.4457e+00, 8.0000e-01, 2.3695e+03, 8.1309e+03,
         0.0000e+00, 2.9598e+03]], device='cuda:0') tensor([-40.4815], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.123414619891353 m 97.0 km/h 157.76692404684658 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9539211939239874 40.0 -0.6055298518891038 -71.36636944052636 0.0
reward =  -31.01797809849147 

state, action, next_state, reward =  tensor([[3.0000e+00, 5.0076e+01, 8.4457e+00, 8.0000e-01, 2.3695e+03, 8.1309e+03,
         0.0000e+00, 2.9598e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 5.0257e+01, 8.6564e+00, 8.0000e-01, 9.5127e+02, 9.0634e+03,
         0.0000e+00, 3.9111e+03]], device='cuda:0') tensor([-31.0180], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.9
Length, speed, consumption 25.64624480096898 m 86.0 km/h 125.8980189445635 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.008959094683039 40.0 -0.6055298518891038 -60.63073208198121 -243.0
reward =  -263.22730283918725 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0257e+01, 8.6564e+00, 8.0000e-01, 9.5127e+02, 9.0634e+03,
         0.0000e+00, 3.9111e+03]], device='cuda:0') tensor([[20]], device='cuda:0') tensor([[5.0000e+00, 5.0351e+01, 8.9861e+00, 7.4509e-01, 0.0000e+00, 1.0137e+04,
         0.0000e+00, 3.9111e+03]], device='cuda:0') tensor([-263.2273], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.215991779749853 m 87.0 km/h 118.37724638661712 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.7516836745526223 40.0 -0.01943229407210262 -50.1965285869123 0.0
reward =  -10.967644555537028 

state, action, next_state, reward =  tensor([[5.0000e+00, 5.0351e+01, 8.9861e+00, 7.4509e-01, 0.0000e+00, 1.0137e+04,
         0.0000e+00, 3.9111e+03]], device='cuda:0') tensor([[2]], device='cuda:0') tensor([[1.0000e+00, 5.0129e+01, 8.9144e+00, 5.0000e-01, 0.0000e+00, 1.1180e+04,
         0.0000e+00, 3.9111e+03]], device='cuda:0') tensor([-10.9676], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.318678017471516 m 83.99999999999999 km/h 127.89644881433365 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0026487149242846 40.0 -1.246849425327382 -39.3456665794245 0.0
reward =  -1.5951647196761698 

state, action, next_state, reward =  tensor([[1.0000e+00, 5.0129e+01, 8.9144e+00, 5.0000e-01, 0.0000e+00, 1.1180e+04,
         0.0000e+00, 3.9111e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9963e+01, 8.6710e+00, 5.0000e-01, 5.2988e+03, 1.2265e+04,
         0.0000e+00, 2.5753e+03]], device='cuda:0') tensor([-1.5952], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.3
Length, speed, consumption 25.540193502077766 m 84.99999999999999 km/h 119.04878433026981 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9792480509179621 40.0 -1.246849425327382 -28.52864344913274 0.0
reward =  9.245259074621917 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9963e+01, 8.6710e+00, 5.0000e-01, 5.2988e+03, 1.2265e+04,
         0.0000e+00, 2.5753e+03]], device='cuda:0') tensor([[13]], device='cuda:0') tensor([[4.0000e+00, 4.9772e+01, 8.4728e+00, 4.4829e-01, 3.7405e+01, 1.3347e+04,
         0.0000e+00, 2.5753e+03]], device='cuda:0') tensor([9.2453], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 1.0
Length, speed, consumption 25.25974059819085 m 96.0 km/h 167.81324700492414 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.939958811266392 40.0 -1.246849425327382 -19.05624072481118 0.0
reward =  20.63686866112783 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9772e+01, 8.4728e+00, 4.4829e-01, 3.7405e+01, 1.3347e+04,
         0.0000e+00, 2.5753e+03]], device='cuda:0') tensor([[21]], device='cuda:0') tensor([[5.0000e+00, 4.9848e+01, 8.8048e+00, 3.7620e-01, 1.2468e+02, 1.4294e+04,
         0.0000e+00, 2.5753e+03]], device='cuda:0') tensor([20.6369], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.026990847073222 m 89.0 km/h 119.01985914754222 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  1.0009388511148094 40.0 -12.560236149316298 -8.932963528242235 0.0
reward =  19.50773917355628 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9848e+01, 8.8048e+00, 3.7620e-01, 1.2468e+02, 1.4294e+04,
         0.0000e+00, 2.5753e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9994e+01, 9.0702e+00, 5.0000e-01, 2.4620e+03, 1.5307e+04,
         0.0000e+00, 1.4440e+03]], device='cuda:0') tensor([19.5077], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.5 0.0
Length, speed, consumption 25.530527107640417 m 92.00000000000001 km/h 201.31910544493627 kWh/100km

Terminated: Violated self.max_driving times,should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.37618897342681884 40.0 -1.4965566903424041 -10.572427312692344 0.0
reward =  28.307204970392075 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9994e+01, 9.0702e+00, 5.0000e-01, 2.4620e+03, 1.5307e+04,
         0.0000e+00, 1.4440e+03]], device='cuda:0') tensor([[2]], device='cuda:0') None tensor([28.3072], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 16
Sum reward: -1138.6031913682436
**************************************Episode 54 done**************************************

state_reset =  tensor([[ 4.0000, 49.6809,  9.7794,  0.7379,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  5.0 0.0 0.6
Length, speed, consumption 25.93141501689975 m 92.00000000000001 km/h 123.7392605607365 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5195308647491876 40.0 -27.0 -151.85292455860446 0.0
reward =  -138.33339369385527 

state, action, next_state, reward =  tensor([[ 4.0000, 49.6809,  9.7794,  0.7379,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[19]], device='cuda:0') tensor([[5.0000e+00, 4.9659e+01, 1.0138e+01, 6.8330e-01, 1.6200e+03, 1.0147e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-138.3334], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 26.18025089133919 m 81.00000000000001 km/h 111.92826851315803 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.1588444454817311 40.0 -0.6084350688398233 -140.21725749578704 0.0
reward =  -100.66684811914513 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9659e+01, 1.0138e+01, 6.8330e-01, 1.6200e+03, 1.0147e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9824e+01, 9.8784e+00, 8.0000e-01, 3.9169e+03, 2.1783e+03,
         0.0000e+00, 3.9169e+03]], device='cuda:0') tensor([-100.6668], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 1.0
Length, speed, consumption 25.473128519195328 m 95.0 km/h 150.71079946473773 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.747442374443966 40.0 -0.6084350688398233 -130.5642824779867 -270.0
reward =  -360.42527517238256 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9824e+01, 9.8784e+00, 8.0000e-01, 3.9169e+03, 2.1783e+03,
         0.0000e+00, 3.9169e+03]], device='cuda:0') tensor([[16]], device='cuda:0') tensor([[4.0000e+00, 4.9866e+01, 1.0228e+01, 7.3471e-01, 0.0000e+00, 3.1436e+03,
         0.0000e+00, 3.9169e+03]], device='cuda:0') tensor([-360.4253], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.3 0.0
Length, speed, consumption 25.19958404900593 m 80.0 km/h 114.48729216714297 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9965541929379013 40.0 -0.03856444267771267 -119.22446965593403 0.0
reward =  -80.25958829154965 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9866e+01, 1.0228e+01, 7.3471e-01, 0.0000e+00, 3.1436e+03,
         0.0000e+00, 3.9169e+03]], device='cuda:0') tensor([[1]], device='cuda:0') tensor([[1.0000e+00, 4.9662e+01, 1.0075e+01, 3.0000e-01, 0.0000e+00, 4.2776e+03,
         0.0000e+00, 3.9169e+03]], device='cuda:0') tensor([-80.2596], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.2665112556546 m 95.0 km/h 166.7264052954785 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.710479000863179 40.0 -2.525146420361388 -109.6497917064228 0.0
reward =  -72.88541712764737 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9662e+01, 1.0075e+01, 3.0000e-01, 0.0000e+00, 4.2776e+03,
         0.0000e+00, 3.9169e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9627e+01, 9.7282e+00, 5.0000e-01, 3.8334e+03, 5.2350e+03,
         0.0000e+00, 7.7503e+03]], device='cuda:0') tensor([-72.8854], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.025069067130826 m 96.0 km/h 133.3958253088183 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9446802387425536 40.0 -1.240799329188667 -100.26539080624876 0.0
reward =  -60.56150989669487 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9627e+01, 9.7282e+00, 5.0000e-01, 3.8334e+03, 5.2350e+03,
         0.0000e+00, 7.7503e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9753e+01, 1.0016e+01, 8.0000e-01, 7.5522e+03, 6.1735e+03,
         0.0000e+00, 2.5759e+03]], device='cuda:0') tensor([-60.5615], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.18643979562303 m 83.00000000000001 km/h 138.1508220553056 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9579213258207636 40.0 -0.024082436458483358 -89.34115185874961 0.0
reward =  -50.32315562102886 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9753e+01, 1.0016e+01, 8.0000e-01, 7.5522e+03, 6.1735e+03,
         0.0000e+00, 2.5759e+03]], device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9622e+01, 9.7309e+00, 5.0000e-01, 0.0000e+00, 7.2659e+03,
         0.0000e+00, 2.5759e+03]], device='cuda:0') tensor([-50.3232], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.06361961567346 m 94.0 km/h 140.06650553436302 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.37746223165875303 40.0 -0.3792570960572339 -79.74231881444913 0.0
reward =  -40.49903814216512 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9622e+01, 9.7309e+00, 5.0000e-01, 0.0000e+00, 7.2659e+03,
         0.0000e+00, 2.5759e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9688e+01, 9.3981e+00, 8.0000e-01, 3.0457e+04, 8.2258e+03,
         0.0000e+00, 3.4585e+03]], device='cuda:0') tensor([-40.4990], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.8 0.0
Length, speed, consumption 28.077988170283817 m 87.0 km/h 140.96637449040418 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0706471609329875 40.0 -1.804155886383005 -68.12384095088342 0.0
reward =  -30.998643998199412 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9688e+01, 9.3981e+00, 8.0000e-01, 3.0457e+04, 8.2258e+03,
         0.0000e+00, 3.4585e+03]], device='cuda:0') tensor([[11]], device='cuda:0') tensor([[3.0000e+00, 4.9455e+01, 9.2471e+00, 8.0000e-01, 2.8498e+03, 9.3876e+03,
         0.0000e+00, 6.3083e+03]], device='cuda:0') tensor([-30.9986], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.12269709135771 m 97.0 km/h 114.01609432977291 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8469035154483094 40.0 -2.8353369348821644 -58.79995337058572 0.0
reward =  -22.482193820916194 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9455e+01, 9.2471e+00, 8.0000e-01, 2.8498e+03, 9.3876e+03,
         0.0000e+00, 6.3083e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9230e+01, 9.2113e+00, 8.0000e-01, 2.0624e+03, 1.0320e+04,
         0.0000e+00, 8.3707e+03]], device='cuda:0') tensor([-22.4822], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.472165081317012 m 81.0 km/h 121.07713991106766 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.5766162398861722 40.0 -19.598167451067756 -56.70673869764329 0.0
reward =  -36.88152238859722 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9230e+01, 9.2113e+00, 8.0000e-01, 2.0624e+03, 1.0320e+04,
         0.0000e+00, 8.3707e+03]], device='cuda:0') tensor([[7]], device='cuda:0') tensor([[2.0000e+00, 4.9248e+01, 8.8615e+00, 8.0000e-01, 7.4018e+02, 9.2277e+02,
         0.0000e+00, 7.4018e+02]], device='cuda:0') tensor([-36.8815], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 25.220767676893143 m 100.0 km/h 156.02214376354092 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.49115743896561675 40.0 -0.02330782612191993 -143.69277605089778 0.0
reward =  -103.22492643805408 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9248e+01, 8.8615e+00, 8.0000e-01, 7.4018e+02, 9.2277e+02,
         0.0000e+00, 7.4018e+02]], device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 4.9210e+01, 9.2039e+00, 5.0000e-01, 0.0000e+00, 1.8307e+03,
         0.0000e+00, 7.4018e+02]], device='cuda:0') tensor([-103.2249], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.220767676893143 m 94.0 km/h 145.4285852040303 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.49115743896561675 40.0 -0.04376220993025492 -134.03375864272593 0.0
reward =  -94.56867829162181 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9210e+01, 9.2039e+00, 5.0000e-01, 0.0000e+00, 1.8307e+03,
         0.0000e+00, 7.4018e+02]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 4.9248e+01, 8.8615e+00, 0.0000e+00, 0.0000e+00, 2.7966e+03,
         0.0000e+00, 7.4018e+02]], device='cuda:0') tensor([-94.5687], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.415746995586165 m 98.0 km/h 142.22504748080343 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9499429571825266 -500 -2.9818623262314925 -124.69736178720449 0.0
reward =  -628.6291670706185 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9248e+01, 8.8615e+00, 0.0000e+00, 0.0000e+00, 2.7966e+03,
         0.0000e+00, 7.4018e+02]], device='cuda:0') tensor([[10]], device='cuda:0') None tensor([-628.6292], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 14
Sum reward: -1820.739358072476
**************************************Episode 55 done**************************************

state_reset =  tensor([[ 4.0000, 49.3561, 11.1381,  0.3271,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 26.008352788972722 m 95.0 km/h 136.82062925919587 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7706448750022193 40.0 -0.923936497207331 -152.14420315365243 0.0
reward =  -112.29749477585753 

state, action, next_state, reward =  tensor([[ 4.0000, 49.3561, 11.1381,  0.3271,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9572e+01, 1.1000e+01, 5.0000e-01, 2.2462e+04, 9.8558e+02,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([-112.2975], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  5.0 0.0 0.3
Length, speed, consumption 25.246242745431733 m 83.00000000000001 km/h 126.91846489565985 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9609625400932064 40.0 -0.923936497207331 -141.19402557732062 -81.0
reward =  -182.15699953443473 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9572e+01, 1.1000e+01, 5.0000e-01, 2.2462e+04, 9.8558e+02,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([[18]], device='cuda:0') tensor([[5.0000e+00, 4.9750e+01, 1.1219e+01, 4.4551e-01, 0.0000e+00, 2.0806e+03,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([-182.1570], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.373657837239737 m 88.99999999999999 km/h 126.29558947501503 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.11899485021193745 40.0 -0.923936497207331 -130.93052353079668 -243.0
reward =  -334.7354651777921 

state, action, next_state, reward =  tensor([[5.0000e+00, 4.9750e+01, 1.1219e+01, 4.4551e-01, 0.0000e+00, 2.0806e+03,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([[15]], device='cuda:0') tensor([[4.0000e+00, 4.9862e+01, 1.0911e+01, 3.9101e-01, 0.0000e+00, 3.1069e+03,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([-334.7355], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.0 0.0
Length, speed, consumption 26.184528436923824 m 84.0 km/h 125.8887516541821 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.9395413113498687 40.0 -0.03349467169234237 -119.70858277211502 0.0
reward =  -80.68161875515725 

state, action, next_state, reward =  tensor([[4.0000e+00, 4.9862e+01, 1.0911e+01, 3.9101e-01, 0.0000e+00, 3.1069e+03,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([[4]], device='cuda:0') tensor([[2.0000e+00, 4.9627e+01, 1.0923e+01, 0.0000e+00, 0.0000e+00, 4.2291e+03,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([-80.6816], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  2.0 0.8 0.0
Length, speed, consumption 25.69527790362639 m 92.00000000000001 km/h 137.90682564270347 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.5872850952349289 -500 -7.127785410103825 -109.65390880982642 0.0
reward =  -616.1944091246953 

state, action, next_state, reward =  tensor([[2.0000e+00, 4.9627e+01, 1.0923e+01, 0.0000e+00, 0.0000e+00, 4.2291e+03,
         0.0000e+00, 4.5479e+03]], device='cuda:0') tensor([[7]], device='cuda:0') None tensor([-616.1944], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 5
Sum reward: -1326.065987367937
**************************************Episode 56 done**************************************

state_reset =  tensor([[ 4.0000, 49.1391,  9.2220,  0.1097,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 27.342894113180876 m 84.0 km/h 123.84727273738228 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.2608496567340265 -25.634042157393733 -1.8100753105077592 -150.28161680863678 0.0
reward =  -177.9865839332723 

state, action, next_state, reward =  tensor([[ 4.0000, 49.1391,  9.2220,  0.1097,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[10]], device='cuda:0') tensor([[3.0000e+00, 4.9241e+01, 8.8796e+00, 5.0000e-01, 6.3202e+03, 1.1718e+03,
         0.0000e+00, 6.3202e+03]], device='cuda:0') tensor([-177.9866], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.8 0.0
Length, speed, consumption 25.296569708281428 m 91.0 km/h 135.81680074281672 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.2779624232685915 40.0 -1.0336178789080952 -140.27418263832763 0.0
reward =  -101.02983809396713 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9241e+01, 8.8796e+00, 5.0000e-01, 6.3202e+03, 1.1718e+03,
         0.0000e+00, 6.3202e+03]], device='cuda:0') tensor([[3]], device='cuda:0') tensor([[1.0000e+00, 4.9154e+01, 9.2013e+00, 8.0000e-01, 1.5175e+04, 2.1726e+03,
         0.0000e+00, 4.7672e+03]], device='cuda:0') tensor([-101.0298], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.29687198742829 m 85.0 km/h 128.2031965119448 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.27794612906069494 40.0 -0.04448445603649358 -129.56021332600506 0.0
reward =  -89.88264391110224 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9154e+01, 9.2013e+00, 8.0000e-01, 1.5175e+04, 2.1726e+03,
         0.0000e+00, 4.7672e+03]], device='cuda:0') tensor([[9]], device='cuda:0') tensor([[3.0000e+00, 4.9241e+01, 8.8796e+00, 3.0000e-01, 0.0000e+00, 3.2440e+03,
         0.0000e+00, 4.7672e+03]], device='cuda:0') tensor([-89.8826], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  1.0 0.0 0.0
Length, speed, consumption 25.29687198742829 m 80.0 km/h 114.67353907714127 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.27794612906069494 40.0 -0.02506652748574864 -118.17662093166233 0.0
reward =  -77.92374133008738 

state, action, next_state, reward =  tensor([[3.0000e+00, 4.9241e+01, 8.8796e+00, 3.0000e-01, 0.0000e+00, 3.2440e+03,
         0.0000e+00, 4.7672e+03]], device='cuda:0') tensor([[0]], device='cuda:0') tensor([[1.0000e+00, 4.9154e+01, 9.2013e+00, 0.0000e+00, 0.0000e+00, 4.3823e+03,
         0.0000e+00, 4.7672e+03]], device='cuda:0') tensor([-77.9237], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.5 0.0
Length, speed, consumption 25.29687198742829 m 91.0 km/h 140.07311207452636 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.27794612906069494 -500 -6.134792690599191 -108.169067178394 0.0
reward =  -614.5818059980538 

state, action, next_state, reward =  tensor([[1.0000e+00, 4.9154e+01, 9.2013e+00, 0.0000e+00, 0.0000e+00, 4.3823e+03,
         0.0000e+00, 4.7672e+03]], device='cuda:0') tensor([[10]], device='cuda:0') None tensor([-614.5818], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 5
Sum reward: -1061.404613266483
**************************************Episode 57 done**************************************

state_reset =  tensor([[ 5.0000, 49.5927, 11.0038,  0.1949,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.174916186625087 m 94.0 km/h 153.8063356251271 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.8436239246431622 40.0 -0.012901998214434485 -152.3585427370372 0.0
reward =  -113.2150686598948 

state, action, next_state, reward =  tensor([[ 5.0000, 49.5927, 11.0038,  0.1949,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[8]], device='cuda:0') tensor([[  3.0000,  49.3720,  11.0819,   0.0000,   0.0000, 964.1458,   0.0000,
           0.0000]], device='cuda:0') tensor([-113.2151], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.3 0.0
Length, speed, consumption 25.59911993321534 m 92.00000000000001 km/h 136.14643160260147 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.7122405187764298 -500 -6.255082379186746 -142.3414958066486 0.0
reward =  -647.884337667059 

state, action, next_state, reward =  tensor([[  3.0000,  49.3720,  11.0819,   0.0000,   0.0000, 964.1458,   0.0000,
           0.0000]], device='cuda:0') tensor([[9]], device='cuda:0') None tensor([-647.8843], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 2
Sum reward: -761.0994063269537
**************************************Episode 58 done**************************************

state_reset =  tensor([[ 4.0000, 50.5759,  8.5641,  0.6014,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') 

next_node, charge, rest =  2.0 0.5 0.0
Length, speed, consumption 26.126252485761313 m 94.0 km/h 171.3131444130299 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -0.6021461956571671 40.0 -0.0025296141419396513 -151.99420117566586 0.0
reward =  -112.59887698546498 

state, action, next_state, reward =  tensor([[ 4.0000, 50.5759,  8.5641,  0.6014,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='cuda:0') tensor([[6]], device='cuda:0') tensor([[2.0000e+00, 5.0342e+01, 8.5305e+00, 5.0000e-01, 0.0000e+00, 1.0006e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([-112.5989], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  3.0 0.0 0.0
Length, speed, consumption 25.45001260905537 m 92.00000000000001 km/h 125.01816936644003 kWh/100km

r_distance, r_trapped, r_charge, r_driving, r_rest_p =  0.9552081881201384 40.0 -0.04458892179126374 -142.0355005895138 0.0
reward =  -101.12488132318492 

state, action, next_state, reward =  tensor([[2.0000e+00, 5.0342e+01, 8.5305e+00, 5.0000e-01, 0.0000e+00, 1.0006e+03,
         0.0000e+00, 0.0000e+00]], device='cuda:0') tensor([[8]], device='cuda:0') tensor([[   3.0000,   50.5205,    8.7553,    0.0000,    0.0000, 1996.4500,
            0.0000,    0.0000]], device='cuda:0') tensor([-101.1249], device='cuda:0', dtype=torch.float64) 

next_node, charge, rest =  4.0 0.0 0.9
Length, speed, consumption 25.23053441097701 m 81.0 km/h 148.3042956568751 kWh/100km

Terminated: Trapped on the road, should be reseted
r_distance, r_trapped, r_charge, r_driving, r_rest_p =  -1.0091061393627712 -500 -27.0 -130.82192974019065 0.0
reward =  -658.8310358795534 

state, action, next_state, reward =  tensor([[   3.0000,   50.5205,    8.7553,    0.0000,    0.0000, 1996.4500,
            0.0000,    0.0000]], device='cuda:0') tensor([[15]], device='cuda:0') None tensor([-658.8310], device='cuda:0', dtype=torch.float64) 

Number of steps in an episode: 3
Sum reward: -872.5547941882032
**************************************Episode 59 done**************************************

Complete
